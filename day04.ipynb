{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业\n",
    "\n",
    "- 补全程序中的代码，理解其含义，并跑通整个项目；\n",
    "- 报名参加[千言数据集：信息抽取比赛](https://aistudio.baidu.com/aistudio/competition/detail/46)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Github作业链接和requirements截图\n",
    "\n",
    "<b>Github: https://github.com/libertatis/PaddleNLP-Learning</b>\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ecdbaf6026a749bf8e438ec633d2265b1af283d5c7d84dc78624c87fe90b6e44)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 基于预训练模型完成实体关系抽取\n",
    "\n",
    "信息抽取旨在从非结构化自然语言文本中提取结构化知识，如实体、关系、事件等。对于给定的自然语言句子，根据预先定义的schema集合，抽取出所有满足schema约束的SPO三元组。\n",
    "\n",
    "例如，「妻子」关系的schema定义为：      \n",
    "{      \n",
    "    S_TYPE: 人物,        \n",
    "    P: 妻子,      \n",
    "    O_TYPE: {      \n",
    "        @value: 人物       \n",
    "    }       \n",
    "}        \n",
    "\n",
    "该示例展示了如何使用PaddleNLP快速完成实体关系抽取，参与[千言信息抽取-关系抽取比赛](https://aistudio.baidu.com/aistudio/competition/detail/46)打榜。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already up-to-date: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl->paddlenlp) (7.2.0)\n",
      "/home/aistudio/relation_extraction\n"
     ]
    }
   ],
   "source": [
    "# 安装paddlenlp最新版本\n",
    "!pip install --upgrade paddlenlp\n",
    "\n",
    "%cd relation_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 92\r\n",
      "drwxr-xr-x 2 aistudio aistudio  4096 Jun 14 17:37 checkpoints\r\n",
      "drwxr-xr-x 3 aistudio aistudio  4096 Jun 14 17:37 data\r\n",
      "-rw-r--r-- 1 aistudio aistudio 13221 Jun 13 19:00 data_loader.py\r\n",
      "-rw-r--r-- 1 aistudio aistudio  4675 Jun 13 19:00 extract_chinese_and_punct.py\r\n",
      "-rw-r--r-- 1 aistudio aistudio   333 Jun 14 18:05 predict.sh\r\n",
      "drwxr-xr-x 2 aistudio aistudio  4096 Jun 14 06:31 __pycache__\r\n",
      "-rw-r--r-- 1 aistudio aistudio  6626 Jun 13 19:00 README.md\r\n",
      "-rw-r--r-- 1 aistudio aistudio  9849 Jun 13 19:00 re_official_evaluation.py\r\n",
      "-rw-r--r-- 1 aistudio aistudio 13477 Jun 14 12:28 run_duie.py\r\n",
      "-rw-r--r-- 1 aistudio aistudio   640 Jun 13 19:00 train.sh\r\n",
      "-rw-r--r-- 1 aistudio aistudio  8308 Jun 13 19:00 utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 关系抽取介绍\n",
    "\n",
    "针对 DuIE2.0 任务中多条、交叠SPO这一抽取目标，比赛对标准的 'BIO' 标注进行了扩展。\n",
    "对于每个 token，根据其在实体span中的位置（包括B、I、O三种），我们为其打上三类标签，并且根据其所参与构建的predicate种类，将 B 标签进一步区分。给定 schema 集合，对于 N 种不同 predicate，以及头实体/尾实体两种情况，我们设计对应的共 2*N 种 B 标签，再合并 I 和 O 标签，故每个 token 一共有 (2*N+2) 个标签，如下图所示。\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/f984664777b241a9b43ef843c9b752f33906c8916bc146a69f7270b5858bee63\" width=\"500\" height=\"400\" alt=\"标注策略\" align=center />\n",
    "</div>\n",
    "\n",
    "### 评价方法\n",
    "\n",
    "对测试集上参评系统输出的SPO结果和人工标注的SPO结果进行精准匹配，采用F1值作为评价指标。注意，对于复杂O值类型的SPO，必须所有槽位都精确匹配才认为该SPO抽取正确。针对部分文本中存在实体别名的问题，使用百度知识图谱的别名词典来辅助评测。F1值的计算方式如下：\n",
    "\n",
    "F1 = (2 * P * R) / (P + R)，其中\n",
    "\n",
    "- P = 测试集所有句子中预测正确的SPO个数 / 测试集所有句子中预测出的SPO个数\n",
    "- R = 测试集所有句子中预测正确的SPO个数 / 测试集所有句子中人工标注的SPO个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step1：构建模型\n",
    "\n",
    "该任务可以看作一个序列标注任务，所以基线模型采用的是ERNIE序列标注模型。\n",
    "\n",
    "**PaddleNLP提供了ERNIE预训练模型常用序列标注模型，可以通过指定模型名字完成一键加载。PaddleNLP为了方便用户处理数据，内置了对于各个预训练模型对应的Tokenizer，可以完成文本token化，转token ID，文本长度截断等操作。**\n",
    "\n",
    "文本数据处理直接调用tokenizer即可输出模型所需输入数据。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-14 12:51:00,208] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-gram-zh\n",
      "[2021-06-14 12:51:00,211] [    INFO] - Downloading ernie_gram_zh.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/ernie_gram_zh.pdparams\n",
      "100%|██████████| 583566/583566 [00:15<00:00, 38382.83it/s]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "[2021-06-14 12:51:25,475] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_gram_zh/vocab.txt\n",
      "100%|██████████| 78/78 [00:00<00:00, 3079.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import paddle\n",
    "from paddlenlp.transformers import ErnieGramTokenizer\n",
    "from paddlenlp.transformers import ErnieGramForTokenClassification\n",
    "\n",
    "\n",
    "label_map_path = os.path.join('data', \"predicate2id.json\")\n",
    "\n",
    "if not (os.path.exists(label_map_path) and os.path.isfile(label_map_path)):\n",
    "    sys.exit(\"{} dose not exists or is not a file.\".format(label_map_path))\n",
    "with open(label_map_path, 'r', encoding='utf8') as fp:\n",
    "    label_map = json.load(fp)\n",
    "    \n",
    "num_classes = (len(label_map.keys()) - 2) * 2 + 2\n",
    "\n",
    "# 补齐代码，理解TokenClassification接口含义，理解关系抽取标注体系和类别数由来\n",
    "model = ErnieGramForTokenClassification.from_pretrained('ernie-gram-zh', num_classes=num_classes)\n",
    "tokenizer = ErnieGramTokenizer.from_pretrained(\"ernie-gram-zh\")\n",
    "\n",
    "inputs = tokenizer(text=\"请输入测试样例\", max_seq_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step2：加载并处理数据\n",
    "\n",
    "\n",
    "从比赛官网下载数据集，解压存放于data/目录下并重命名为train_data.json, dev_data.json, test_data.json.\n",
    "\n",
    "我们可以加载自定义数据集。通过继承[`paddle.io.Dataset`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/Dataset_cn.html#dataset)，自定义实现`__getitem__` 和 `__len__`两个方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from tqdm import tqdm\n",
    "from paddlenlp.utils.log import logger\n",
    "\n",
    "from data_loader import DataCollator\n",
    "from data_loader import convert_example_to_feature\n",
    "from data_loader import parse_label\n",
    "from extract_chinese_and_punct import ChineseAndPunctuationExtractor\n",
    "\n",
    "\n",
    "class DuIEDataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of DuIE.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_ids: List[Union[List[int], np.ndarray]],\n",
    "            seq_lens: List[Union[List[int], np.ndarray]],\n",
    "            tok_to_orig_start_index: List[Union[List[int], np.ndarray]],\n",
    "            tok_to_orig_end_index: List[Union[List[int], np.ndarray]],\n",
    "            labels: List[Union[List[int], np.ndarray, List[str], List[Dict]]]):\n",
    "        super(DuIEDataset, self).__init__()\n",
    "\n",
    "        self.input_ids = input_ids\n",
    "        self.seq_lens = seq_lens\n",
    "        self.tok_to_orig_start_index = tok_to_orig_start_index\n",
    "        self.tok_to_orig_end_index = tok_to_orig_end_index\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        if isinstance(self.input_ids, np.ndarray):\n",
    "            return self.input_ids.shape[0]\n",
    "        else:\n",
    "            return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"input_ids\": np.array(self.input_ids[item]),\n",
    "            \"seq_lens\": np.array(self.seq_lens[item]),\n",
    "            \"tok_to_orig_start_index\":\n",
    "            np.array(self.tok_to_orig_start_index[item]),\n",
    "            \"tok_to_orig_end_index\": np.array(self.tok_to_orig_end_index[item]),\n",
    "            # If model inputs is generated in `collate_fn`, delete the data type casting.\n",
    "            \"labels\": np.array(\n",
    "                self.labels[item], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls,\n",
    "                  file_path: Union[str, os.PathLike],\n",
    "                  tokenizer: ErnieGramTokenizer,\n",
    "                  max_length: Optional[int]=512,\n",
    "                  pad_to_max_length: Optional[bool]=None):\n",
    "        \n",
    "        assert os.path.exists(file_path) and os.path.isfile(\n",
    "            file_path), f\"{file_path} dose not exists or is not a file.\"\n",
    "        label_map_path = os.path.join(os.path.dirname(file_path), \"predicate2id.json\")\n",
    "        assert os.path.exists(label_map_path) and os.path.isfile(\n",
    "            label_map_path), f\"{label_map_path} dose not exists or is not a file.\"\n",
    "        with open(label_map_path, 'r', encoding='utf8') as fp:\n",
    "            label_map = json.load(fp)\n",
    "        \n",
    "        chineseandpunctuationextractor = ChineseAndPunctuationExtractor()\n",
    "\n",
    "        input_ids, seq_lens, \\\n",
    "        tok_to_orig_start_index, \\\n",
    "        tok_to_orig_end_index, labels = ([] for _ in range(5))\n",
    "\n",
    "        dataset_scale = sum(1 for line in open(file_path, 'r'))\n",
    "        logger.info(\"Preprocessing data, loaded from %s\" % file_path)\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "            lines = fp.readlines()\n",
    "            for line in tqdm(lines):\n",
    "                example = json.loads(line)\n",
    "                input_feature = convert_example_to_feature(\n",
    "                    example=example, \n",
    "                    tokenizer=tokenizer, \n",
    "                    chineseandpunctuationextractor=chineseandpunctuationextractor,\n",
    "                    label_map=label_map, \n",
    "                    max_length=max_length, \n",
    "                    pad_to_max_length=pad_to_max_length\n",
    "                )\n",
    "                input_ids.append(input_feature.input_ids)\n",
    "                seq_lens.append(input_feature.seq_len)\n",
    "                tok_to_orig_start_index.append(\n",
    "                    input_feature.tok_to_orig_start_index\n",
    "                )\n",
    "                tok_to_orig_end_index.append(\n",
    "                    input_feature.tok_to_orig_end_index\n",
    "                )\n",
    "                labels.append(input_feature.labels)\n",
    "\n",
    "        return cls(\n",
    "            input_ids, \n",
    "            seq_lens, \n",
    "            tok_to_orig_start_index,\n",
    "            tok_to_orig_end_index, labels\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-14 12:52:28,550] [    INFO] - Preprocessing data, loaded from data/train.json\n",
      "100%|██████████| 171293/171293 [05:16<00:00, 540.79it/s]\n",
      "[2021-06-14 12:57:45,740] [    INFO] - Preprocessing data, loaded from data/dev.json\n",
      "100%|██████████| 20674/20674 [00:37<00:00, 548.41it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "\n",
    "# train Dataset\n",
    "train_file_path = os.path.join(data_path, 'train.json')\n",
    "train_dataset = DuIEDataset.from_file(\n",
    "    file_path=train_file_path, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=max_seq_length, \n",
    "    pad_to_max_length=True\n",
    ")\n",
    "# train BatchSampler\n",
    "train_batch_sampler = paddle.io.BatchSampler(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    drop_last=True\n",
    ")\n",
    "# train DataLoader\n",
    "collator = DataCollator()\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    collate_fn=collator\n",
    ")\n",
    "\n",
    "# dev Dataset\n",
    "eval_file_path = os.path.join(data_path, 'dev.json')\n",
    "test_dataset = DuIEDataset.from_file(\n",
    "    file_path=eval_file_path, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=max_seq_length, \n",
    "    pad_to_max_length=True\n",
    ")\n",
    "# dev BatchSampler\n",
    "test_batch_sampler = paddle.io.BatchSampler(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    drop_last=True\n",
    ")\n",
    "# dev DataLoader\n",
    "test_data_loader = paddle.io.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    collate_fn=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step3：定义损失函数和优化器，开始训练\n",
    "\n",
    "我们选择均方误差作为损失函数，使用[`paddle.optimizer.AdamW`](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/adamw/AdamW_cn.html#adamw)作为优化器。\n",
    "\n",
    "\n",
    "\n",
    "在训练过程中，模型保存在当前目录checkpoints文件夹下。同时在训练的同时使用官方评测脚本进行评估，输出P/R/F1指标。\n",
    "在验证集上F1可以达到69.42。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\n",
    "\n",
    "class BCELossForDuIE(nn.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(BCELossForDuIE, self).__init__()\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, labels, mask):\n",
    "        loss = self.criterion(logits, labels)\n",
    "        mask = paddle.cast(mask, 'float32')\n",
    "        loss = loss * mask.unsqueeze(-1)\n",
    "        loss = paddle.sum(loss.mean(axis=2), axis=1) / paddle.sum(mask, axis=1)\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import decoding\n",
    "from utils import get_precision_recall_f1\n",
    "from utils import write_prediction_results\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, data_loader, file_path, mode):\n",
    "    \"\"\"\n",
    "    mode eval:\n",
    "    eval on development set and compute P/R/F1, called between training.\n",
    "    mode predict:\n",
    "    eval on development / test set, then write predictions to \\\n",
    "        predict_test.json and predict_test.json.zip \\\n",
    "        under /home/aistudio/relation_extraction/data dir for later submission or evaluation.\n",
    "    \"\"\"\n",
    "    example_all = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        for line in fp:\n",
    "            example_all.append(json.loads(line))\n",
    "    \n",
    "    id2spo_path = os.path.join(os.path.dirname(file_path), \"id2spo.json\")\n",
    "    with open(id2spo_path, 'r', encoding='utf8') as fp:\n",
    "        id2spo = json.load(fp)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_all = 0\n",
    "    eval_steps = 0\n",
    "    formatted_outputs = []\n",
    "    current_idx = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        \n",
    "        eval_steps += 1\n",
    "\n",
    "        input_ids, seq_len, \\\n",
    "        tok_to_orig_start_index, \\\n",
    "        tok_to_orig_end_index, labels = batch\n",
    "\n",
    "        logits = model(input_ids=input_ids)\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and((input_ids != 2))\n",
    "        loss = criterion(logits, labels, mask)\n",
    "        loss_all += loss.numpy().item()\n",
    "\n",
    "        probs = F.sigmoid(logits)\n",
    "        logits_batch = probs.numpy()\n",
    "\n",
    "        seq_len_batch = seq_len.numpy()\n",
    "        tok_to_orig_start_index_batch = tok_to_orig_start_index.numpy()\n",
    "        tok_to_orig_end_index_batch = tok_to_orig_end_index.numpy()\n",
    "\n",
    "        formatted_outputs.extend(\n",
    "            decoding(\n",
    "                example_all[current_idx: current_idx+len(logits)],\n",
    "                id2spo,\n",
    "                logits_batch,\n",
    "                seq_len_batch,\n",
    "                tok_to_orig_start_index_batch,\n",
    "                tok_to_orig_end_index_batch\n",
    "            )\n",
    "        )\n",
    "        current_idx = current_idx+len(logits)\n",
    "        \n",
    "    loss_avg = loss_all / eval_steps\n",
    "    print(\"eval loss: %f\" % (loss_avg))\n",
    "\n",
    "    if mode == \"predict\":\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predictions.json')\n",
    "    else:\n",
    "        predict_file_path = os.path.join(\"/home/aistudio/relation_extraction/data\", 'predict_eval.json')\n",
    "\n",
    "    predict_zipfile_path = write_prediction_results(formatted_outputs, predict_file_path)\n",
    "\n",
    "    if mode == \"eval\":\n",
    "        precision, recall, f1 = get_precision_recall_f1(file_path, predict_zipfile_path)\n",
    "        os.system('rm {} {}'.format(predict_file_path, predict_zipfile_path))\n",
    "        return precision, recall, f1\n",
    "    elif mode != \"predict\":\n",
    "        raise Exception(\"wrong mode for eval func\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "\n",
    "learning_rate = 2e-5\n",
    "num_train_epochs = 12\n",
    "warmup_ratio = 0.06\n",
    "\n",
    "# Loss\n",
    "criterion = BCELossForDuIE()\n",
    "\n",
    "# Defines learning rate strategy.\n",
    "steps_by_epoch = len(train_data_loader)\n",
    "num_training_steps = steps_by_epoch * num_train_epochs\n",
    "# Learning rate Scheduler\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_ratio)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型参数保存路径\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step4：提交预测结果\n",
    "\n",
    "加载训练保存的模型加载后进行预测。\n",
    "\n",
    "**NOTE:** 注意设置用于预测的模型参数路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====start training of 0 epochs=====\n",
      "epoch: 0 / 12, steps: 0 / 5352, loss: 0.744464, speed: 202.94 step/s\n",
      "epoch: 0 / 12, steps: 200 / 5352, loss: 0.508270, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 300 / 5352, loss: 0.313107, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 400 / 5352, loss: 0.236216, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 500 / 5352, loss: 0.196758, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 600 / 5352, loss: 0.168844, speed: 4.11 step/s\n",
      "epoch: 0 / 12, steps: 700 / 5352, loss: 0.144960, speed: 4.10 step/s\n",
      "epoch: 0 / 12, steps: 800 / 5352, loss: 0.123290, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 900 / 5352, loss: 0.103853, speed: 4.08 step/s\n",
      "epoch: 0 / 12, steps: 1000 / 5352, loss: 0.089236, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 1100 / 5352, loss: 0.077180, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 1200 / 5352, loss: 0.065765, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 1300 / 5352, loss: 0.056916, speed: 4.11 step/s\n",
      "epoch: 0 / 12, steps: 1400 / 5352, loss: 0.048526, speed: 4.10 step/s\n",
      "epoch: 0 / 12, steps: 1500 / 5352, loss: 0.042865, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 1600 / 5352, loss: 0.037011, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 1700 / 5352, loss: 0.033190, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 1800 / 5352, loss: 0.030878, speed: 4.15 step/s\n",
      "epoch: 0 / 12, steps: 1900 / 5352, loss: 0.026755, speed: 4.09 step/s\n",
      "epoch: 0 / 12, steps: 2000 / 5352, loss: 0.026216, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 2100 / 5352, loss: 0.021675, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 2300 / 5352, loss: 0.017549, speed: 4.09 step/s\n",
      "epoch: 0 / 12, steps: 2400 / 5352, loss: 0.016270, speed: 4.09 step/s\n",
      "epoch: 0 / 12, steps: 2500 / 5352, loss: 0.015788, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 2600 / 5352, loss: 0.012700, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 2800 / 5352, loss: 0.010806, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 2900 / 5352, loss: 0.009824, speed: 4.15 step/s\n",
      "epoch: 0 / 12, steps: 3000 / 5352, loss: 0.009190, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 3100 / 5352, loss: 0.011935, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 3200 / 5352, loss: 0.009524, speed: 4.15 step/s\n",
      "epoch: 0 / 12, steps: 3300 / 5352, loss: 0.008839, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 3400 / 5352, loss: 0.007985, speed: 4.14 step/s\n",
      "epoch: 0 / 12, steps: 3500 / 5352, loss: 0.007390, speed: 4.11 step/s\n",
      "epoch: 0 / 12, steps: 3600 / 5352, loss: 0.005879, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 3700 / 5352, loss: 0.006303, speed: 4.10 step/s\n",
      "epoch: 0 / 12, steps: 3800 / 5352, loss: 0.006097, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 3900 / 5352, loss: 0.005597, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 4000 / 5352, loss: 0.006989, speed: 4.08 step/s\n",
      "epoch: 0 / 12, steps: 4100 / 5352, loss: 0.006564, speed: 4.12 step/s\n",
      "epoch: 0 / 12, steps: 4200 / 5352, loss: 0.005810, speed: 4.11 step/s\n",
      "epoch: 0 / 12, steps: 4300 / 5352, loss: 0.004944, speed: 4.08 step/s\n",
      "epoch: 0 / 12, steps: 4400 / 5352, loss: 0.005449, speed: 4.15 step/s\n",
      "epoch: 0 / 12, steps: 4500 / 5352, loss: 0.005357, speed: 4.15 step/s\n",
      "epoch: 0 / 12, steps: 4600 / 5352, loss: 0.004456, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 4700 / 5352, loss: 0.006276, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 4800 / 5352, loss: 0.004672, speed: 4.16 step/s\n",
      "epoch: 0 / 12, steps: 4900 / 5352, loss: 0.004101, speed: 4.17 step/s\n",
      "epoch: 0 / 12, steps: 5000 / 5352, loss: 0.004148, speed: 4.16 step/s\n",
      "\n",
      "=====start evaluating ckpt of 5000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.004111\n",
      "precision: 60.04\t recall: 35.59\t f1: 44.69\t\n",
      "saving checkpoing model_5000.pdparams to checkpoints \n",
      "epoch: 0 / 12, steps: 5100 / 5352, loss: 0.005252, speed: 1.07 step/s\n",
      "epoch: 0 / 12, steps: 5200 / 5352, loss: 0.004375, speed: 4.13 step/s\n",
      "epoch: 0 / 12, steps: 5300 / 5352, loss: 0.004112, speed: 4.05 step/s\n",
      "epoch time footprint: 0 hour 22 min 47 sec\n",
      "\n",
      "=====start training of 1 epochs=====\n",
      "epoch: 1 / 12, steps: 48 / 5352, loss: 0.006314, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 148 / 5352, loss: 0.003308, speed: 4.00 step/s\n",
      "epoch: 1 / 12, steps: 248 / 5352, loss: 0.003674, speed: 4.13 step/s\n",
      "epoch: 1 / 12, steps: 348 / 5352, loss: 0.003547, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 448 / 5352, loss: 0.003775, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 548 / 5352, loss: 0.003131, speed: 4.15 step/s\n",
      "epoch: 1 / 12, steps: 648 / 5352, loss: 0.004093, speed: 4.09 step/s\n",
      "epoch: 1 / 12, steps: 748 / 5352, loss: 0.003733, speed: 4.13 step/s\n",
      "epoch: 1 / 12, steps: 848 / 5352, loss: 0.003262, speed: 4.15 step/s\n",
      "epoch: 1 / 12, steps: 948 / 5352, loss: 0.002918, speed: 4.15 step/s\n",
      "epoch: 1 / 12, steps: 1048 / 5352, loss: 0.004005, speed: 4.12 step/s\n",
      "epoch: 1 / 12, steps: 1148 / 5352, loss: 0.003207, speed: 4.12 step/s\n",
      "epoch: 1 / 12, steps: 1248 / 5352, loss: 0.003303, speed: 4.13 step/s\n",
      "epoch: 1 / 12, steps: 1348 / 5352, loss: 0.003035, speed: 4.14 step/s\n",
      "epoch: 1 / 12, steps: 1448 / 5352, loss: 0.003234, speed: 4.15 step/s\n",
      "epoch: 1 / 12, steps: 1548 / 5352, loss: 0.002940, speed: 4.14 step/s\n",
      "epoch: 1 / 12, steps: 1648 / 5352, loss: 0.003435, speed: 4.14 step/s\n",
      "epoch: 1 / 12, steps: 1748 / 5352, loss: 0.003842, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 1848 / 5352, loss: 0.003332, speed: 4.09 step/s\n",
      "epoch: 1 / 12, steps: 1948 / 5352, loss: 0.004088, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 2048 / 5352, loss: 0.002940, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 2148 / 5352, loss: 0.003323, speed: 4.06 step/s\n",
      "epoch: 1 / 12, steps: 2248 / 5352, loss: 0.003788, speed: 4.04 step/s\n",
      "epoch: 1 / 12, steps: 2348 / 5352, loss: 0.003225, speed: 4.08 step/s\n",
      "epoch: 1 / 12, steps: 2448 / 5352, loss: 0.002914, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 2548 / 5352, loss: 0.003756, speed: 4.08 step/s\n",
      "epoch: 1 / 12, steps: 2648 / 5352, loss: 0.002668, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 2748 / 5352, loss: 0.002312, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 2848 / 5352, loss: 0.003334, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 2948 / 5352, loss: 0.002723, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 3048 / 5352, loss: 0.002860, speed: 4.06 step/s\n",
      "epoch: 1 / 12, steps: 3148 / 5352, loss: 0.002161, speed: 4.03 step/s\n",
      "epoch: 1 / 12, steps: 3248 / 5352, loss: 0.002427, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 3348 / 5352, loss: 0.002926, speed: 4.05 step/s\n",
      "epoch: 1 / 12, steps: 3448 / 5352, loss: 0.003218, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 3548 / 5352, loss: 0.002522, speed: 4.06 step/s\n",
      "epoch: 1 / 12, steps: 3648 / 5352, loss: 0.003414, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 3748 / 5352, loss: 0.002417, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 3848 / 5352, loss: 0.002470, speed: 4.08 step/s\n",
      "epoch: 1 / 12, steps: 3948 / 5352, loss: 0.001926, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 4048 / 5352, loss: 0.002475, speed: 4.09 step/s\n",
      "epoch: 1 / 12, steps: 4148 / 5352, loss: 0.003542, speed: 4.08 step/s\n",
      "epoch: 1 / 12, steps: 4248 / 5352, loss: 0.003158, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 4348 / 5352, loss: 0.004400, speed: 4.09 step/s\n",
      "epoch: 1 / 12, steps: 4448 / 5352, loss: 0.002425, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 4548 / 5352, loss: 0.002380, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 4648 / 5352, loss: 0.002673, speed: 4.08 step/s\n",
      "\n",
      "=====start evaluating ckpt of 10000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:00<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002381\n",
      "precision: 64.60\t recall: 63.21\t f1: 63.90\t\n",
      "saving checkpoing model_10000.pdparams to checkpoints \n",
      "epoch: 1 / 12, steps: 4748 / 5352, loss: 0.002981, speed: 1.05 step/s\n",
      "epoch: 1 / 12, steps: 4848 / 5352, loss: 0.002436, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 4948 / 5352, loss: 0.002184, speed: 4.11 step/s\n",
      "epoch: 1 / 12, steps: 5048 / 5352, loss: 0.002903, speed: 4.10 step/s\n",
      "epoch: 1 / 12, steps: 5148 / 5352, loss: 0.002977, speed: 4.07 step/s\n",
      "epoch: 1 / 12, steps: 5248 / 5352, loss: 0.003068, speed: 4.04 step/s\n",
      "epoch: 1 / 12, steps: 5348 / 5352, loss: 0.003506, speed: 4.03 step/s\n",
      "epoch time footprint: 0 hour 22 min 58 sec\n",
      "\n",
      "=====start training of 2 epochs=====\n",
      "epoch: 2 / 12, steps: 96 / 5352, loss: 0.002204, speed: 4.06 step/s\n",
      "epoch: 2 / 12, steps: 196 / 5352, loss: 0.002520, speed: 4.06 step/s\n",
      "epoch: 2 / 12, steps: 296 / 5352, loss: 0.001738, speed: 4.02 step/s\n",
      "epoch: 2 / 12, steps: 396 / 5352, loss: 0.001697, speed: 4.02 step/s\n",
      "epoch: 2 / 12, steps: 496 / 5352, loss: 0.002552, speed: 4.05 step/s\n",
      "epoch: 2 / 12, steps: 596 / 5352, loss: 0.002610, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 696 / 5352, loss: 0.002472, speed: 4.01 step/s\n",
      "epoch: 2 / 12, steps: 796 / 5352, loss: 0.001586, speed: 3.99 step/s\n",
      "epoch: 2 / 12, steps: 896 / 5352, loss: 0.002956, speed: 3.98 step/s\n",
      "epoch: 2 / 12, steps: 996 / 5352, loss: 0.002575, speed: 3.98 step/s\n",
      "epoch: 2 / 12, steps: 1096 / 5352, loss: 0.002651, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 1196 / 5352, loss: 0.003051, speed: 3.99 step/s\n",
      "epoch: 2 / 12, steps: 1296 / 5352, loss: 0.001593, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 1396 / 5352, loss: 0.002031, speed: 3.98 step/s\n",
      "epoch: 2 / 12, steps: 1496 / 5352, loss: 0.002013, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 1596 / 5352, loss: 0.001706, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 1696 / 5352, loss: 0.002749, speed: 4.00 step/s\n",
      "epoch: 2 / 12, steps: 1796 / 5352, loss: 0.002426, speed: 3.98 step/s\n",
      "epoch: 2 / 12, steps: 1896 / 5352, loss: 0.002857, speed: 4.03 step/s\n",
      "epoch: 2 / 12, steps: 1996 / 5352, loss: 0.002544, speed: 4.04 step/s\n",
      "epoch: 2 / 12, steps: 2096 / 5352, loss: 0.001830, speed: 4.03 step/s\n",
      "epoch: 2 / 12, steps: 2196 / 5352, loss: 0.001984, speed: 4.04 step/s\n",
      "epoch: 2 / 12, steps: 2296 / 5352, loss: 0.001997, speed: 4.02 step/s\n",
      "epoch: 2 / 12, steps: 2396 / 5352, loss: 0.002849, speed: 4.08 step/s\n",
      "epoch: 2 / 12, steps: 2496 / 5352, loss: 0.002599, speed: 4.12 step/s\n",
      "epoch: 2 / 12, steps: 2596 / 5352, loss: 0.002160, speed: 4.12 step/s\n",
      "epoch: 2 / 12, steps: 2696 / 5352, loss: 0.002495, speed: 4.13 step/s\n",
      "epoch: 2 / 12, steps: 2796 / 5352, loss: 0.001851, speed: 4.14 step/s\n",
      "epoch: 2 / 12, steps: 2896 / 5352, loss: 0.002129, speed: 4.15 step/s\n",
      "epoch: 2 / 12, steps: 2996 / 5352, loss: 0.002362, speed: 4.16 step/s\n",
      "epoch: 2 / 12, steps: 3096 / 5352, loss: 0.001815, speed: 4.13 step/s\n",
      "epoch: 2 / 12, steps: 3196 / 5352, loss: 0.002659, speed: 4.14 step/s\n",
      "epoch: 2 / 12, steps: 3296 / 5352, loss: 0.002589, speed: 4.13 step/s\n",
      "epoch: 2 / 12, steps: 3396 / 5352, loss: 0.002691, speed: 4.12 step/s\n",
      "epoch: 2 / 12, steps: 3496 / 5352, loss: 0.002137, speed: 4.15 step/s\n",
      "epoch: 2 / 12, steps: 3596 / 5352, loss: 0.001579, speed: 4.10 step/s\n",
      "epoch: 2 / 12, steps: 3696 / 5352, loss: 0.002222, speed: 4.16 step/s\n",
      "epoch: 2 / 12, steps: 3796 / 5352, loss: 0.002078, speed: 4.10 step/s\n",
      "epoch: 2 / 12, steps: 3896 / 5352, loss: 0.001870, speed: 4.11 step/s\n",
      "epoch: 2 / 12, steps: 3996 / 5352, loss: 0.001924, speed: 4.11 step/s\n",
      "epoch: 2 / 12, steps: 4096 / 5352, loss: 0.002438, speed: 4.12 step/s\n",
      "epoch: 2 / 12, steps: 4196 / 5352, loss: 0.002235, speed: 4.10 step/s\n",
      "epoch: 2 / 12, steps: 4296 / 5352, loss: 0.001717, speed: 4.10 step/s\n",
      "\n",
      "=====start evaluating ckpt of 15000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002238\n",
      "precision: 61.74\t recall: 70.87\t f1: 65.99\t\n",
      "saving checkpoing model_15000.pdparams to checkpoints \n",
      "epoch: 2 / 12, steps: 4396 / 5352, loss: 0.002477, speed: 1.05 step/s\n",
      "epoch: 2 / 12, steps: 4496 / 5352, loss: 0.003344, speed: 4.08 step/s\n",
      "epoch: 2 / 12, steps: 4596 / 5352, loss: 0.001533, speed: 4.10 step/s\n",
      "epoch: 2 / 12, steps: 4696 / 5352, loss: 0.002968, speed: 4.10 step/s\n",
      "epoch: 2 / 12, steps: 4796 / 5352, loss: 0.002064, speed: 4.09 step/s\n",
      "epoch: 2 / 12, steps: 4896 / 5352, loss: 0.001616, speed: 4.09 step/s\n",
      "epoch: 2 / 12, steps: 4996 / 5352, loss: 0.001847, speed: 4.07 step/s\n",
      "epoch: 2 / 12, steps: 5096 / 5352, loss: 0.002440, speed: 4.09 step/s\n",
      "epoch: 2 / 12, steps: 5196 / 5352, loss: 0.002296, speed: 4.09 step/s\n",
      "epoch: 2 / 12, steps: 5296 / 5352, loss: 0.003625, speed: 4.11 step/s\n",
      "epoch time footprint: 0 hour 23 min 6 sec\n",
      "\n",
      "=====start training of 3 epochs=====\n",
      "epoch: 3 / 12, steps: 44 / 5352, loss: 0.001991, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 144 / 5352, loss: 0.001395, speed: 4.09 step/s\n",
      "epoch: 3 / 12, steps: 244 / 5352, loss: 0.002332, speed: 4.07 step/s\n",
      "epoch: 3 / 12, steps: 344 / 5352, loss: 0.001773, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 444 / 5352, loss: 0.002169, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 544 / 5352, loss: 0.001504, speed: 4.11 step/s\n",
      "epoch: 3 / 12, steps: 644 / 5352, loss: 0.001280, speed: 4.13 step/s\n",
      "epoch: 3 / 12, steps: 744 / 5352, loss: 0.002066, speed: 4.11 step/s\n",
      "epoch: 3 / 12, steps: 844 / 5352, loss: 0.002143, speed: 4.06 step/s\n",
      "epoch: 3 / 12, steps: 944 / 5352, loss: 0.001489, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 1044 / 5352, loss: 0.002392, speed: 4.11 step/s\n",
      "epoch: 3 / 12, steps: 1144 / 5352, loss: 0.001757, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 1244 / 5352, loss: 0.001730, speed: 4.05 step/s\n",
      "epoch: 3 / 12, steps: 1344 / 5352, loss: 0.003322, speed: 4.06 step/s\n",
      "epoch: 3 / 12, steps: 1444 / 5352, loss: 0.002626, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 1544 / 5352, loss: 0.002162, speed: 4.09 step/s\n",
      "epoch: 3 / 12, steps: 1644 / 5352, loss: 0.001486, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 1744 / 5352, loss: 0.001375, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 1844 / 5352, loss: 0.002414, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 1944 / 5352, loss: 0.001590, speed: 4.00 step/s\n",
      "epoch: 3 / 12, steps: 2044 / 5352, loss: 0.002234, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 2144 / 5352, loss: 0.001549, speed: 4.00 step/s\n",
      "epoch: 3 / 12, steps: 2244 / 5352, loss: 0.002884, speed: 4.04 step/s\n",
      "epoch: 3 / 12, steps: 2344 / 5352, loss: 0.003085, speed: 4.02 step/s\n",
      "epoch: 3 / 12, steps: 2444 / 5352, loss: 0.001248, speed: 4.02 step/s\n",
      "epoch: 3 / 12, steps: 2544 / 5352, loss: 0.002296, speed: 4.02 step/s\n",
      "epoch: 3 / 12, steps: 2644 / 5352, loss: 0.002652, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 2744 / 5352, loss: 0.001423, speed: 4.04 step/s\n",
      "epoch: 3 / 12, steps: 2844 / 5352, loss: 0.001894, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 2944 / 5352, loss: 0.002496, speed: 4.00 step/s\n",
      "epoch: 3 / 12, steps: 3044 / 5352, loss: 0.001500, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 3144 / 5352, loss: 0.001735, speed: 4.04 step/s\n",
      "epoch: 3 / 12, steps: 3244 / 5352, loss: 0.001238, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 3344 / 5352, loss: 0.002005, speed: 4.07 step/s\n",
      "epoch: 3 / 12, steps: 3444 / 5352, loss: 0.001819, speed: 4.09 step/s\n",
      "epoch: 3 / 12, steps: 3544 / 5352, loss: 0.002246, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 3644 / 5352, loss: 0.001258, speed: 4.09 step/s\n",
      "epoch: 3 / 12, steps: 3744 / 5352, loss: 0.002200, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 3844 / 5352, loss: 0.001809, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 3944 / 5352, loss: 0.001377, speed: 4.09 step/s\n",
      "\n",
      "=====start evaluating ckpt of 20000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002223\n",
      "precision: 56.64\t recall: 75.31\t f1: 64.65\t\n",
      "saving checkpoing model_20000.pdparams to checkpoints \n",
      "epoch: 3 / 12, steps: 4044 / 5352, loss: 0.001771, speed: 1.04 step/s\n",
      "epoch: 3 / 12, steps: 4144 / 5352, loss: 0.001909, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 4244 / 5352, loss: 0.001293, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 4344 / 5352, loss: 0.001260, speed: 4.01 step/s\n",
      "epoch: 3 / 12, steps: 4444 / 5352, loss: 0.001909, speed: 4.03 step/s\n",
      "epoch: 3 / 12, steps: 4544 / 5352, loss: 0.001677, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 4644 / 5352, loss: 0.002507, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 4744 / 5352, loss: 0.002020, speed: 4.11 step/s\n",
      "epoch: 3 / 12, steps: 4844 / 5352, loss: 0.002141, speed: 4.15 step/s\n",
      "epoch: 3 / 12, steps: 4944 / 5352, loss: 0.001549, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 5044 / 5352, loss: 0.001560, speed: 4.08 step/s\n",
      "epoch: 3 / 12, steps: 5144 / 5352, loss: 0.001358, speed: 4.10 step/s\n",
      "epoch: 3 / 12, steps: 5244 / 5352, loss: 0.002891, speed: 4.14 step/s\n",
      "epoch: 3 / 12, steps: 5344 / 5352, loss: 0.001844, speed: 4.13 step/s\n",
      "epoch time footprint: 0 hour 23 min 8 sec\n",
      "\n",
      "=====start training of 4 epochs=====\n",
      "epoch: 4 / 12, steps: 92 / 5352, loss: 0.001910, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 192 / 5352, loss: 0.002229, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 292 / 5352, loss: 0.001417, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 392 / 5352, loss: 0.002087, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 492 / 5352, loss: 0.001125, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 592 / 5352, loss: 0.001512, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 692 / 5352, loss: 0.001024, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 792 / 5352, loss: 0.001483, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 892 / 5352, loss: 0.001114, speed: 4.08 step/s\n",
      "epoch: 4 / 12, steps: 992 / 5352, loss: 0.001331, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 1092 / 5352, loss: 0.001839, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 1192 / 5352, loss: 0.001661, speed: 4.09 step/s\n",
      "epoch: 4 / 12, steps: 1292 / 5352, loss: 0.001076, speed: 4.09 step/s\n",
      "epoch: 4 / 12, steps: 1392 / 5352, loss: 0.001423, speed: 4.11 step/s\n",
      "epoch: 4 / 12, steps: 1492 / 5352, loss: 0.001454, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 1592 / 5352, loss: 0.001460, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 1692 / 5352, loss: 0.001102, speed: 4.11 step/s\n",
      "epoch: 4 / 12, steps: 1792 / 5352, loss: 0.001747, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 1892 / 5352, loss: 0.001729, speed: 4.03 step/s\n",
      "epoch: 4 / 12, steps: 1992 / 5352, loss: 0.001753, speed: 4.05 step/s\n",
      "epoch: 4 / 12, steps: 2092 / 5352, loss: 0.001643, speed: 3.99 step/s\n",
      "epoch: 4 / 12, steps: 2192 / 5352, loss: 0.001446, speed: 4.03 step/s\n",
      "epoch: 4 / 12, steps: 2292 / 5352, loss: 0.002401, speed: 4.05 step/s\n",
      "epoch: 4 / 12, steps: 2392 / 5352, loss: 0.001513, speed: 4.04 step/s\n",
      "epoch: 4 / 12, steps: 2492 / 5352, loss: 0.002042, speed: 4.05 step/s\n",
      "epoch: 4 / 12, steps: 2592 / 5352, loss: 0.001525, speed: 4.04 step/s\n",
      "epoch: 4 / 12, steps: 2692 / 5352, loss: 0.001930, speed: 4.04 step/s\n",
      "epoch: 4 / 12, steps: 2792 / 5352, loss: 0.001855, speed: 4.03 step/s\n",
      "epoch: 4 / 12, steps: 2892 / 5352, loss: 0.001181, speed: 4.05 step/s\n",
      "epoch: 4 / 12, steps: 2992 / 5352, loss: 0.002521, speed: 4.05 step/s\n",
      "epoch: 4 / 12, steps: 3092 / 5352, loss: 0.001874, speed: 4.07 step/s\n",
      "epoch: 4 / 12, steps: 3192 / 5352, loss: 0.002532, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 3292 / 5352, loss: 0.001759, speed: 4.03 step/s\n",
      "epoch: 4 / 12, steps: 3392 / 5352, loss: 0.001688, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 3492 / 5352, loss: 0.001656, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 3592 / 5352, loss: 0.001413, speed: 4.12 step/s\n",
      "\n",
      "=====start evaluating ckpt of 25000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002097\n",
      "precision: 62.42\t recall: 72.18\t f1: 66.94\t\n",
      "saving checkpoing model_25000.pdparams to checkpoints \n",
      "epoch: 4 / 12, steps: 3692 / 5352, loss: 0.001687, speed: 1.03 step/s\n",
      "epoch: 4 / 12, steps: 3792 / 5352, loss: 0.001492, speed: 4.09 step/s\n",
      "epoch: 4 / 12, steps: 3892 / 5352, loss: 0.001914, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 3992 / 5352, loss: 0.001211, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 4092 / 5352, loss: 0.001887, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 4192 / 5352, loss: 0.001293, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 4292 / 5352, loss: 0.001368, speed: 4.11 step/s\n",
      "epoch: 4 / 12, steps: 4392 / 5352, loss: 0.001580, speed: 4.13 step/s\n",
      "epoch: 4 / 12, steps: 4492 / 5352, loss: 0.001692, speed: 4.11 step/s\n",
      "epoch: 4 / 12, steps: 4592 / 5352, loss: 0.002473, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 4692 / 5352, loss: 0.001635, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 4792 / 5352, loss: 0.001872, speed: 4.14 step/s\n",
      "epoch: 4 / 12, steps: 4892 / 5352, loss: 0.001392, speed: 4.16 step/s\n",
      "epoch: 4 / 12, steps: 4992 / 5352, loss: 0.001937, speed: 4.12 step/s\n",
      "epoch: 4 / 12, steps: 5092 / 5352, loss: 0.001969, speed: 4.15 step/s\n",
      "epoch: 4 / 12, steps: 5192 / 5352, loss: 0.001330, speed: 4.10 step/s\n",
      "epoch: 4 / 12, steps: 5292 / 5352, loss: 0.001552, speed: 4.07 step/s\n",
      "epoch time footprint: 0 hour 22 min 59 sec\n",
      "\n",
      "=====start training of 5 epochs=====\n",
      "epoch: 5 / 12, steps: 40 / 5352, loss: 0.001594, speed: 4.08 step/s\n",
      "epoch: 5 / 12, steps: 140 / 5352, loss: 0.001903, speed: 4.05 step/s\n",
      "epoch: 5 / 12, steps: 240 / 5352, loss: 0.001406, speed: 4.09 step/s\n",
      "epoch: 5 / 12, steps: 340 / 5352, loss: 0.001153, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 440 / 5352, loss: 0.001137, speed: 4.08 step/s\n",
      "epoch: 5 / 12, steps: 540 / 5352, loss: 0.001178, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 640 / 5352, loss: 0.001390, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 840 / 5352, loss: 0.001440, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 940 / 5352, loss: 0.001172, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 1040 / 5352, loss: 0.001926, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 1140 / 5352, loss: 0.001904, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 1240 / 5352, loss: 0.001418, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 1340 / 5352, loss: 0.001227, speed: 4.05 step/s\n",
      "epoch: 5 / 12, steps: 1440 / 5352, loss: 0.002317, speed: 4.01 step/s\n",
      "epoch: 5 / 12, steps: 1540 / 5352, loss: 0.001417, speed: 4.02 step/s\n",
      "epoch: 5 / 12, steps: 1640 / 5352, loss: 0.002045, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 1740 / 5352, loss: 0.001197, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 1840 / 5352, loss: 0.001135, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 1940 / 5352, loss: 0.002233, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 2040 / 5352, loss: 0.001414, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 2140 / 5352, loss: 0.001130, speed: 4.09 step/s\n",
      "epoch: 5 / 12, steps: 2240 / 5352, loss: 0.001652, speed: 4.02 step/s\n",
      "epoch: 5 / 12, steps: 2340 / 5352, loss: 0.001415, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 2440 / 5352, loss: 0.001036, speed: 4.01 step/s\n",
      "epoch: 5 / 12, steps: 2540 / 5352, loss: 0.001245, speed: 4.02 step/s\n",
      "epoch: 5 / 12, steps: 2640 / 5352, loss: 0.001550, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 2740 / 5352, loss: 0.001546, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 2840 / 5352, loss: 0.001985, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 2940 / 5352, loss: 0.001354, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 3040 / 5352, loss: 0.001925, speed: 4.01 step/s\n",
      "epoch: 5 / 12, steps: 3140 / 5352, loss: 0.001400, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 3240 / 5352, loss: 0.001207, speed: 4.05 step/s\n",
      "\n",
      "=====start evaluating ckpt of 30000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002137\n",
      "precision: 62.20\t recall: 73.73\t f1: 67.48\t\n",
      "saving checkpoing model_30000.pdparams to checkpoints \n",
      "epoch: 5 / 12, steps: 3440 / 5352, loss: 0.001758, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 3540 / 5352, loss: 0.001161, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 3640 / 5352, loss: 0.001489, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 3740 / 5352, loss: 0.002413, speed: 4.05 step/s\n",
      "epoch: 5 / 12, steps: 3840 / 5352, loss: 0.001611, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 3940 / 5352, loss: 0.001594, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 4040 / 5352, loss: 0.001453, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 4140 / 5352, loss: 0.001401, speed: 4.06 step/s\n",
      "epoch: 5 / 12, steps: 4240 / 5352, loss: 0.001436, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 4340 / 5352, loss: 0.001072, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 4440 / 5352, loss: 0.002107, speed: 4.02 step/s\n",
      "epoch: 5 / 12, steps: 4540 / 5352, loss: 0.001223, speed: 4.05 step/s\n",
      "epoch: 5 / 12, steps: 4640 / 5352, loss: 0.002165, speed: 4.03 step/s\n",
      "epoch: 5 / 12, steps: 4740 / 5352, loss: 0.000959, speed: 4.08 step/s\n",
      "epoch: 5 / 12, steps: 4840 / 5352, loss: 0.001549, speed: 4.08 step/s\n",
      "epoch: 5 / 12, steps: 4940 / 5352, loss: 0.001237, speed: 4.07 step/s\n",
      "epoch: 5 / 12, steps: 5040 / 5352, loss: 0.001072, speed: 4.04 step/s\n",
      "epoch: 5 / 12, steps: 5140 / 5352, loss: 0.001117, speed: 4.09 step/s\n",
      "epoch: 5 / 12, steps: 5240 / 5352, loss: 0.001374, speed: 4.05 step/s\n",
      "epoch: 5 / 12, steps: 5340 / 5352, loss: 0.001850, speed: 4.07 step/s\n",
      "epoch time footprint: 0 hour 23 min 13 sec\n",
      "\n",
      "=====start training of 6 epochs=====\n",
      "epoch: 6 / 12, steps: 88 / 5352, loss: 0.001016, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 188 / 5352, loss: 0.000980, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 288 / 5352, loss: 0.002132, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 388 / 5352, loss: 0.001426, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 488 / 5352, loss: 0.000637, speed: 3.98 step/s\n",
      "epoch: 6 / 12, steps: 588 / 5352, loss: 0.001827, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 688 / 5352, loss: 0.001502, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 788 / 5352, loss: 0.001509, speed: 4.09 step/s\n",
      "epoch: 6 / 12, steps: 888 / 5352, loss: 0.000932, speed: 4.10 step/s\n",
      "epoch: 6 / 12, steps: 988 / 5352, loss: 0.001160, speed: 4.02 step/s\n",
      "epoch: 6 / 12, steps: 1088 / 5352, loss: 0.001275, speed: 4.08 step/s\n",
      "epoch: 6 / 12, steps: 1188 / 5352, loss: 0.001360, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 1288 / 5352, loss: 0.001704, speed: 4.09 step/s\n",
      "epoch: 6 / 12, steps: 1388 / 5352, loss: 0.001164, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 1488 / 5352, loss: 0.001271, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 1588 / 5352, loss: 0.001151, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 1688 / 5352, loss: 0.001527, speed: 4.08 step/s\n",
      "epoch: 6 / 12, steps: 1788 / 5352, loss: 0.001179, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 1888 / 5352, loss: 0.001597, speed: 4.10 step/s\n",
      "epoch: 6 / 12, steps: 1988 / 5352, loss: 0.000838, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 2088 / 5352, loss: 0.001017, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 2188 / 5352, loss: 0.001831, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 2288 / 5352, loss: 0.001103, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 2388 / 5352, loss: 0.001313, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 2588 / 5352, loss: 0.001623, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 2688 / 5352, loss: 0.001322, speed: 4.03 step/s\n",
      "epoch: 6 / 12, steps: 2788 / 5352, loss: 0.001039, speed: 4.02 step/s\n",
      "epoch: 6 / 12, steps: 2888 / 5352, loss: 0.001920, speed: 4.04 step/s\n",
      "\n",
      "=====start evaluating ckpt of 35000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002271\n",
      "precision: 60.82\t recall: 76.28\t f1: 67.68\t\n",
      "saving checkpoing model_35000.pdparams to checkpoints \n",
      "epoch: 6 / 12, steps: 2988 / 5352, loss: 0.001169, speed: 1.03 step/s\n",
      "epoch: 6 / 12, steps: 3088 / 5352, loss: 0.001444, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 3188 / 5352, loss: 0.001378, speed: 4.03 step/s\n",
      "epoch: 6 / 12, steps: 3288 / 5352, loss: 0.000606, speed: 4.05 step/s\n",
      "epoch: 6 / 12, steps: 3488 / 5352, loss: 0.001637, speed: 4.08 step/s\n",
      "epoch: 6 / 12, steps: 3588 / 5352, loss: 0.000640, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 3688 / 5352, loss: 0.001274, speed: 4.09 step/s\n",
      "epoch: 6 / 12, steps: 3788 / 5352, loss: 0.001535, speed: 4.08 step/s\n",
      "epoch: 6 / 12, steps: 3888 / 5352, loss: 0.001255, speed: 4.08 step/s\n",
      "epoch: 6 / 12, steps: 3988 / 5352, loss: 0.000838, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 4088 / 5352, loss: 0.001374, speed: 4.06 step/s\n",
      "epoch: 6 / 12, steps: 4188 / 5352, loss: 0.001600, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 4288 / 5352, loss: 0.001457, speed: 4.07 step/s\n",
      "epoch: 6 / 12, steps: 4388 / 5352, loss: 0.001112, speed: 4.02 step/s\n",
      "epoch: 6 / 12, steps: 4488 / 5352, loss: 0.001709, speed: 4.03 step/s\n",
      "epoch: 6 / 12, steps: 4588 / 5352, loss: 0.001556, speed: 4.03 step/s\n",
      "epoch: 6 / 12, steps: 4688 / 5352, loss: 0.001260, speed: 4.03 step/s\n",
      "epoch: 6 / 12, steps: 4788 / 5352, loss: 0.001612, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 4888 / 5352, loss: 0.001100, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 4988 / 5352, loss: 0.001314, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 5088 / 5352, loss: 0.001009, speed: 4.02 step/s\n",
      "epoch: 6 / 12, steps: 5188 / 5352, loss: 0.001796, speed: 4.04 step/s\n",
      "epoch: 6 / 12, steps: 5288 / 5352, loss: 0.001480, speed: 4.04 step/s\n",
      "epoch time footprint: 0 hour 23 min 12 sec\n",
      "\n",
      "=====start training of 7 epochs=====\n",
      "epoch: 7 / 12, steps: 36 / 5352, loss: 0.000876, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 136 / 5352, loss: 0.001147, speed: 4.04 step/s\n",
      "epoch: 7 / 12, steps: 236 / 5352, loss: 0.001609, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 336 / 5352, loss: 0.001103, speed: 4.03 step/s\n",
      "epoch: 7 / 12, steps: 436 / 5352, loss: 0.001140, speed: 4.08 step/s\n",
      "epoch: 7 / 12, steps: 536 / 5352, loss: 0.002245, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 636 / 5352, loss: 0.001162, speed: 4.09 step/s\n",
      "epoch: 7 / 12, steps: 736 / 5352, loss: 0.000766, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 836 / 5352, loss: 0.001576, speed: 4.07 step/s\n",
      "epoch: 7 / 12, steps: 936 / 5352, loss: 0.001396, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 1036 / 5352, loss: 0.001425, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 1136 / 5352, loss: 0.001283, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 1236 / 5352, loss: 0.000915, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 1336 / 5352, loss: 0.000871, speed: 4.07 step/s\n",
      "epoch: 7 / 12, steps: 1436 / 5352, loss: 0.001549, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 1536 / 5352, loss: 0.001052, speed: 4.05 step/s\n",
      "epoch: 7 / 12, steps: 1636 / 5352, loss: 0.000951, speed: 4.07 step/s\n",
      "epoch: 7 / 12, steps: 1736 / 5352, loss: 0.000977, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 1836 / 5352, loss: 0.001503, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 1936 / 5352, loss: 0.000942, speed: 4.06 step/s\n",
      "epoch: 7 / 12, steps: 2136 / 5352, loss: 0.001712, speed: 4.10 step/s\n",
      "epoch: 7 / 12, steps: 2236 / 5352, loss: 0.001392, speed: 4.10 step/s\n",
      "epoch: 7 / 12, steps: 2336 / 5352, loss: 0.001172, speed: 4.10 step/s\n",
      "epoch: 7 / 12, steps: 2436 / 5352, loss: 0.001493, speed: 4.11 step/s\n",
      "epoch: 7 / 12, steps: 2536 / 5352, loss: 0.001631, speed: 4.14 step/s\n",
      "\n",
      "=====start evaluating ckpt of 40000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:00<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002340\n",
      "precision: 60.74\t recall: 75.61\t f1: 67.37\t\n",
      "saving checkpoing model_40000.pdparams to checkpoints \n",
      "epoch: 7 / 12, steps: 2636 / 5352, loss: 0.000892, speed: 1.05 step/s\n",
      "epoch: 7 / 12, steps: 2736 / 5352, loss: 0.002022, speed: 4.13 step/s\n",
      "epoch: 7 / 12, steps: 2836 / 5352, loss: 0.001166, speed: 4.10 step/s\n",
      "epoch: 7 / 12, steps: 2936 / 5352, loss: 0.001355, speed: 4.15 step/s\n",
      "epoch: 7 / 12, steps: 3036 / 5352, loss: 0.001363, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 3136 / 5352, loss: 0.001914, speed: 4.11 step/s\n",
      "epoch: 7 / 12, steps: 3236 / 5352, loss: 0.000735, speed: 4.14 step/s\n",
      "epoch: 7 / 12, steps: 3336 / 5352, loss: 0.001152, speed: 4.12 step/s\n",
      "epoch: 7 / 12, steps: 3436 / 5352, loss: 0.000925, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 3536 / 5352, loss: 0.002039, speed: 4.14 step/s\n",
      "epoch: 7 / 12, steps: 3636 / 5352, loss: 0.001439, speed: 4.12 step/s\n",
      "epoch: 7 / 12, steps: 3736 / 5352, loss: 0.000926, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 3836 / 5352, loss: 0.000785, speed: 4.15 step/s\n",
      "epoch: 7 / 12, steps: 3936 / 5352, loss: 0.001357, speed: 4.11 step/s\n",
      "epoch: 7 / 12, steps: 4036 / 5352, loss: 0.001821, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 4136 / 5352, loss: 0.000976, speed: 4.14 step/s\n",
      "epoch: 7 / 12, steps: 4236 / 5352, loss: 0.001070, speed: 4.14 step/s\n",
      "epoch: 7 / 12, steps: 4336 / 5352, loss: 0.002077, speed: 4.13 step/s\n",
      "epoch: 7 / 12, steps: 4436 / 5352, loss: 0.001031, speed: 4.09 step/s\n",
      "epoch: 7 / 12, steps: 4536 / 5352, loss: 0.000981, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 4636 / 5352, loss: 0.001553, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 4736 / 5352, loss: 0.001602, speed: 4.17 step/s\n",
      "epoch: 7 / 12, steps: 4836 / 5352, loss: 0.001249, speed: 4.19 step/s\n",
      "epoch: 7 / 12, steps: 4936 / 5352, loss: 0.001388, speed: 4.16 step/s\n",
      "epoch: 7 / 12, steps: 5036 / 5352, loss: 0.001132, speed: 4.13 step/s\n",
      "epoch: 7 / 12, steps: 5136 / 5352, loss: 0.001052, speed: 4.13 step/s\n",
      "epoch: 7 / 12, steps: 5236 / 5352, loss: 0.001381, speed: 4.13 step/s\n",
      "epoch: 7 / 12, steps: 5336 / 5352, loss: 0.001276, speed: 4.12 step/s\n",
      "epoch time footprint: 0 hour 22 min 55 sec\n",
      "\n",
      "=====start training of 8 epochs=====\n",
      "epoch: 8 / 12, steps: 84 / 5352, loss: 0.000917, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 184 / 5352, loss: 0.001176, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 284 / 5352, loss: 0.001401, speed: 4.09 step/s\n",
      "epoch: 8 / 12, steps: 384 / 5352, loss: 0.000878, speed: 4.08 step/s\n",
      "epoch: 8 / 12, steps: 484 / 5352, loss: 0.001292, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 584 / 5352, loss: 0.000731, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 684 / 5352, loss: 0.000919, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 784 / 5352, loss: 0.000716, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 884 / 5352, loss: 0.000971, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 984 / 5352, loss: 0.001380, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 1084 / 5352, loss: 0.000834, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 1184 / 5352, loss: 0.000970, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 1284 / 5352, loss: 0.001225, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 1384 / 5352, loss: 0.000757, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 1484 / 5352, loss: 0.001537, speed: 4.09 step/s\n",
      "epoch: 8 / 12, steps: 1584 / 5352, loss: 0.001435, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 1684 / 5352, loss: 0.000985, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 1784 / 5352, loss: 0.000871, speed: 4.16 step/s\n",
      "epoch: 8 / 12, steps: 1884 / 5352, loss: 0.000960, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 1984 / 5352, loss: 0.002054, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 2084 / 5352, loss: 0.000840, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 2184 / 5352, loss: 0.000902, speed: 4.12 step/s\n",
      "\n",
      "=====start evaluating ckpt of 45000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002329\n",
      "precision: 62.39\t recall: 75.04\t f1: 68.13\t\n",
      "saving checkpoing model_45000.pdparams to checkpoints \n",
      "epoch: 8 / 12, steps: 2284 / 5352, loss: 0.001252, speed: 1.05 step/s\n",
      "epoch: 8 / 12, steps: 2384 / 5352, loss: 0.001372, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 2484 / 5352, loss: 0.001230, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 2584 / 5352, loss: 0.001131, speed: 4.18 step/s\n",
      "epoch: 8 / 12, steps: 2684 / 5352, loss: 0.000817, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 2784 / 5352, loss: 0.001098, speed: 4.14 step/s\n",
      "epoch: 8 / 12, steps: 2884 / 5352, loss: 0.000908, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 2984 / 5352, loss: 0.000800, speed: 4.16 step/s\n",
      "epoch: 8 / 12, steps: 3084 / 5352, loss: 0.000513, speed: 4.18 step/s\n",
      "epoch: 8 / 12, steps: 3184 / 5352, loss: 0.001152, speed: 4.16 step/s\n",
      "epoch: 8 / 12, steps: 3284 / 5352, loss: 0.001025, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 3384 / 5352, loss: 0.001106, speed: 4.18 step/s\n",
      "epoch: 8 / 12, steps: 3484 / 5352, loss: 0.001175, speed: 4.17 step/s\n",
      "epoch: 8 / 12, steps: 3584 / 5352, loss: 0.001333, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 3684 / 5352, loss: 0.001731, speed: 4.13 step/s\n",
      "epoch: 8 / 12, steps: 3784 / 5352, loss: 0.001506, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 3884 / 5352, loss: 0.000747, speed: 4.16 step/s\n",
      "epoch: 8 / 12, steps: 3984 / 5352, loss: 0.001802, speed: 4.16 step/s\n",
      "epoch: 8 / 12, steps: 4084 / 5352, loss: 0.001086, speed: 4.12 step/s\n",
      "epoch: 8 / 12, steps: 4184 / 5352, loss: 0.000996, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 4284 / 5352, loss: 0.001557, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 4384 / 5352, loss: 0.001548, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 4484 / 5352, loss: 0.001151, speed: 4.15 step/s\n",
      "epoch: 8 / 12, steps: 4584 / 5352, loss: 0.000939, speed: 4.14 step/s\n",
      "epoch: 8 / 12, steps: 4684 / 5352, loss: 0.001152, speed: 4.10 step/s\n",
      "epoch: 8 / 12, steps: 4784 / 5352, loss: 0.001549, speed: 4.13 step/s\n",
      "epoch: 8 / 12, steps: 4884 / 5352, loss: 0.000915, speed: 4.11 step/s\n",
      "epoch: 8 / 12, steps: 4984 / 5352, loss: 0.000846, speed: 4.08 step/s\n",
      "epoch: 8 / 12, steps: 5084 / 5352, loss: 0.001087, speed: 4.09 step/s\n",
      "epoch: 8 / 12, steps: 5184 / 5352, loss: 0.000999, speed: 4.09 step/s\n",
      "epoch: 8 / 12, steps: 5284 / 5352, loss: 0.000893, speed: 4.10 step/s\n",
      "epoch time footprint: 0 hour 22 min 47 sec\n",
      "\n",
      "=====start training of 9 epochs=====\n",
      "epoch: 9 / 12, steps: 32 / 5352, loss: 0.002113, speed: 4.09 step/s\n",
      "epoch: 9 / 12, steps: 132 / 5352, loss: 0.001037, speed: 4.10 step/s\n",
      "epoch: 9 / 12, steps: 232 / 5352, loss: 0.001737, speed: 4.09 step/s\n",
      "epoch: 9 / 12, steps: 332 / 5352, loss: 0.000906, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 432 / 5352, loss: 0.000989, speed: 4.10 step/s\n",
      "epoch: 9 / 12, steps: 532 / 5352, loss: 0.000951, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 632 / 5352, loss: 0.000605, speed: 4.09 step/s\n",
      "epoch: 9 / 12, steps: 732 / 5352, loss: 0.001227, speed: 4.11 step/s\n",
      "epoch: 9 / 12, steps: 832 / 5352, loss: 0.001251, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 932 / 5352, loss: 0.000893, speed: 4.10 step/s\n",
      "epoch: 9 / 12, steps: 1032 / 5352, loss: 0.000852, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 1132 / 5352, loss: 0.000869, speed: 4.01 step/s\n",
      "epoch: 9 / 12, steps: 1232 / 5352, loss: 0.001058, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 1332 / 5352, loss: 0.001146, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 1432 / 5352, loss: 0.001201, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 1532 / 5352, loss: 0.001195, speed: 4.05 step/s\n",
      "epoch: 9 / 12, steps: 1632 / 5352, loss: 0.001114, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 1732 / 5352, loss: 0.000758, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 1832 / 5352, loss: 0.000810, speed: 4.02 step/s\n",
      "\n",
      "=====start evaluating ckpt of 50000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:02<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002533\n",
      "precision: 62.26\t recall: 75.64\t f1: 68.30\t\n",
      "saving checkpoing model_50000.pdparams to checkpoints \n",
      "epoch: 9 / 12, steps: 1932 / 5352, loss: 0.001091, speed: 1.03 step/s\n",
      "epoch: 9 / 12, steps: 2032 / 5352, loss: 0.001153, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 2132 / 5352, loss: 0.001275, speed: 4.05 step/s\n",
      "epoch: 9 / 12, steps: 2232 / 5352, loss: 0.000759, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 2332 / 5352, loss: 0.000609, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 2432 / 5352, loss: 0.001258, speed: 4.02 step/s\n",
      "epoch: 9 / 12, steps: 2532 / 5352, loss: 0.000748, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 2632 / 5352, loss: 0.001124, speed: 4.02 step/s\n",
      "epoch: 9 / 12, steps: 2732 / 5352, loss: 0.000946, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 2832 / 5352, loss: 0.001167, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 2932 / 5352, loss: 0.001401, speed: 4.03 step/s\n",
      "epoch: 9 / 12, steps: 3032 / 5352, loss: 0.001138, speed: 4.02 step/s\n",
      "epoch: 9 / 12, steps: 3132 / 5352, loss: 0.000799, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 3232 / 5352, loss: 0.000892, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 3332 / 5352, loss: 0.001065, speed: 4.07 step/s\n",
      "epoch: 9 / 12, steps: 3432 / 5352, loss: 0.001055, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 3532 / 5352, loss: 0.001696, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 3632 / 5352, loss: 0.001021, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 3732 / 5352, loss: 0.001585, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 3832 / 5352, loss: 0.000639, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 3932 / 5352, loss: 0.000879, speed: 4.08 step/s\n",
      "epoch: 9 / 12, steps: 4032 / 5352, loss: 0.001425, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 4132 / 5352, loss: 0.000686, speed: 4.06 step/s\n",
      "epoch: 9 / 12, steps: 4232 / 5352, loss: 0.001540, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 4332 / 5352, loss: 0.000345, speed: 4.03 step/s\n",
      "epoch: 9 / 12, steps: 4432 / 5352, loss: 0.001027, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 4532 / 5352, loss: 0.000813, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 4632 / 5352, loss: 0.001076, speed: 4.05 step/s\n",
      "epoch: 9 / 12, steps: 4732 / 5352, loss: 0.001122, speed: 4.04 step/s\n",
      "epoch: 9 / 12, steps: 4832 / 5352, loss: 0.001387, speed: 4.00 step/s\n",
      "epoch: 9 / 12, steps: 4932 / 5352, loss: 0.000938, speed: 4.03 step/s\n",
      "epoch: 9 / 12, steps: 5032 / 5352, loss: 0.000882, speed: 3.99 step/s\n",
      "epoch: 9 / 12, steps: 5132 / 5352, loss: 0.000757, speed: 4.01 step/s\n",
      "epoch: 9 / 12, steps: 5232 / 5352, loss: 0.001522, speed: 4.02 step/s\n",
      "epoch: 9 / 12, steps: 5332 / 5352, loss: 0.001041, speed: 4.04 step/s\n",
      "epoch time footprint: 0 hour 23 min 12 sec\n",
      "\n",
      "=====start training of 10 epochs=====\n",
      "epoch: 10 / 12, steps: 80 / 5352, loss: 0.001000, speed: 4.04 step/s\n",
      "epoch: 10 / 12, steps: 180 / 5352, loss: 0.001300, speed: 4.04 step/s\n",
      "epoch: 10 / 12, steps: 280 / 5352, loss: 0.000963, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 380 / 5352, loss: 0.000939, speed: 4.04 step/s\n",
      "epoch: 10 / 12, steps: 480 / 5352, loss: 0.001601, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 580 / 5352, loss: 0.000883, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 680 / 5352, loss: 0.001278, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 780 / 5352, loss: 0.001238, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 880 / 5352, loss: 0.000791, speed: 4.00 step/s\n",
      "epoch: 10 / 12, steps: 980 / 5352, loss: 0.001397, speed: 4.00 step/s\n",
      "epoch: 10 / 12, steps: 1080 / 5352, loss: 0.001603, speed: 4.02 step/s\n",
      "epoch: 10 / 12, steps: 1180 / 5352, loss: 0.000719, speed: 4.00 step/s\n",
      "epoch: 10 / 12, steps: 1280 / 5352, loss: 0.001151, speed: 4.04 step/s\n",
      "epoch: 10 / 12, steps: 1380 / 5352, loss: 0.000644, speed: 4.04 step/s\n",
      "epoch: 10 / 12, steps: 1480 / 5352, loss: 0.000875, speed: 4.04 step/s\n",
      "\n",
      "=====start evaluating ckpt of 55000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002527\n",
      "precision: 61.12\t recall: 76.11\t f1: 67.79\t\n",
      "saving checkpoing model_55000.pdparams to checkpoints \n",
      "epoch: 10 / 12, steps: 1680 / 5352, loss: 0.000837, speed: 4.05 step/s\n",
      "epoch: 10 / 12, steps: 1780 / 5352, loss: 0.000787, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 1880 / 5352, loss: 0.000778, speed: 4.17 step/s\n",
      "epoch: 10 / 12, steps: 1980 / 5352, loss: 0.000749, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 2080 / 5352, loss: 0.000603, speed: 4.21 step/s\n",
      "epoch: 10 / 12, steps: 2180 / 5352, loss: 0.000807, speed: 4.12 step/s\n",
      "epoch: 10 / 12, steps: 2280 / 5352, loss: 0.001261, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 2380 / 5352, loss: 0.001749, speed: 4.14 step/s\n",
      "epoch: 10 / 12, steps: 2480 / 5352, loss: 0.001250, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 2580 / 5352, loss: 0.000929, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 2680 / 5352, loss: 0.000821, speed: 4.12 step/s\n",
      "epoch: 10 / 12, steps: 2780 / 5352, loss: 0.001921, speed: 4.20 step/s\n",
      "epoch: 10 / 12, steps: 2880 / 5352, loss: 0.001236, speed: 4.17 step/s\n",
      "epoch: 10 / 12, steps: 2980 / 5352, loss: 0.001243, speed: 4.19 step/s\n",
      "epoch: 10 / 12, steps: 3080 / 5352, loss: 0.000772, speed: 4.21 step/s\n",
      "epoch: 10 / 12, steps: 3180 / 5352, loss: 0.001720, speed: 4.17 step/s\n",
      "epoch: 10 / 12, steps: 3280 / 5352, loss: 0.001166, speed: 4.19 step/s\n",
      "epoch: 10 / 12, steps: 3380 / 5352, loss: 0.001377, speed: 4.18 step/s\n",
      "epoch: 10 / 12, steps: 3480 / 5352, loss: 0.001327, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 3580 / 5352, loss: 0.001139, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 3680 / 5352, loss: 0.000986, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 3780 / 5352, loss: 0.000966, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 3880 / 5352, loss: 0.001006, speed: 4.14 step/s\n",
      "epoch: 10 / 12, steps: 3980 / 5352, loss: 0.000921, speed: 4.15 step/s\n",
      "epoch: 10 / 12, steps: 4080 / 5352, loss: 0.001063, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 4180 / 5352, loss: 0.000557, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 4280 / 5352, loss: 0.001319, speed: 4.14 step/s\n",
      "epoch: 10 / 12, steps: 4380 / 5352, loss: 0.001164, speed: 4.11 step/s\n",
      "epoch: 10 / 12, steps: 4480 / 5352, loss: 0.001063, speed: 4.15 step/s\n",
      "epoch: 10 / 12, steps: 4580 / 5352, loss: 0.000515, speed: 4.12 step/s\n",
      "epoch: 10 / 12, steps: 4680 / 5352, loss: 0.000497, speed: 4.13 step/s\n",
      "epoch: 10 / 12, steps: 4780 / 5352, loss: 0.000670, speed: 4.16 step/s\n",
      "epoch: 10 / 12, steps: 4880 / 5352, loss: 0.001440, speed: 4.10 step/s\n",
      "epoch: 10 / 12, steps: 4980 / 5352, loss: 0.000870, speed: 4.10 step/s\n",
      "epoch: 10 / 12, steps: 5080 / 5352, loss: 0.000710, speed: 4.11 step/s\n",
      "epoch: 10 / 12, steps: 5180 / 5352, loss: 0.000772, speed: 4.10 step/s\n",
      "epoch: 10 / 12, steps: 5280 / 5352, loss: 0.000811, speed: 4.11 step/s\n",
      "epoch time footprint: 0 hour 22 min 54 sec\n",
      "\n",
      "=====start training of 11 epochs=====\n",
      "epoch: 11 / 12, steps: 28 / 5352, loss: 0.000940, speed: 4.11 step/s\n",
      "epoch: 11 / 12, steps: 128 / 5352, loss: 0.000925, speed: 4.17 step/s\n",
      "epoch: 11 / 12, steps: 228 / 5352, loss: 0.001492, speed: 4.12 step/s\n",
      "epoch: 11 / 12, steps: 328 / 5352, loss: 0.001128, speed: 4.15 step/s\n",
      "epoch: 11 / 12, steps: 428 / 5352, loss: 0.001021, speed: 4.15 step/s\n",
      "epoch: 11 / 12, steps: 528 / 5352, loss: 0.000847, speed: 4.13 step/s\n",
      "epoch: 11 / 12, steps: 628 / 5352, loss: 0.001283, speed: 4.11 step/s\n",
      "epoch: 11 / 12, steps: 728 / 5352, loss: 0.000749, speed: 4.14 step/s\n",
      "epoch: 11 / 12, steps: 828 / 5352, loss: 0.000952, speed: 4.15 step/s\n",
      "epoch: 11 / 12, steps: 928 / 5352, loss: 0.001348, speed: 4.18 step/s\n",
      "epoch: 11 / 12, steps: 1028 / 5352, loss: 0.000615, speed: 4.09 step/s\n",
      "epoch: 11 / 12, steps: 1128 / 5352, loss: 0.000873, speed: 4.08 step/s\n",
      "\n",
      "=====start evaluating ckpt of 60000 steps=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002589\n",
      "precision: 62.56\t recall: 75.80\t f1: 68.55\t\n",
      "saving checkpoing model_60000.pdparams to checkpoints \n",
      "epoch: 11 / 12, steps: 1228 / 5352, loss: 0.001184, speed: 1.05 step/s\n",
      "epoch: 11 / 12, steps: 1328 / 5352, loss: 0.001324, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 1428 / 5352, loss: 0.000902, speed: 4.04 step/s\n",
      "epoch: 11 / 12, steps: 1528 / 5352, loss: 0.000969, speed: 4.04 step/s\n",
      "epoch: 11 / 12, steps: 1628 / 5352, loss: 0.000848, speed: 4.05 step/s\n",
      "epoch: 11 / 12, steps: 1728 / 5352, loss: 0.000628, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 1828 / 5352, loss: 0.001002, speed: 4.06 step/s\n",
      "epoch: 11 / 12, steps: 1928 / 5352, loss: 0.000728, speed: 4.06 step/s\n",
      "epoch: 11 / 12, steps: 2028 / 5352, loss: 0.000603, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 2128 / 5352, loss: 0.001005, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 2228 / 5352, loss: 0.000832, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 2328 / 5352, loss: 0.000931, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 2428 / 5352, loss: 0.000989, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 2528 / 5352, loss: 0.001113, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 2628 / 5352, loss: 0.000950, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 2728 / 5352, loss: 0.001369, speed: 4.06 step/s\n",
      "epoch: 11 / 12, steps: 2828 / 5352, loss: 0.000701, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 2928 / 5352, loss: 0.000855, speed: 4.04 step/s\n",
      "epoch: 11 / 12, steps: 3028 / 5352, loss: 0.000772, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 3128 / 5352, loss: 0.001050, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 3228 / 5352, loss: 0.000910, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 3328 / 5352, loss: 0.000894, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 3428 / 5352, loss: 0.001189, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 3528 / 5352, loss: 0.000889, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 3628 / 5352, loss: 0.000941, speed: 4.08 step/s\n",
      "epoch: 11 / 12, steps: 3728 / 5352, loss: 0.001350, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 3828 / 5352, loss: 0.000757, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 3928 / 5352, loss: 0.001153, speed: 4.04 step/s\n",
      "epoch: 11 / 12, steps: 4028 / 5352, loss: 0.000947, speed: 4.04 step/s\n",
      "epoch: 11 / 12, steps: 4128 / 5352, loss: 0.000435, speed: 4.10 step/s\n",
      "epoch: 11 / 12, steps: 4228 / 5352, loss: 0.000939, speed: 4.09 step/s\n",
      "epoch: 11 / 12, steps: 4328 / 5352, loss: 0.000956, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 4428 / 5352, loss: 0.001607, speed: 4.06 step/s\n",
      "epoch: 11 / 12, steps: 4528 / 5352, loss: 0.000880, speed: 4.07 step/s\n",
      "epoch: 11 / 12, steps: 4628 / 5352, loss: 0.000806, speed: 4.09 step/s\n",
      "epoch: 11 / 12, steps: 4728 / 5352, loss: 0.000869, speed: 4.09 step/s\n",
      "epoch: 11 / 12, steps: 4828 / 5352, loss: 0.001101, speed: 4.09 step/s\n",
      "epoch: 11 / 12, steps: 4928 / 5352, loss: 0.000745, speed: 4.05 step/s\n",
      "epoch: 11 / 12, steps: 5028 / 5352, loss: 0.000964, speed: 4.01 step/s\n",
      "epoch: 11 / 12, steps: 5128 / 5352, loss: 0.000721, speed: 4.05 step/s\n",
      "epoch: 11 / 12, steps: 5228 / 5352, loss: 0.001249, speed: 4.09 step/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 646/646 [01:01<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss: 0.002565\n",
      "precision: 61.94\t recall: 76.13\t f1: 68.30\t\n",
      "\n",
      "=====training complete=====\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# Starts training.\n",
    "global_step = 0\n",
    "logging_steps = 100\n",
    "save_steps = 5000\n",
    "num_train_epochs = 12\n",
    "output_dir = 'checkpoints'\n",
    "tic_train = time.time()\n",
    "model.train()\n",
    "for epoch in range(num_train_epochs):\n",
    "    print(\"\\n=====start training of %d epochs=====\" % epoch)\n",
    "    tic_epoch = time.time()\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        input_ids, seq_lens, tok_to_orig_start_index, tok_to_orig_end_index, labels = batch\n",
    "        logits = model(input_ids=input_ids)\n",
    "        mask = (input_ids != 0).logical_and((input_ids != 1)).logical_and(\n",
    "            (input_ids != 2))\n",
    "        loss = criterion(logits, labels, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_gradients()\n",
    "        loss_item = loss.numpy().item()\n",
    "\n",
    "        if global_step % logging_steps == 0:\n",
    "            print(\n",
    "                \"epoch: %d / %d, steps: %d / %d, loss: %f, speed: %.2f step/s\"\n",
    "                % (epoch, num_train_epochs, step, steps_by_epoch,\n",
    "                    loss_item, logging_steps / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "\n",
    "        if global_step % save_steps == 0 and global_step != 0:\n",
    "            print(\"\\n=====start evaluating ckpt of %d steps=====\" %\n",
    "                    global_step)\n",
    "            precision, recall, f1 = evaluate(\n",
    "                model, criterion, test_data_loader, eval_file_path, \"eval\")\n",
    "            print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\n",
    "                    (100 * precision, 100 * recall, 100 * f1))\n",
    "            print(\"saving checkpoing model_%d.pdparams to %s \" %\n",
    "                    (global_step, output_dir))\n",
    "            paddle.save(model.state_dict(),\n",
    "                        os.path.join(output_dir, \n",
    "                                        \"model_%d.pdparams\" % global_step))\n",
    "            model.train()\n",
    "\n",
    "        global_step += 1\n",
    "    tic_epoch = time.time() - tic_epoch\n",
    "    print(\"epoch time footprint: %d hour %d min %d sec\" %\n",
    "            (tic_epoch // 3600, (tic_epoch % 3600) // 60, tic_epoch % 60))\n",
    "\n",
    "# Does final evaluation.\n",
    "print(\"\\n=====start evaluating last ckpt of %d steps=====\" %\n",
    "        global_step)\n",
    "precision, recall, f1 = evaluate(model, criterion, test_data_loader,\n",
    "                                    eval_file_path, \"eval\")\n",
    "print(\"precision: %.2f\\t recall: %.2f\\t f1: %.2f\\t\" %\n",
    "        (100 * precision, 100 * recall, 100 * f1))\n",
    "paddle.save(model.state_dict(),\n",
    "            os.path.join(output_dir,\n",
    "                            \"model_%d.pdparams\" % global_step))\n",
    "print(\"\\n=====training complete=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ export CUDA_VISIBLE_DEVICES=0\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ export BATCH_SIZE=32\n",
      "+ BATCH_SIZE=32\n",
      "+ export CKPT=./checkpoints/model_64224.pdparams\n",
      "+ CKPT=./checkpoints/model_64224.pdparams\n",
      "+ export DATASET_FILE=./data/test.json\n",
      "+ DATASET_FILE=./data/test.json\n",
      "+ python run_duie.py --do_predict --init_checkpoint ./checkpoints/model_64224.pdparams --predict_data_file ./data/test.json --max_seq_length 128 --batch_size 32 --device gpu\n",
      "\u001b[32m[2021-06-14 21:26:50,629] [    INFO]\u001b[0m - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\u001b[0m\n",
      "W0614 21:26:50.630327 20241 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0614 21:26:50.635741 20241 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "!bash predict.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "预测结果会被保存在data/predictions.json，data/predictions.json.zip，其格式与原数据集文件一致。\n",
    "\n",
    "之后可以使用官方评估脚本评估训练模型在dev_data.json上的效果。如：\n",
    "\n",
    "```shell\n",
    "python re_official_evaluation.py --golden_file=dev_data.json  --predict_file=predicitons.json.zip [--alias_file alias_dict]\n",
    "```\n",
    "输出指标为Precision, Recall 和 F1，Alias file包含了合法的实体别名，最终评测的时候会使用，这里不予提供。\n",
    "\n",
    "之后在test_data.json上预测，然后预测结果（.zip文件）至[千言评测页面](https://aistudio.baidu.com/aistudio/competition/detail/46)。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 【千言数据集：信息抽取】比赛结果提交与排名截图\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5cb578f9f7b14e20ae92fc608d7f05db7d45e2d11af641c2a28dc55961eb68b7)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1cd2574968864b3c8c45689d9b624bec17d46221059440adac98b16c416097c6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Tricks\n",
    "\n",
    "### 尝试更多的预训练模型\n",
    "\n",
    "基线采用的预训练模型为ERNIE，PaddleNLP提供了丰富的预训练模型，如BERT，RoBERTa，Electra，XLNet等\n",
    "参考[预训练模型文档](https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers.html)\n",
    "\n",
    "如可以选择RoBERTa large中文模型优化模型效果，只需更换模型和tokenizer即可无缝衔接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import RobertaForTokenClassification, RobertaTokenizer\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(\n",
    "    \"roberta-wwm-ext-large\",\n",
    "    num_classes=(len(label_map) - 2) * 2 + 2)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-wwm-ext-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型集成\n",
    "\n",
    "使用多个模型进行训练预测，将各个模型预测结果进行融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上基线实现基于PaddleNLP，开源不易，希望大家多多支持~ \n",
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐，及时跟踪最新消息和功能哦**\n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
