{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ä½œä¸š\n",
    "\n",
    "å®Œæˆé¢„æµ‹ç¯èŠ‚é¢„è®­ç»ƒæ¨¡å‹çš„è°ƒç”¨ä»£ç ï¼Œå¹¶è·‘é€šæ•´ä¸ªé¡¹ç›®ï¼ŒæˆåŠŸæäº¤åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›ï¼ŒæŒ‰è¦æ±‚æˆªå›¾ï¼Œæäº¤ä½œä¸šå³å¯ã€‚\n",
    "\n",
    "tipsï¼š\n",
    "\n",
    "- é¢„æµ‹å¯ä»¥ä½¿ç”¨è‡ªå·±è®­ç»ƒçš„æ¨¡å‹ï¼ˆè®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼‰ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨æä¾›ä¸‹è½½çš„æ¨¡å‹æƒé‡ï¼›\n",
    "- æŠ¥ååƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›ï¼Œå¹¶æˆåŠŸæäº¤ç»“æœï¼›\n",
    "- å¹¶å°†å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ç»“æœæˆªå›¾ï¼Œè´´åˆ°æœ¬é¡¹ç›®ä½œä¸šæœ€åä¸€è¡Œå³å®Œæˆä½œä¸šã€‚\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/cf119d3bc6504c098cc3cc58597b7061890d5fe915364f5fbd52341033307c7c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# åŸºäºé¢„è®­ç»ƒæ¨¡å‹ ERNIE-Gram å®ç°è¯­ä¹‰åŒ¹é…\n",
    "\n",
    "\n",
    "6.7NLPç›´æ’­æ‰“å¡è¯¾å³å°†å¼€æ’­ï¼Œæ¬¢è¿å¤§å®¶å…³æ³¨è¯¾ç¨‹ï¼Œæœ‰ä»»ä½•é—®é¢˜æ¥è¯„è®ºåŒºæˆ–**QQç¾¤**ï¼ˆç¾¤å·:758287592ï¼‰äº¤æµå§~~\n",
    "\n",
    "**[ç›´æ’­é“¾æ¥è¯·æˆ³è¿™é‡Œï¼Œæ¯æ™š20:00-21:30ğŸ‘ˆ](http://live.bilibili.com/21689802)**\n",
    "\n",
    "**[è¯¾ç¨‹åœ°å€è¯·æˆ³è¿™é‡ŒğŸ‘ˆ](https://aistudio.baidu.com/aistudio/course/introduce/24177)**\n",
    "\n",
    "\n",
    "æœ¬æ¡ˆä¾‹ä»‹ç» NLP æœ€åŸºæœ¬çš„ä»»åŠ¡ç±»å‹ä¹‹ä¸€ â€”â€” æ–‡æœ¬è¯­ä¹‰åŒ¹é…ï¼Œå¹¶ä¸”åŸºäº PaddleNLP ä½¿ç”¨ç™¾åº¦å¼€æºçš„é¢„è®­ç»ƒæ¨¡å‹ ERNIE-Gram æ­å»ºæ•ˆæœä¼˜å¼‚çš„è¯­ä¹‰åŒ¹é…æ¨¡å‹ï¼Œæ¥åˆ¤æ–­ 2 æ®µæ–‡æœ¬è¯­ä¹‰æ˜¯å¦ç›¸åŒã€‚\n",
    "\n",
    "## 1. èƒŒæ™¯ä»‹ç»\n",
    "æ–‡æœ¬è¯­ä¹‰åŒ¹é…ä»»åŠ¡ï¼Œç®€å•æ¥è¯´å°±æ˜¯ç»™å®šä¸¤æ®µæ–‡æœ¬ï¼Œè®©æ¨¡å‹æ¥åˆ¤æ–­ä¸¤æ®µæ–‡æœ¬æ˜¯ä¸æ˜¯è¯­ä¹‰ç›¸ä¼¼ã€‚\n",
    "\n",
    "åœ¨æœ¬æ¡ˆä¾‹ä¸­ä»¥æƒå¨çš„è¯­ä¹‰åŒ¹é…æ•°æ®é›† [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) ä¸ºä¾‹ï¼Œ[LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) æ•°æ®é›†æ˜¯åŸºäºç™¾åº¦çŸ¥é“ç›¸ä¼¼é—®é¢˜æ¨èæ„é€ çš„é€šé—®å¥è¯­ä¹‰åŒ¹é…æ•°æ®é›†ã€‚è®­ç»ƒé›†ä¸­çš„æ¯ä¸¤æ®µæ–‡æœ¬éƒ½ä¼šè¢«æ ‡è®°ä¸º 1ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰ æˆ–è€… 0ï¼ˆè¯­ä¹‰ä¸ç›¸ä¼¼ï¼‰ã€‚æ›´å¤šæ•°æ®é›†å¯è®¿é—®[åƒè¨€](https://www.luge.ai/)è·å–å“¦ã€‚\n",
    "\n",
    "ä¾‹å¦‚ç™¾åº¦çŸ¥é“åœºæ™¯ä¸‹ï¼Œç”¨æˆ·æœç´¢ä¸€ä¸ªé—®é¢˜ï¼Œæ¨¡å‹ä¼šè®¡ç®—è¿™ä¸ªé—®é¢˜ä¸å€™é€‰é—®é¢˜æ˜¯å¦è¯­ä¹‰ç›¸ä¼¼ï¼Œè¯­ä¹‰åŒ¹é…æ¨¡å‹ä¼šæ‰¾å‡ºä¸é—®é¢˜è¯­ä¹‰ç›¸ä¼¼çš„å€™é€‰é—®é¢˜è¿”å›ç»™ç”¨æˆ·ï¼ŒåŠ å¿«ç”¨æˆ·æé—®-è·å–ç­”æ¡ˆçš„æ•ˆç‡ã€‚ä¾‹å¦‚ï¼Œå½“æŸç”¨æˆ·åœ¨æœç´¢å¼•æ“ä¸­æœç´¢ â€œæ·±åº¦å­¦ä¹ çš„æ•™ææœ‰å“ªäº›ï¼Ÿâ€ï¼Œæ¨¡å‹å°±è‡ªåŠ¨æ‰¾åˆ°äº†ä¸€äº›è¯­ä¹‰ç›¸ä¼¼çš„é—®é¢˜å±•ç°ç»™ç”¨æˆ·:\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ecc1244685ec4476b869ce8a32d421c0ad530666e98d487da21fa4f61670544f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.å¿«é€Ÿå®è·µ\n",
    "\n",
    "ä»‹ç»å¦‚ä½•å‡†å¤‡æ•°æ®ï¼ŒåŸºäº ERNIE-Gram æ¨¡å‹æ­å»ºåŒ¹é…ç½‘ç»œï¼Œç„¶åå¿«é€Ÿè¿›è¡Œè¯­ä¹‰åŒ¹é…æ¨¡å‹çš„è®­ç»ƒã€è¯„ä¼°å’Œé¢„æµ‹ã€‚\n",
    "\n",
    "### 2.1 æ•°æ®åŠ è½½\n",
    "ä¸ºäº†è®­ç»ƒåŒ¹é…æ¨¡å‹ï¼Œä¸€èˆ¬éœ€è¦å‡†å¤‡ä¸‰ä¸ªæ•°æ®é›†ï¼šè®­ç»ƒé›† train.tsvã€éªŒè¯é›†dev.tsvã€æµ‹è¯•é›†test.tsvã€‚æ­¤æ¡ˆä¾‹æˆ‘ä»¬ä½¿ç”¨ PaddleNLP å†…ç½®çš„è¯­ä¹‰æ•°æ®é›† [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) æ¥è¿›è¡Œè®­ç»ƒã€è¯„ä¼°ã€é¢„æµ‹ã€‚\n",
    "\n",
    "è®­ç»ƒé›†: ç”¨æ¥è®­ç»ƒæ¨¡å‹å‚æ•°çš„æ•°æ®é›†ï¼Œæ¨¡å‹ç›´æ¥æ ¹æ®è®­ç»ƒé›†æ¥è°ƒæ•´è‡ªèº«å‚æ•°ä»¥è·å¾—æ›´å¥½çš„åˆ†ç±»æ•ˆæœã€‚\n",
    "\n",
    "éªŒè¯é›†: ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€éªŒæ¨¡å‹çš„çŠ¶æ€ï¼Œæ”¶æ•›æƒ…å†µã€‚éªŒè¯é›†é€šå¸¸ç”¨äºè°ƒæ•´è¶…å‚æ•°ï¼Œæ ¹æ®å‡ ç»„æ¨¡å‹éªŒè¯é›†ä¸Šçš„è¡¨ç°ï¼Œå†³å®šé‡‡ç”¨å“ªç»„è¶…å‚æ•°ã€‚\n",
    "\n",
    "æµ‹è¯•é›†: ç”¨æ¥è®¡ç®—æ¨¡å‹çš„å„é¡¹è¯„ä¼°æŒ‡æ ‡ï¼ŒéªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "\n",
    "[LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) æ•°æ®é›†æ˜¯å…¬å¼€çš„è¯­ä¹‰åŒ¹é…æƒå¨æ•°æ®é›†ã€‚PaddleNLP å·²ç»å†…ç½®è¯¥æ•°æ®é›†ï¼Œä¸€é”®å³å¯åŠ è½½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color='red'><b>ç”±äº PaddleNLP ä»…å†…ç½®äº†LCQMCæ•°æ®é›†ï¼Œè€Œæ¯”èµ›ç”¨çš„å¦å¤–ä¸¤ä¸ªæ•°æ®é›†BQCorpuså’ŒPaws-xå¹¶æ²¡æœ‰å†…ç½®ã€‚å› æ­¤ï¼Œè¿™é‡Œä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†çš„æ–¹å¼ã€‚å¹¶ä»¥LCMQä¸ºä¾‹ï¼Œå…¶ä»–è¿ä¸ªæ•°æ®é›†ç±»ä¼¼ã€‚</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**ä¸‹è½½åƒè¨€è¯­ä¹‰ç›¸ä¼¼åº¦æ•°æ®é›†ï¼Œå¹¶è§£å‹åˆ°æŒ‡å®šç›®å½•**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-10 23:05:33--  https://dataset-bj.cdn.bcebos.com/qianyan/bq_corpus.zip\n",
      "Resolving dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 182.61.128.166\n",
      "Connecting to dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|182.61.128.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3026847 (2.9M) [application/zip]\n",
      "Saving to: â€˜bq_corpus.zipâ€™\n",
      "\n",
      "bq_corpus.zip       100%[===================>]   2.89M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2021-06-10 23:05:33 (58.6 MB/s) - â€˜bq_corpus.zipâ€™ saved [3026847/3026847]\n",
      "\n",
      "--2021-06-10 23:05:34--  https://dataset-bj.cdn.bcebos.com/qianyan/lcqmc.zip\n",
      "Resolving dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 182.61.128.166\n",
      "Connecting to dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|182.61.128.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6990130 (6.7M) [application/zip]\n",
      "Saving to: â€˜lcqmc.zipâ€™\n",
      "\n",
      "lcqmc.zip           100%[===================>]   6.67M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-06-10 23:05:34 (47.7 MB/s) - â€˜lcqmc.zipâ€™ saved [6990130/6990130]\n",
      "\n",
      "--2021-06-10 23:05:34--  https://dataset-bj.cdn.bcebos.com/qianyan/paws-x-zh.zip\n",
      "Resolving dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 182.61.128.166\n",
      "Connecting to dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|182.61.128.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4349546 (4.1M) [application/zip]\n",
      "Saving to: â€˜paws-x-zh.zipâ€™\n",
      "\n",
      "paws-x-zh.zip       100%[===================>]   4.15M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-06-10 23:05:34 (41.2 MB/s) - â€˜paws-x-zh.zipâ€™ saved [4349546/4349546]\n",
      "\n",
      "Archive:  ./bq_corpus.zip\n",
      "   creating: ./data/bq_corpus/\n",
      "  inflating: ./data/bq_corpus/train.tsv  \n",
      "   creating: ./data/__MACOSX/\n",
      "   creating: ./data/__MACOSX/bq_corpus/\n",
      "  inflating: ./data/__MACOSX/bq_corpus/._train.tsv  \n",
      "  inflating: ./data/bq_corpus/dev.tsv  \n",
      "  inflating: ./data/__MACOSX/bq_corpus/._dev.tsv  \n",
      "  inflating: ./data/bq_corpus/License.pdf  \n",
      "  inflating: ./data/__MACOSX/bq_corpus/._License.pdf  \n",
      "  inflating: ./data/bq_corpus/test.tsv  \n",
      "  inflating: ./data/__MACOSX/bq_corpus/._test.tsv  \n",
      "  inflating: ./data/bq_corpus/User_Agreement.pdf  \n",
      "  inflating: ./data/__MACOSX/bq_corpus/._User_Agreement.pdf  \n",
      "  inflating: ./data/__MACOSX/._bq_corpus  \n",
      "Archive:  ./lcqmc.zip\n",
      "   creating: ./data/lcqmc/\n",
      "  inflating: ./data/lcqmc/train.tsv  \n",
      "   creating: ./data/__MACOSX/lcqmc/\n",
      "  inflating: ./data/__MACOSX/lcqmc/._train.tsv  \n",
      "  inflating: ./data/lcqmc/dev.tsv    \n",
      "  inflating: ./data/__MACOSX/lcqmc/._dev.tsv  \n",
      "  inflating: ./data/lcqmc/License.pdf  \n",
      "  inflating: ./data/__MACOSX/lcqmc/._License.pdf  \n",
      "  inflating: ./data/lcqmc/test.tsv   \n",
      "  inflating: ./data/__MACOSX/lcqmc/._test.tsv  \n",
      "  inflating: ./data/lcqmc/User_Agreement.pdf  \n",
      "  inflating: ./data/__MACOSX/lcqmc/._User_Agreement.pdf  \n",
      "  inflating: ./data/__MACOSX/._lcqmc  \n",
      "Archive:  ./paws-x-zh.zip\n",
      "   creating: ./data/paws-x-zh/\n",
      "  inflating: ./data/paws-x-zh/train.tsv  \n",
      "   creating: ./data/__MACOSX/paws-x-zh/\n",
      "  inflating: ./data/__MACOSX/paws-x-zh/._train.tsv  \n",
      "  inflating: ./data/paws-x-zh/dev.tsv  \n",
      "  inflating: ./data/__MACOSX/paws-x-zh/._dev.tsv  \n",
      "  inflating: ./data/paws-x-zh/License.pdf  \n",
      "  inflating: ./data/__MACOSX/paws-x-zh/._License.pdf  \n",
      "  inflating: ./data/paws-x-zh/test.tsv  \n",
      "  inflating: ./data/__MACOSX/paws-x-zh/._test.tsv  \n",
      "  inflating: ./data/__MACOSX/._paws-x-zh  \n"
     ]
    }
   ],
   "source": [
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/bq_corpus.zip\r\n",
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/lcqmc.zip\r\n",
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/paws-x-zh.zip\r\n",
    "\r\n",
    "!unzip ./bq_corpus.zip -d ./data/\r\n",
    "!unzip ./lcqmc.zip -d ./data/\r\n",
    "!unzip ./paws-x-zh.zip -d ./data/\r\n",
    "\r\n",
    "!mv ./data/paws-x-zh/ ./data/paws-x/\r\n",
    "\r\n",
    "!rm bq_corpus.zip lcqmc.zip paws-x-zh.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/e9/128dfc1371db3fc2fa883d8ef27ab6b21e3876e76750a43f58cf3c24e707/paddlenlp-2.0.2-py3-none-any.whl (426kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 430kB 18kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.2\n"
     ]
    }
   ],
   "source": [
    "# æ­£å¼å¼€å§‹å®éªŒä¹‹å‰é¦–å…ˆé€šè¿‡å¦‚ä¸‹å‘½ä»¤å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ paddlenlp\n",
    "!pip install --upgrade paddlenlp -i https://pypi.org/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddlenlp\n",
    "\n",
    "# ä¸€é”®åŠ è½½ Lcqmc çš„è®­ç»ƒé›†ã€éªŒè¯é›†\n",
    "# train_ds, dev_ds = load_dataset(\"lcqmc\", splits=[\"train\", \"dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddlenlp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color='red'><b>!!!ä»¥lcqmcæ•°æ®é›†ä¸ºä¾‹ï¼Œä¸¤å¤–ä¸¤ä¸ªæ•°æ®é›†ï¼Œæ›´æ¢data_classå³å¯!!!</b><font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_class = 'lcqmc' # 'lcqmc', 'bq_corpus', 'paws-x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/lcqmc/train.tsv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_path(data_dir='data', data_class='lcqmc', split='train'):\r\n",
    "\r\n",
    "    data_path = os.path.join(data_dir, data_class, split + '.tsv')\r\n",
    "    return data_path\r\n",
    "\r\n",
    "# æµ‹è¯•ï¼Œè·å–bq_corpusæ•°æ®é›†çš„è®­ç»ƒæ•°æ®é›†æ–‡ä»¶è·¯å¾„\r\n",
    "get_data_path(data_class=data_class, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®é›†\r\n",
    "\r\n",
    "def create_dataset(data_class, split, is_test=False):\r\n",
    "    \r\n",
    "    def read(data_path):\r\n",
    "        with open(data_path, 'r', encoding='utf-8') as fRead:\r\n",
    "            for line in fRead:  \r\n",
    "                if is_test:\r\n",
    "                    query, title = line.strip('\\n').split('\\t')\r\n",
    "                    yield {'query': query, 'title': title}\r\n",
    "                else:\r\n",
    "                    query, title, label = line.strip('\\n').split('\\t')\r\n",
    "                    yield {'query': query, 'title': title, 'label': label}\r\n",
    "\r\n",
    "    data_path = get_data_path(data_class=data_class, split=split)\r\n",
    "\r\n",
    "    dataset = load_dataset(read, data_path=data_path, lazy=False)\r\n",
    "    return dataset\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'å–œæ¬¢æ‰“ç¯®çƒçš„ç”·ç”Ÿå–œæ¬¢ä»€ä¹ˆæ ·çš„å¥³ç”Ÿ', 'title': 'çˆ±æ‰“ç¯®çƒçš„ç”·ç”Ÿå–œæ¬¢ä»€ä¹ˆæ ·çš„å¥³ç”Ÿ', 'label': '1'}\n",
      "{'query': 'æˆ‘æ‰‹æœºä¸¢äº†ï¼Œæˆ‘æƒ³æ¢ä¸ªæ‰‹æœº', 'title': 'æˆ‘æƒ³ä¹°ä¸ªæ–°æ‰‹æœºï¼Œæ±‚æ¨è', 'label': '1'}\n",
      "{'query': 'å¤§å®¶è§‰å¾—å¥¹å¥½çœ‹å—', 'title': 'å¤§å®¶è§‰å¾—è·‘ç”·å¥½çœ‹å—ï¼Ÿ', 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ï¼Œè¾“å‡ºBQè®­ç»ƒæ•°æ®é›†çš„å‰ä¸‰æ¡æ ·æœ¬\r\n",
    "train_dataset =create_dataset(data_class=data_class, split='train')\r\n",
    "dev_dataset = create_dataset(data_class=data_class, split='dev')\r\n",
    "\r\n",
    "for idx, example in enumerate(lcqmc_dataset):\r\n",
    "    if idx < 3:\r\n",
    "        print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "é€šè¿‡ PaddleNLP åŠ è½½è¿›æ¥çš„ [LCQMC](http://icrc.hitsz.edu.cn/Article/show/171.html) æ•°æ®é›†æ˜¯åŸå§‹çš„æ˜æ–‡æ•°æ®é›†ï¼Œè¿™éƒ¨åˆ†æˆ‘ä»¬æ¥å®ç°ç»„ batchã€tokenize ç­‰é¢„å¤„ç†é€»è¾‘ï¼Œå°†åŸå§‹æ˜æ–‡æ•°æ®è½¬æ¢æˆç½‘ç»œè®­ç»ƒçš„è¾“å…¥æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å®šä¹‰æ ·æœ¬è½¬æ¢å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-10 23:25:52,080] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-gram-zh/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# å› ä¸ºæ˜¯åŸºäºé¢„è®­ç»ƒæ¨¡å‹ ERNIE-Gram æ¥è¿›è¡Œï¼Œæ‰€ä»¥éœ€è¦é¦–å…ˆåŠ è½½ ERNIE-Gram çš„ tokenizerï¼Œ\n",
    "# åç»­æ ·æœ¬è½¬æ¢å‡½æ•°åŸºäº tokenizer å¯¹æ–‡æœ¬è¿›è¡Œåˆ‡åˆ†\n",
    "\n",
    "tokenizer = paddlenlp.transformers.ErnieGramTokenizer.from_pretrained('ernie-gram-zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# å°† 1 æ¡æ˜æ–‡æ•°æ®çš„ queryã€title æ‹¼æ¥èµ·æ¥ï¼Œæ ¹æ®é¢„è®­ç»ƒæ¨¡å‹çš„ tokenizer å°†æ˜æ–‡è½¬æ¢ä¸º ID æ•°æ®\n",
    "# è¿”å› input_ids å’Œ token_type_ids\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    # åœ¨é¢„æµ‹æˆ–è€…è¯„ä¼°é˜¶æ®µï¼Œä¸è¿”å› label å­—æ®µ\n",
    "    else:\n",
    "        return input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:  [1, 692, 811, 445, 2001, 497, 5, 654, 21, 692, 811, 614, 356, 314, 5, 291, 21, 2, 329, 445, 2001, 497, 5, 654, 21, 692, 811, 614, 356, 314, 5, 291, 21, 2]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label:  [1]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ï¼Œå¯¹BQè®­ç»ƒé›†çš„ç¬¬ 1 æ¡æ•°æ®è¿›è¡Œè½¬æ¢ï¼Œå¹¶è¾“å‡º\n",
    "input_ids, token_type_ids, label = convert_example(train_dataset[0], tokenizer)\n",
    "\n",
    "print('input_ids: ', input_ids)\n",
    "print('token_type_ids: ', token_type_ids)\n",
    "print('label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ä¸ºäº†åç»­æ–¹ä¾¿ä½¿ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨pythonåå‡½æ•°ï¼ˆpartialï¼‰ç»™ convert_example èµ‹äºˆä¸€äº›é»˜è®¤å‚æ•°\n",
    "from functools import partial\n",
    "\n",
    "# è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ ·æœ¬è½¬æ¢å‡½æ•°\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### ç»„è£… Batch æ•°æ® & Padding\n",
    "\n",
    "ä¸Šä¸€å°èŠ‚ï¼Œæˆ‘ä»¬å®Œæˆäº†å¯¹å•æ¡æ ·æœ¬çš„è½¬æ¢ï¼Œæœ¬èŠ‚æˆ‘ä»¬éœ€è¦å°†æ ·æœ¬ç»„åˆæˆ Batch æ•°æ®ï¼Œå¯¹äºä¸ç­‰é•¿çš„æ•°æ®è¿˜éœ€è¦è¿›è¡Œ Padding æ“ä½œï¼Œä¾¿äº GPU è®­ç»ƒã€‚\n",
    "\n",
    "PaddleNLP æä¾›äº†è®¸å¤šå…³äº NLP ä»»åŠ¡ä¸­æ„å»ºæœ‰æ•ˆçš„æ•°æ® pipeline çš„å¸¸ç”¨ API\n",
    "\n",
    "| API                             | ç®€ä»‹                                       |\n",
    "| ------------------------------- | :----------------------------------------- |\n",
    "| `paddlenlp.data.Stack`          | å †å Nä¸ªå…·æœ‰ç›¸åŒshapeçš„è¾“å…¥æ•°æ®æ¥æ„å»ºä¸€ä¸ªbatch |\n",
    "| `paddlenlp.data.Pad`            | å°†é•¿åº¦ä¸åŒçš„å¤šä¸ªå¥å­paddingåˆ°ç»Ÿä¸€é•¿åº¦ï¼Œå–Nä¸ªè¾“å…¥æ•°æ®ä¸­çš„æœ€å¤§é•¿åº¦ |\n",
    "| `paddlenlp.data.Tuple`          | å°†å¤šä¸ªbatchifyå‡½æ•°åŒ…è£…åœ¨ä¸€èµ· |\n",
    "\n",
    "æ›´å¤šæ•°æ®å¤„ç†æ“ä½œè¯¦è§ï¼š [https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Data: \n",
      " [[1 2 3 4]\n",
      " [3 4 5 6]\n",
      " [5 6 7 8]]\n",
      "\n",
      "Padded Data: \n",
      " [[1 2 3 4]\n",
      " [5 6 7 0]\n",
      " [8 9 0 0]]\n",
      "\n",
      "ids: \n",
      " [[1 2 3 4]\n",
      " [5 6 7 0]\n",
      " [8 9 0 0]]\n",
      "\n",
      "labels: \n",
      " [[1]\n",
      " [0]\n",
      " [1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.data import Pad\n",
    "from paddlenlp.data import Stack\n",
    "from paddlenlp.data import Tuple\n",
    "\n",
    "\n",
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "c = [5, 6, 7, 8]\n",
    "result = Stack()([a, b, c])\n",
    "print(\"Stacked Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7]\n",
    "c = [8, 9]\n",
    "result = Pad(pad_val=0)([a, b, c])\n",
    "print(\"Padded Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "data = [\n",
    "        [[1, 2, 3, 4], [1]],\n",
    "        [[5, 6, 7], [0]],\n",
    "        [[8, 9], [1]],\n",
    "       ]\n",
    "batchify_fn = Tuple(Pad(pad_val=0), Stack())\n",
    "ids, labels = batchify_fn(data)\n",
    "print(\"ids: \\n\", ids)\n",
    "print()\n",
    "print(\"labels: \\n\", labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¼šè¿”å› input_ids, token_type_ids, labels 3 ä¸ªå­—æ®µ\n",
    "# å› æ­¤é’ˆå¯¹è¿™ 3 ä¸ªå­—æ®µéœ€è¦åˆ†åˆ«å®šä¹‰ 3 ä¸ªç»„ batch æ“ä½œ\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\n",
    "    Stack(dtype=\"int64\")  # label\n",
    "): [data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å®šä¹‰ Dataloader\n",
    "ä¸‹é¢æˆ‘ä»¬åŸºäºç»„ batchify_fn å‡½æ•°å’Œæ ·æœ¬è½¬æ¢å‡½æ•° trans_func æ¥æ„é€ è®­ç»ƒé›†çš„ DataLoader, æ”¯æŒå¤šå¡è®­ç»ƒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# å®šä¹‰åˆ†å¸ƒå¼ Sampler: è‡ªåŠ¨å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ‡åˆ†ï¼Œæ”¯æŒå¤šå¡å¹¶è¡Œè®­ç»ƒ\n",
    "batch_sampler = paddle.io.DistributedBatchSampler(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# åŸºäº train_ds å®šä¹‰ train_data_loader\n",
    "# å› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†åˆ†å¸ƒå¼çš„ DistributedBatchSampler, train_data_loader ä¼šè‡ªåŠ¨å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œåˆ‡åˆ†\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "        dataset=train_dataset.map(trans_func),\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True\n",
    ")\n",
    "\n",
    "# é’ˆå¯¹éªŒè¯é›†æ•°æ®åŠ è½½ï¼Œæˆ‘ä»¬ä½¿ç”¨å•å¡è¿›è¡Œè¯„ä¼°ï¼Œæ‰€ä»¥é‡‡ç”¨ paddle.io.BatchSampler å³å¯\n",
    "# å®šä¹‰ dev_data_loader\n",
    "batch_sampler = paddle.io.BatchSampler(dev_dataset, batch_size=32, shuffle=False)\n",
    "dev_data_loader = paddle.io.DataLoader(\n",
    "        dataset=dev_dataset.map(trans_func),\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 æ¨¡å‹æ­å»º\n",
    "\n",
    "è‡ªä» 2018 å¹´ 10 æœˆä»¥æ¥ï¼ŒNLP ä¸ªé¢†åŸŸçš„ä»»åŠ¡éƒ½é€šè¿‡ Pretrain + Finetune çš„æ¨¡å¼ç›¸æ¯”ä¼ ç»Ÿ DNN æ–¹æ³•åœ¨æ•ˆæœä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œæœ¬èŠ‚æˆ‘ä»¬ä»¥ç™¾åº¦å¼€æºçš„é¢„è®­ç»ƒæ¨¡å‹ ERNIE-Gram ä¸ºåŸºç¡€æ¨¡å‹ï¼Œåœ¨æ­¤ä¹‹ä¸Šæ„å»º Point-wise è¯­ä¹‰åŒ¹é…ç½‘ç»œã€‚\n",
    "\n",
    "é¦–å…ˆæˆ‘ä»¬æ¥å®šä¹‰ç½‘ç»œç»“æ„:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color='red'><b>ï¼ï¼ï¼ç½‘ç»œæœ€åå¯¹logitsåšsoftmaxæ“ä½œæ˜¯å¤šä½™çš„ï¼ï¼ï¼</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-10 23:28:54,932] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn as nn\n",
    "\n",
    "# æˆ‘ä»¬åŸºäº ERNIE-Gram æ¨¡å‹ç»“æ„æ­å»º Point-wise è¯­ä¹‰åŒ¹é…ç½‘ç»œ\n",
    "# æ‰€ä»¥æ­¤å¤„å…ˆå®šä¹‰ ERNIE-Gram çš„ pretrained_model\n",
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "#pretrained_model = paddlenlp.transformers.ErnieModel.from_pretrained('ernie-1.0')\n",
    "\n",
    "\n",
    "class PointwiseMatching(nn.Layer):\n",
    "   \n",
    "    # æ­¤å¤„çš„ pretained_model åœ¨æœ¬ä¾‹ä¸­ä¼šè¢« ERNIE-Gram é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–\n",
    "    def __init__(self, pretrained_model, dropout=None):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # è¯­ä¹‰åŒ¹é…ä»»åŠ¡: ç›¸ä¼¼ã€ä¸ç›¸ä¼¼ 2 åˆ†ç±»ä»»åŠ¡\n",
    "        self.classifier = nn.Linear(self.ptm.config[\"hidden_size\"], 2)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        # æ­¤å¤„çš„ Input_ids ç”±ä¸¤æ¡æ–‡æœ¬çš„ token ids æ‹¼æ¥è€Œæˆ\n",
    "        # token_type_ids è¡¨ç¤ºä¸¤æ®µæ–‡æœ¬çš„ç±»å‹ç¼–ç \n",
    "        # è¿”å›çš„ cls_embedding å°±è¡¨ç¤ºè¿™ä¸¤æ®µæ–‡æœ¬ç»è¿‡æ¨¡å‹çš„è®¡ç®—ä¹‹åè€Œå¾—åˆ°çš„è¯­ä¹‰è¡¨ç¤ºå‘é‡\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n",
    "                                    attention_mask)\n",
    "\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "\n",
    "        # åŸºäºæ–‡æœ¬å¯¹çš„è¯­ä¹‰è¡¨ç¤ºå‘é‡è¿›è¡Œ 2 åˆ†ç±»ä»»åŠ¡\n",
    "        logits = self.classifier(cls_embedding)\n",
    "\n",
    "        # å› ä¸ºCrossEntropyLosså·²ç»åŒ…å«softmaxæ“ä½œäº†ï¼Œæ•…è¿™é‡Œä¸åº”è¯¥å†å¯¹logitsåšsoftmaxæ“ä½œ\n",
    "        # å®éªŒè¡¨æ˜ï¼Œä¸å¯¹logitsåšå¤šä½™çš„softmaxæ“ä½œï¼Œå¯ä»¥æœ‰æ•ˆçš„é™ä½è®­ç»ƒé›†çš„æŸå¤±ï¼Œæå‡å‡†ç¡®ç‡ã€‚\n",
    "        #probs = F.softmax(logits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "# å®šä¹‰ Point-wise è¯­ä¹‰åŒ¹é…ç½‘ç»œ\n",
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 æ¨¡å‹è®­ç»ƒ & è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epochs = 3\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "# å®šä¹‰ learning_rate_schedulerï¼Œè´Ÿè´£åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹ lr è¿›è¡Œè°ƒåº¦\n",
    "lr_scheduler = LinearDecayWithWarmup(5E-5, num_training_steps, 0.0)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# å®šä¹‰ Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# é‡‡ç”¨äº¤å‰ç†µ æŸå¤±å‡½æ•°\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# è¯„ä¼°çš„æ—¶å€™é‡‡ç”¨å‡†ç¡®ç‡æŒ‡æ ‡\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# å› ä¸ºè®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶è¦åœ¨éªŒè¯é›†è¿›è¡Œæ¨¡å‹è¯„ä¼°ï¼Œå› æ­¤æˆ‘ä»¬å…ˆå®šä¹‰è¯„ä¼°å‡½æ•°\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        loss = criterion(probs, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "\n",
    "    return np.mean(losses), accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 22380, epoch: 3, batch: 7456, loss: 0.04549, accu: 0.95039, speed: 3.90 step/s\r"
     ]
    }
   ],
   "source": [
    "# æ¥ä¸‹æ¥ï¼Œå¼€å§‹æ­£å¼è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå¯æ³¨é‡Šæ‰è¿™éƒ¨åˆ†\n",
    "\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "\n",
    "print_every_steps = 10\n",
    "evaluate_every_steps = 100\n",
    "\n",
    "best_val_acc = 0.0 \n",
    "\n",
    "save_dir = os.path.join('checkpoints', data_class)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_param_path = os.path.join(save_dir, 'bets_model_state.pdparams')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        probs = model(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        loss = criterion(probs, labels)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        \n",
    "        # æ¯é—´éš” 10 step è¾“å‡ºè®­ç»ƒæŒ‡æ ‡\n",
    "        if global_step % print_every_steps == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, acc,\n",
    "                    print_every_steps / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        # æ¯é—´éš” 100 step åœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°\n",
    "        if global_step % evaluate_every_steps == 0:\n",
    "            loss, acc = evaluate(model, criterion, metric, dev_data_loader)\n",
    "            print(f'eval dev loss: {loss:.5f}, acc: {acc:.5f}')\n",
    "            \n",
    "            # ä»…ä¿å­˜æœ€ä¼˜çš„æ¨¡å‹\n",
    "            if acc > best_val_acc:\n",
    "                best_val_acc = acc\n",
    "\n",
    "                print(f'save model at global step {global_step}, best val acc is {best_val_acc:.5f}!')\n",
    "\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_dir)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè¾“å‡ºå¦‚ä¸‹æ—¥å¿—:\n",
    "```\n",
    "global step 22110, epoch: 3, batch: 7186, loss: 0.19087, accu: 0.93125, speed: 0.40 step/s\n",
    "global step 22120, epoch: 3, batch: 7196, loss: 0.03083, accu: 0.94531, speed: 3.79 step/s\n",
    "global step 22130, epoch: 3, batch: 7206, loss: 0.07848, accu: 0.94063, speed: 4.26 step/s\n",
    "global step 22140, epoch: 3, batch: 7216, loss: 0.10873, accu: 0.94531, speed: 4.24 step/s\n",
    "global step 22150, epoch: 3, batch: 7226, loss: 0.13034, accu: 0.93937, speed: 4.24 step/s\n",
    "global step 22160, epoch: 3, batch: 7236, loss: 0.19423, accu: 0.94323, speed: 3.96 step/s\n",
    "global step 22170, epoch: 3, batch: 7246, loss: 0.32185, accu: 0.94330, speed: 3.94 step/s\n",
    "global step 22180, epoch: 3, batch: 7256, loss: 0.13469, accu: 0.94531, speed: 4.48 step/s\n",
    "global step 22190, epoch: 3, batch: 7266, loss: 0.09357, accu: 0.94444, speed: 4.40 step/s\n",
    "global step 22200, epoch: 3, batch: 7276, loss: 0.17290, accu: 0.94500, speed: 3.82 step/s\n",
    "eval dev loss: 0.30158, acc: 0.89457\n",
    "global step 22210, epoch: 3, batch: 7286, loss: 0.06599, accu: 0.94688, speed: 0.40 step/s\n",
    "global step 22220, epoch: 3, batch: 7296, loss: 0.03316, accu: 0.95000, speed: 4.10 step/s\n",
    "global step 22230, epoch: 3, batch: 7306, loss: 0.15541, accu: 0.95104, speed: 4.18 step/s\n",
    "global step 22240, epoch: 3, batch: 7316, loss: 0.27690, accu: 0.94688, speed: 3.96 step/s\n",
    "global step 22250, epoch: 3, batch: 7326, loss: 0.17896, accu: 0.94437, speed: 4.31 step/s\n",
    "global step 22260, epoch: 3, batch: 7336, loss: 0.15845, accu: 0.94583, speed: 3.43 step/s\n",
    "global step 22270, epoch: 3, batch: 7346, loss: 0.23599, accu: 0.94777, speed: 4.55 step/s\n",
    "global step 22280, epoch: 3, batch: 7356, loss: 0.15914, accu: 0.94414, speed: 4.31 step/s\n",
    "global step 22290, epoch: 3, batch: 7366, loss: 0.14851, accu: 0.94271, speed: 3.98 step/s\n",
    "global step 22300, epoch: 3, batch: 7376, loss: 0.10155, accu: 0.94406, speed: 4.32 step/s\n",
    "eval dev loss: 0.30169, acc: 0.89446\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "åŸºäºé»˜è®¤å‚æ•°é…ç½®è¿›è¡Œå•å¡è®­ç»ƒå¤§æ¦‚è¦æŒç»­ 4 ä¸ªå°æ—¶å·¦å³ï¼Œä¼šè®­ç»ƒå®Œæˆ 3 ä¸ª Epoch, æ¨¡å‹æœ€ç»ˆçš„æ”¶æ•›æŒ‡æ ‡ç»“æœå¦‚ä¸‹:\n",
    "\n",
    "\n",
    "| æ•°æ®é›† | Accuracy |\n",
    "| -------- | -------- |\n",
    "| dev.tsv     | 89.446  |\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°: æˆ‘ä»¬åŸºäº PaddleNLP ï¼Œåˆ©ç”¨ ERNIE-Gram é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨éå¸¸ç®€æ´çš„ä»£ç ï¼Œå°±åœ¨æƒå¨è¯­ä¹‰åŒ¹é…æ•°æ®é›†ä¸Šå–å¾—äº†å¾ˆä¸é”™çš„æ•ˆæœ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.5 æ¨¡å‹é¢„æµ‹\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„è¯­ä¹‰åŒ¹é…æ¨¡å‹å¯¹ä¸€äº›é¢„æµ‹æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚å¾…é¢„æµ‹æ•°æ®ä¸ºæ¯è¡Œéƒ½æ˜¯æ–‡æœ¬å¯¹çš„ tsv æ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ Lcqmc æ•°æ®é›†çš„æµ‹è¯•é›†ä½œä¸ºæˆ‘ä»¬çš„é¢„æµ‹æ•°æ®ï¼Œè¿›è¡Œé¢„æµ‹å¹¶æäº¤é¢„æµ‹ç»“æœåˆ° [åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›](https://aistudio.baidu.com/aistudio/competition/detail/45)\n",
    "\n",
    "ä¸‹è½½æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½çš„è¯­ä¹‰åŒ¹é…æ¨¡å‹, å¹¶è§£å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color='red'><b>ï¼ï¼ï¼è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ï¼ï¼</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ä¸‹è½½æˆ‘ä»¬åŸºäº Lcqmc äº‹å…ˆè®­ç»ƒå¥½çš„è¯­ä¹‰åŒ¹é…æ¨¡å‹å¹¶è§£å‹\n",
    "# ! wget https://paddlenlp.bj.bcebos.com/models/text_matching/ernie_gram_zh_pointwise_matching_model.tar\n",
    "# ! tar -xvf ernie_gram_zh_pointwise_matching_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/lcqmc/test.tsv\n",
      "è°æœ‰ç‹‚ä¸‰è¿™å¼ é«˜æ¸…çš„\tè¿™å¼ é«˜æ¸…å›¾ï¼Œè°æœ‰\n",
      "è‹±é›„è”ç›Ÿä»€ä¹ˆè‹±é›„æœ€å¥½\tè‹±é›„è”ç›Ÿæœ€å¥½è‹±é›„æ˜¯ä»€ä¹ˆ\n",
      "è¿™æ˜¯ä»€ä¹ˆæ„æ€ï¼Œè¢«è¹­ç½‘å—\tæˆ‘ä¹Ÿæ˜¯é†‰äº†ï¼Œè¿™æ˜¯ä»€ä¹ˆæ„æ€\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ•°æ®ç”± 2 åˆ—æ–‡æœ¬æ„æˆ tab åˆ†éš”\n",
    "# Lcqmc é»˜è®¤ä¸‹è½½åˆ°å¦‚ä¸‹è·¯å¾„\n",
    "# ! head -n3 \"${HOME}/.paddlenlp/datasets/LCQMC/lcqmc/lcqmc/test.tsv\"\n",
    "print(get_data_path(data_class=data_class, split='test'))\n",
    "! head -n3 'data/lcqmc/test.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å®šä¹‰é¢„æµ‹å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, data_loader):\n",
    "    \n",
    "    batch_probs = []\n",
    "\n",
    "    # é¢„æµ‹é˜¶æ®µæ‰“å¼€ eval æ¨¡å¼ï¼Œæ¨¡å‹ä¸­çš„ dropout ç­‰æ“ä½œä¼šå…³æ‰\n",
    "    model.eval()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids, token_type_ids = batch_data\n",
    "            input_ids = paddle.to_tensor(input_ids)\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids)\n",
    "            \n",
    "            # è·å–æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡: [batch_size, 2] çš„çŸ©é˜µ\n",
    "            batch_prob = model(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "\n",
    "            batch_probs.append(batch_prob)\n",
    "        batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "\n",
    "        return batch_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å®šä¹‰é¢„æµ‹æ•°æ®çš„ data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# é¢„æµ‹æ•°æ®çš„è½¬æ¢å‡½æ•°\n",
    "# predict æ•°æ®æ²¡æœ‰ label, å› æ­¤ convert_exmaple çš„ is_test å‚æ•°è®¾ä¸º True\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "# é¢„æµ‹æ•°æ®çš„ç»„ batch æ“ä½œ\n",
    "# predict æ•°æ®åªè¿”å› input_ids å’Œ token_type_idsï¼Œå› æ­¤åªéœ€è¦ 2 ä¸ª Pad å¯¹è±¡ä½œä¸º batchify_fn\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment_ids\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "# åŠ è½½é¢„æµ‹æ•°æ®\n",
    "test_dataset = create_dataset(data_class, split='test', is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_sampler = paddle.io.BatchSampler(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ç”Ÿæˆé¢„æµ‹æ•°æ® data_loader\n",
    "predict_data_loader =paddle.io.DataLoader(\n",
    "        dataset=test_dataset.map(trans_func),\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å®šä¹‰é¢„æµ‹æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-11 02:36:17,718] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\n"
     ]
    }
   ],
   "source": [
    "# é€‰æ‹©é¢„è®­ç»ƒernie gramï¼Œå¡«å†™è‡ªå·±çš„ä»£ç \n",
    "pretrained_model = paddlenlp.transformers.ErnieGramModel.from_pretrained('ernie-gram-zh')\n",
    "\n",
    "model = PointwiseMatching(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### åŠ è½½å·²è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dict = paddle.load(save_param_path)\n",
    "model.set_dict(state_dict)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### å¼€å§‹é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[32, 38], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[1   , 1022, 9   , ..., 0   , 0   , 0   ],\n",
      "        [1   , 514 , 904 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 47  , 10  , ..., 0   , 0   , 0   ],\n",
      "        ...,\n",
      "        [1   , 733 , 404 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 134 , 170 , ..., 0   , 0   , 0   ],\n",
      "        [1   , 379 , 3122, ..., 0   , 0   , 0   ]]), Tensor(shape=[32, 38], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(predict_data_loader):\n",
    "    if idx < 1:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# æ‰§è¡Œé¢„æµ‹å‡½æ•°\n",
    "y_probs = predict(model, predict_data_loader)\n",
    "\n",
    "# æ ¹æ®é¢„æµ‹æ¦‚ç‡è·å–é¢„æµ‹ label\n",
    "y_preds = np.argmax(y_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### è¾“å‡ºé¢„æµ‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'æˆ‘é•¿çš„åƒå“ªä¸ªæ˜æ˜Ÿ', 'title': 'æˆ‘é•¿å¾—åƒå“ªä¸ªæ˜æ˜Ÿå•Šå•Š', 'label': 1}"
     ]
    }
   ],
   "source": [
    "# æˆ‘ä»¬æŒ‰ç…§åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›çš„æäº¤æ ¼å¼å°†é¢„æµ‹ç»“æœå­˜å‚¨åœ¨ lcqmc.tsv ä¸­ï¼Œç”¨æ¥åç»­æäº¤\n",
    "# åŒæ—¶å°†é¢„æµ‹ç»“æœè¾“å‡ºåˆ°ç»ˆç«¯ï¼Œä¾¿äºå¤§å®¶ç›´è§‚æ„Ÿå—æ¨¡å‹é¢„æµ‹æ•ˆæœ\n",
    "\n",
    "test_dataset = create_dataset(data_class, split='test', is_test=True)\n",
    "\n",
    "with open(data_class + '.tsv', 'w', encoding='utf-8') as fWriter:\n",
    "    \n",
    "    fWriter.write('index\\tprediction\\n')\n",
    "    for idx, y_pred in enumerate(y_preds):\n",
    "        fWriter.write('{}\\t{}\\n'.format(idx, y_pred))\n",
    "        \n",
    "        text_pair = test_dataset[idx]\n",
    "        text_pair['label'] = y_pred\n",
    "        print(text_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### æäº¤ LCQMC é¢„æµ‹ç»“æœ[åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›](https://aistudio.baidu.com/aistudio/competition/detail/45)\n",
    "\n",
    "åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›ä¸€å…±æœ‰ 3 ä¸ªæ•°æ®é›†: lcqmcã€bq_corpusã€paws-x, æˆ‘ä»¬åˆšæ‰ç”Ÿæˆäº† lcqmc çš„é¢„æµ‹ç»“æœ lcqmc.tsv, åŒæ—¶æˆ‘ä»¬åœ¨é¡¹ç›®å†…æä¾›äº† bq_corpusã€paw-x æ•°æ®é›†çš„ç©ºé¢„æµ‹ç»“æœï¼Œæˆ‘ä»¬å°†è¿™ 3 ä¸ªæ–‡ä»¶æ‰“åŒ…æäº¤åˆ°åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›ï¼Œå³å¯çœ‹åˆ°è‡ªå·±çš„æ¨¡å‹åœ¨ Lcqmc æ•°æ®é›†ä¸Šçš„ç«èµ›æˆç»©ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: lcqmc.tsv (deflated 65%)\r\n",
      "  adding: paws-x.tsv (deflated 61%)\r\n",
      "  adding: bq_corpus.tsv (deflated 62%)\r\n"
     ]
    }
   ],
   "source": [
    "# æ‰“åŒ…é¢„æµ‹ç»“æœ\n",
    "!zip submit.zip lcqmc.tsv paws-x.tsv bq_corpus.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### æäº¤é¢„æµ‹ç»“æœ submit.zip åˆ° [åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›](https://aistudio.baidu.com/aistudio/competition/detail/45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# åƒè¨€æ–‡æœ¬ç›¸ä¼¼åº¦ç«èµ›ç»“æœæˆªå›¾\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/649c72f405fc42d394ee6411297b1ac542c9838ef69a465d9aea05662216847e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
