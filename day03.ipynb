{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业\n",
    "\n",
    "更换数据集MSRA和ERNIE-Gram或BERT等预训练模型。\n",
    "\n",
    "- 数据集：\n",
    "`train_ds, test_ds = load_dataset(\"msra_ner\", splits=[\"train\", \"test\"])`\n",
    "- 模型：\n",
    "\t将`from paddlenlp.transformers import ErnieTokenizer, ErnieForTokenClassification`换成相应的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用PaddleNLP语义预训练模型ERNIE完成快递单信息抽取\n",
    "\n",
    "\n",
    "**注意**\n",
    "\n",
    "本项目代码需要使用GPU环境来运行:\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/767f625548714f03b105b6ccb3aa78df9080e38d329e445380f505ddec6c7042\" width=\"40%\" height=\"40%\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "命名实体识别是NLP中一项非常基础的任务，是信息提取、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工具。命名实体识别的准确度，决定了下游任务的效果，是NLP中的一个基础问题。在NER任务提供了两种解决方案，一类LSTM/GRU + CRF，通过RNN类的模型来抽取底层文本的信息，而CRF(条件随机场)模型来学习底层Token之间的联系；另外一类是通过预训练模型，例如ERNIE，BERT模型，直接来预测Token的标签信息。\n",
    "\n",
    "本项目将演示如何使用PaddleNLP语义预训练模型ERNIE完成从快递单中抽取姓名、电话、省、市、区、详细地址等内容，形成结构化信息。辅助物流行业从业者进行有效信息的提取，从而降低客户填单的成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在2017年之前，工业界和学术界对文本处理依赖于序列模型[Recurrent Neural Network (RNN)](https://baike.baidu.com/item/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/23199490?fromtitle=RNN&fromid=5707183&fr=aladdin).\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-general.png\" width=\"40%\" height=\"30%\"> <br />\n",
    "</p><br><center>图1：RNN示意图</center></br>\n",
    "\n",
    "[基于BiGRU+CRF的快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)项目介绍了如何使用序列模型完成快递单信息抽取任务。\n",
    "<br>\n",
    "\n",
    "近年来随着深度学习的发展，模型参数的数量飞速增长。为了训练这些参数，需要更大的数据集来避免过拟合。然而，对于大部分NLP任务来说，构建大规模的标注数据集非常困难（成本过高），特别是对于句法和语义相关的任务。相比之下，大规模的未标注语料库的构建则相对容易。为了利用这些数据，我们可以先从其中学习到一个好的表示，再将这些表示应用到其他任务中。最近的研究表明，基于大规模未标注语料库的预训练模型（Pretrained Models, PTM) 在NLP任务上取得了很好的表现。\n",
    "\n",
    "近年来，大量的研究表明基于大型语料库的预训练模型（Pretrained Models, PTM）可以学习通用的语言表示，有利于下游NLP任务，同时能够避免从零开始训练模型。随着计算能力的不断提高，深度模型的出现（即 Transformer）和训练技巧的增强使得 PTM 不断发展，由浅变深。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/327f44ff3ed24493adca5ddc4dc24bf61eebe67c84a6492f872406f464fde91e\" width=\"60%\" height=\"50%\"> <br />\n",
    "</p><br><center>图2：预训练模型一览，图片来源于：https://github.com/thunlp/PLMpapers</center></br>\n",
    "                                                                                                                             \n",
    "本示例展示了以ERNIE([Enhanced Representation through Knowledge Integration](https://arxiv.org/pdf/1904.09223))为代表的预训练模型如何Finetune完成序列标注任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**记得给[PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)点个小小的Star⭐**\n",
    "\n",
    "开源不易，希望大家多多支持~ \n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a0e8ca7743ea4fe9aa741682a63e767f8c48dc55981f4e44a40e0e00d3ab369e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AI Studio平台后续会默认安装PaddleNLP，在此之前可使用如下命令安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting paddlenlp\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/b1/e9/128dfc1371db3fc2fa883d8ef27ab6b21e3876e76750a43f58cf3c24e707/paddlenlp-2.0.2-py3-none-any.whl (426kB)\n",
      "\u001b[K     |████████████████████████████████| 430kB 14.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied, skipping upgrade: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied, skipping upgrade: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.7.1.1)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.21.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.14.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\n",
      "Requirement already satisfied, skipping upgrade: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (3.8.2)\n",
      "Requirement already satisfied, skipping upgrade: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.4.10)\n",
      "Requirement already satisfied, skipping upgrade: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (16.7.9)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied, skipping upgrade: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp) (1.25.6)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.10.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied, skipping upgrade: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\n",
      "Requirement already satisfied, skipping upgrade: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl->paddlenlp) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->visualdl->paddlenlp) (7.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Found existing installation: paddlenlp 2.0.1\n",
      "    Uninstalling paddlenlp-2.0.1:\n",
      "      Successfully uninstalled paddlenlp-2.0.1\n",
      "Successfully installed paddlenlp-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import paddlenlp\r\n",
    "\r\n",
    "print(paddlenlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 下载 MSRA-NER 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-12 04:18:27--  https://paddlenlp.bj.bcebos.com/datasets/msra_ner.tar.gz\n",
      "Resolving paddlenlp.bj.bcebos.com (paddlenlp.bj.bcebos.com)... 182.61.200.229, 182.61.200.195, 2409:8c00:6c21:10ad:0:ff:b00e:67d\n",
      "Connecting to paddlenlp.bj.bcebos.com (paddlenlp.bj.bcebos.com)|182.61.200.229|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3743966 (3.6M) [application/octet-stream]\n",
      "Saving to: ‘msra_ner.tar.gz’\n",
      "\n",
      "msra_ner.tar.gz     100%[===================>]   3.57M  21.3MB/s    in 0.2s    \n",
      "\n",
      "2021-06-12 04:18:28 (21.3 MB/s) - ‘msra_ner.tar.gz’ saved [3743966/3743966]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载 msra-ner 数据集到当前目录\r\n",
    "!wget https://paddlenlp.bj.bcebos.com/datasets/msra_ner.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msra_ner/\n",
      "msra_ner/train.tsv\n",
      "msra_ner/label_map.json\n",
      "msra_ner/test.tsv\n"
     ]
    }
   ],
   "source": [
    "# 解压msra-ner数据集\r\n",
    "!tar -zxvf ./msra_ner.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "解压后的msra_ner目录下有三个文件：train.tsv, test.tsv, label_map.json\n",
    "\n",
    "其中 train.tsv 和 test.tsv 的每一行为一个样本，样本格式为：\n",
    "\n",
    "tokens\tlabels\n",
    "\n",
    "tokens 为需要标注的样本，labels 为标注信息，二者由制表符(\\t)隔开。tokens 中的每一个字和labels中的每一个标注由STX（即\\002）字符隔开。\n",
    "\n",
    "label_map.json，即标记字典文件，存放了每一标记和标记ID的映射："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "MSRA-NER数据集中，训练集包含45000个样本，测试集包含3442个样本。\n",
    "\n",
    "数据集包含三类实体：人物(Person), 组织机构（Organization），地点（Location）和其他（Other），对应的标记简写为：PER，ORG，LOC和O。\n",
    "\n",
    "数据集采用BIO标注的方式，label_map.json文件，即标记字典文件，存放了每一个标记和标记ID的映射：\n",
    "\n",
    "```\n",
    "    {\n",
    "      \"B-PER\": 0,\n",
    "      \"I-PER\": 1,\n",
    "      \"B-ORG\": 2,\n",
    "      \"I-ORG\": 3,\n",
    "      \"B-LOC\": 4,\n",
    "      \"I-LOC\": 5,\n",
    "      \"O\": 6\n",
    "    }\n",
    "```\n",
    "\n",
    "每一个标记的含义如下：\n",
    "\n",
    "|标记|含义|\n",
    "|---|---|\n",
    "|B-PER|人名的开始字符|\n",
    "|I-PER|人名的非开始字符|\n",
    "|B-ORG|组织机构名的开始字符|\n",
    "|I-ORG|组织机构名的非开始字符|\n",
    "|B-LOC|地点/位置名的开始字符|\n",
    "|I-LOC|地点/位置名的非开始字符|\n",
    "|O|非命名实体部分|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练集包含 45000个样本，测试集包含3442个样本，由于没有验证集，因此我们需要从训练集中划分出与测试集规模相当的验证集出来，用于在训练过程中对模型进行评估。测试集保持不变。我们选择从训练集中随机抽取3000个样本作为验证集。\n",
    "\n",
    "|数据集|样本数|\n",
    "|---|---|\n",
    "|train set| 42000|\n",
    "|dev set|3000|\n",
    "|test set|3442|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(train_file, proportion=3000):\r\n",
    "    \"\"\"\r\n",
    "    proportion: int or float\r\n",
    "    \"\"\"\r\n",
    "    with open(train_file, 'r', encoding='utf-8') as fRead:\r\n",
    "        train_data = []\r\n",
    "        for line in fRead.readlines():\r\n",
    "            train_data.append(line.strip('\\n'))\r\n",
    "        \r\n",
    "        data_id = list(range(len(train_data)))\r\n",
    "\r\n",
    "        train_len = len(data_id)\r\n",
    "        \r\n",
    "        if isinstance(proportion , int):\r\n",
    "            test_split_len = proportion\r\n",
    "        elif isinstance(proportion, float):\r\n",
    "            test_split_len = int(train_len * proportion)\r\n",
    "        else:\r\n",
    "            raise ValueError('proportion must be int or float!')\r\n",
    "\r\n",
    "\r\n",
    "        import random\r\n",
    "        random.seed(5233)\r\n",
    "        random.shuffle(data_id)\r\n",
    "\r\n",
    "        test_split_data = [train_data[idx] for idx in data_id[:test_split_len]]\r\n",
    "        train_split_data = [train_data[idx] for idx in data_id[test_split_len:]]\r\n",
    "\r\n",
    "        import os\r\n",
    "        data_dir = './msra_ner/data/msra'\r\n",
    "        if not os.path.exists(data_dir):\r\n",
    "            os.makedirs(data_dir)\r\n",
    "\r\n",
    "        train_file = os.path.join(data_dir, 'train.tsv')\r\n",
    "        test_file = os.path.join(data_dir, 'dev.tsv')\r\n",
    "\r\n",
    "        with open(train_file, 'w', encoding='utf-8') as fWriter1:\r\n",
    "            for train_line in train_split_data:\r\n",
    "                fWriter1.write(train_line + '\\n')\r\n",
    "\r\n",
    "        with open(test_file, 'w', encoding='utf-8') as fWriter2:\r\n",
    "            for test_line in test_split_data:\r\n",
    "                fWriter2.write(test_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_split('./msra_ner/train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp ./msra_ner/test.tsv ./msra_ner/data/msra/test.tsv\r\n",
    "!cp ./msra_ner/label_map.json ./msra_ner/data/msra/label_map.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "train_data = []\r\n",
    "with open('./msra_ner/data/msra/train.tsv', 'r', encoding='utf-8') as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        train_data.append(line)\r\n",
    "\r\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 加载自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "\n",
    "def read(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as fRead:\n",
    "        for line in fRead:\n",
    "            tokens, labels = line.strip('\\n').split('\\t')\n",
    "            tokens = tokens.split('\\002')  # \\002 即 STX 字符\n",
    "            labels = labels.split('\\002')\n",
    "            yield {'tokens': tokens, 'labels': labels}\n",
    "\n",
    "data_dir = './msra_ner/data/msra'\n",
    "train_file = os.path.join(data_dir, 'train.tsv')\n",
    "dev_file = os.path.join(data_dir, 'dev.tsv')\n",
    "test_file = os.path.join(data_dir, 'test.tsv')\n",
    "\n",
    "train_dataset = load_dataset(read, data_path=train_file, lazy=False)\n",
    "dev_dataset = load_dataset(read, data_path=dev_file, lazy=False)\n",
    "test_dataset = load_dataset(read, data_path=test_file, lazy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['苗', '苗', '妈', '妈', '给', '孩', '子', '以', '信', '任', '和', '期', '待', '，', '并', '且', '巧', '妙', '地', '从', '孩', '子', '力', '所', '能', '及', '的', '日', '常', '生', '活', '小', '事', '出', '发', '，', '让', '孩', '子', '在', '劳', '动', '中', '体', '验', '生', '活', '的', '苦', '与', '乐', '。'], 'labels': ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'tokens': ['郎', '青', '山', '亲', '自', '抓', '产', '供', '销', '和', '技', '术', '改', '造', '，', '副', '总', '经', '理', '分', '管', '财', '务', '、', '后', '勤', '和', '生', '产', '调', '度', '，', '其', '他', '人', '负', '责', '技', '术', '监', '督', '。'], 'labels': ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'tokens': ['日', '本', '官', '方', '近', '来', '就', '日', '美', '防', '卫', '合', '作', '指', '针', '的', '适', '用', '范', '围', '是', '否', '包', '括', '中', '国', '台', '湾', '，', '发', '表', '了', '自', '相', '矛', '盾', '的', '言', '论', '，', '遭', '到', '中', '国', '舆', '论', '的', '谴', '责', '。'], 'labels': ['B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "for idx, ex in enumerate(train_dataset):\n",
    "    if idx < 3:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "每条数据包含一句文本和这个文本中每个汉字以及数字对应的label标签。\n",
    "\n",
    "之后，还需要对输入句子进行数据处理，如切词，映射词表id等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据处理 —— 构建BERT模型输入特征\n",
    "\n",
    "预训练模型ERNIE对中文数据的处理是以字为单位。PaddleNLP对于各种预训练模型已经内置了相应的tokenizer。指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "tokenizer作用为将原始输入文本转化成模型model可以接受的输入数据形式。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_1.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_2.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "<br><center>图3：ERNIE模型示意图</center></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "加载标记字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-PER': 0, 'I-PER': 1, 'B-ORG': 2, 'I-ORG': 3, 'B-LOC': 4, 'I-LOC': 5, 'O': 6}\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import json\r\n",
    "\r\n",
    "\r\n",
    "with open('./msra_ner/data/msra/label_map.json', 'r', encoding='utf-8') as fRead:\r\n",
    "    label_vocab = json.load(fRead)\r\n",
    "\r\n",
    "print(label_vocab)\r\n",
    "\r\n",
    "print(len(label_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-12 04:33:50,743] [    INFO] - Downloading bert-base-chinese-vocab.txt from https://paddle-hapi.bj.bcebos.com/models/bert/bert-base-chinese-vocab.txt\n",
      "100%|██████████| 107/107 [00:00<00:00, 3273.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([101, 5728, 5728, 1968, 1968, 5314, 2111, 2094, 809, 928, 818, 1469, 3309, 2521, 8024, 2400, 684, 2341, 1975, 1765, 794, 2111, 2094, 1213, 2792, 5543, 1350, 4638, 3189, 2382, 4495, 3833, 2207, 752, 1139, 1355, 8024, 6375, 2111, 2094, 1762, 1227, 1220, 704, 860, 7741, 4495, 3833, 4638, 5736, 680, 727, 511, 102], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 54, [6, 0, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import BertTokenizer\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "def convert_example(example, tokenizer, label_vocab, max_seq_len=512):\n",
    "    tokens, labels = example['tokens'], example['labels']\n",
    "    \n",
    "    tokenized_inputs = tokenizer(tokens, return_length=True, is_split_into_words=True, max_seq_len=max_seq_len)\n",
    "\n",
    "    labels = [label_vocab[label] for label in labels]\n",
    "    if len(labels) + 2 > max_seq_len:\n",
    "        labels = labels[: max_seq_len - 2] \n",
    "\n",
    "    tokenized_inputs['labels'] = [label_vocab['O']] + labels + [label_vocab['O']] \n",
    "\n",
    "    return tokenized_inputs['input_ids'], tokenized_inputs['token_type_ids'], tokenized_inputs['seq_len'], tokenized_inputs['labels']\n",
    "\n",
    "for idx, example in enumerate(train_dataset):\n",
    "    if idx < 1:\n",
    "        print(convert_example(example, tokenizer, label_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paddlenlp.datasets.dataset.MapDataset at 0x7f83ce011ed0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\r\n",
    "\r\n",
    "\r\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer, label_vocab=label_vocab)\r\n",
    "\r\n",
    "train_dataset.map(trans_func)\r\n",
    "dev_dataset.map(trans_func)\r\n",
    "test_dataset.map(trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([101, 5728, 5728, 1968, 1968, 5314, 2111, 2094, 809, 928, 818, 1469, 3309, 2521, 8024, 2400, 684, 2341, 1975, 1765, 794, 2111, 2094, 1213, 2792, 5543, 1350, 4638, 3189, 2382, 4495, 3833, 2207, 752, 1139, 1355, 8024, 6375, 2111, 2094, 1762, 1227, 1220, 704, 860, 7741, 4495, 3833, 4638, 5736, 680, 727, 511, 102], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 54, [6, 0, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])\n",
      "([101, 6947, 7471, 2255, 779, 5632, 2831, 772, 897, 7218, 1469, 2825, 3318, 3121, 6863, 8024, 1199, 2600, 5307, 4415, 1146, 5052, 6568, 1218, 510, 1400, 1249, 1469, 4495, 772, 6444, 2428, 8024, 1071, 800, 782, 6566, 6569, 2825, 3318, 4664, 4719, 511, 102], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 44, [6, 0, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])\n",
      "([101, 3189, 3315, 2135, 3175, 6818, 3341, 2218, 3189, 5401, 7344, 1310, 1394, 868, 2900, 7151, 4638, 6844, 4500, 5745, 1741, 3221, 1415, 1259, 2886, 704, 1744, 1378, 3968, 8024, 1355, 6134, 749, 5632, 4685, 4757, 4688, 4638, 6241, 6389, 8024, 6901, 1168, 704, 1744, 5644, 6389, 4638, 6482, 6569, 511, 102], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 52, [6, 4, 5, 6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 5, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 5, 6, 6, 6, 6, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "for idx, example in enumerate(train_dataset):\r\n",
    "    if idx < 3:\r\n",
    "        print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据读入 —— 构建数据集加载器 DataLoader\n",
    "\n",
    "使用`paddle.io.DataLoader`接口多线程异步加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.io import DataLoader\n",
    "from paddle.io import DistributedBatchSampler\n",
    "from paddle.io import BatchSampler\n",
    "from paddlenlp.data import Pad\n",
    "from paddlenlp.data import Stack\n",
    "from paddlenlp.data import Tuple\n",
    "\n",
    "\n",
    "pad_label_id = -1\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id), # token_type_ids\n",
    "    Stack(), # seq_len\n",
    "    Pad(axis=0, pad_val=pad_label_id)  # labels\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "train_batch_sampler = DistributedBatchSampler(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_sampler=train_batch_sampler, \n",
    "    collate_fn=batchify_fn, \n",
    "    return_list=True\n",
    ")\n",
    "\n",
    "dev_batch_sampler = BatchSampler(\n",
    "    dataset=dev_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "dev_data_loader = DataLoader(\n",
    "    dataset=dev_dataset,\n",
    "    batch_sampler=dev_batch_sampler,\n",
    "    collate_fn=batchify_fn,\n",
    "    return_list=True\n",
    ")\n",
    "\n",
    "test_batch_sampler = BatchSampler(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    collate_fn=batchify_fn,\n",
    "    return_list=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PaddleNLP一键加载预训练模型\n",
    "\n",
    "\n",
    "快递单信息抽取本质是一个序列标注任务，PaddleNLP对于各种预训练模型已经内置了对于下游任务文本分类Fine-tune网络。以下教程以ERNIE为预训练模型完成序列标注任务。\n",
    "\n",
    "`paddlenlp.transformers.ErnieForTokenClassification()`一行代码即可加载预训练模型ERNIE用于序列标注任务的fine-tune网络。其在ERNIE模型后拼接上一个全连接网络进行分类。\n",
    "\n",
    "`paddlenlp.transformers.ErnieForTokenClassification.from_pretrained()`方法只需指定想要使用的模型名称和文本分类的类别数即可完成定义模型网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-12 04:38:43,988] [    INFO] - Downloading http://paddlenlp.bj.bcebos.com/models/transformers/bert/bert-base-chinese.pdparams and saved to /home/aistudio/.paddlenlp/models/bert-base-chinese\n",
      "[2021-06-12 04:38:44,019] [    INFO] - Downloading bert-base-chinese.pdparams from http://paddlenlp.bj.bcebos.com/models/transformers/bert/bert-base-chinese.pdparams\n",
      "100%|██████████| 696494/696494 [00:14<00:00, 47208.45it/s]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import BertForTokenClassification\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-chinese', num_classes=len(label_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "PaddleNLP不仅支持ERNIE预训练模型，还支持BERT、RoBERTa、Electra等预训练模型。\n",
    "下表汇总了目前PaddleNLP支持的各类预训练模型。您可以使用PaddleNLP提供的模型，完成文本分类、序列标注、问答等任务。同时我们提供了众多预训练模型的参数权重供用户使用，其中包含了二十多种中文语言模型的预训练权重。中文的预训练模型有`bert-base-chinese, bert-wwm-chinese, bert-wwm-ext-chinese, ernie-1.0, ernie-tiny, gpt2-base-cn, roberta-wwm-ext, roberta-wwm-ext-large, rbt3, rbtl3, chinese-electra-base, chinese-electra-small, chinese-xlnet-base, chinese-xlnet-mid, chinese-xlnet-large, unified_transformer-12L-cn, unified_transformer-12L-cn-luge`等。\n",
    "\n",
    "更多预训练模型参考：[PaddleNLP Transformer API](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/transformers.md)。\n",
    "\n",
    "更多预训练模型fine-tune下游任务使用方法，请参考：[examples](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 设置Fine-Tune优化策略，模型配置\n",
    "适用于ERNIE/BERT这类Transformer模型的迁移优化学习率策略为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p><br><center>图4：动态学习率示意图</center></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.nn import CrossEntropyLoss\n",
    "from paddle.optimizer import AdamW\n",
    "from paddlenlp.metrics import ChunkEvaluator\n",
    "\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epochs = 5\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(2e-5, num_training_steps, 0.0)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 采用交叉熵 损失函数\n",
    "loss_fn = CrossEntropyLoss(ignore_index=pad_label_id)\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = ChunkEvaluator(label_list=label_vocab.keys(), suffix=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data\n",
    "2. 将batch data喂给model，做前向计算\n",
    "3. 将前向计算结果传给损失函数，计算loss。将前向计算结果传给评价方法，计算评价指标。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch时，程序将会评估一次，评估当前模型训练的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "@paddle.no_grad()\r\n",
    "def evaluate(model,loss_fn, metric, data_loader):\r\n",
    "    model.eval()\r\n",
    "    metric.reset()\r\n",
    "\r\n",
    "    losses = []\r\n",
    "\r\n",
    "    for batch_data in data_loader:\r\n",
    "\r\n",
    "        input_ids, token_type_ids, length, labels = batch_data\r\n",
    "\r\n",
    "        logits = model(input_ids, token_type_ids)\r\n",
    "\r\n",
    "        loss = loss_fn(logits, labels)\r\n",
    "        losses.append(loss.numpy())\r\n",
    "\r\n",
    "        preds = paddle.argmax(logits, axis=-1)\r\n",
    "        n_infer, n_label, n_correct = metric.compute(None, length, preds, labels)\r\n",
    "        metric.update(n_infer.numpy(), n_label.numpy(), n_correct.numpy())\r\n",
    "        precission, recall, f1_score = metric.accumulate()\r\n",
    "\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    return np.mean(losses), precission, recall, f1_score\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.float32, but right dtype is paddle.bool, the right dtype will convert to paddle.float32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "[2021-06-12 04:53:22,019] [ WARNING] - Compatibility Warning: The params of ChunkEvaluator.compute has been modified. The old version is `inputs`, `lengths`, `predictions`, `labels` while the current version is `lengths`, `predictions`, `labels`.  Please update the usage.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 10, epoch: 0, batch: 9, loss: 0.38094, precission: 0.00038, recall: 0.00223, f1_score: 0.00065, speed: 4.26 step/s\n",
      "global_step: 20, epoch: 0, batch: 19, loss: 0.38861, precission: 0.00038, recall: 0.00108, f1_score: 0.00056, speed: 3.80 step/s\n",
      "global_step: 30, epoch: 0, batch: 29, loss: 0.23985, precission: 0.00212, recall: 0.00422, f1_score: 0.00283, speed: 4.78 step/s\n",
      "global_step: 40, epoch: 0, batch: 39, loss: 0.24867, precission: 0.01549, recall: 0.02669, f1_score: 0.01960, speed: 4.64 step/s\n",
      "global_step: 50, epoch: 0, batch: 49, loss: 0.10196, precission: 0.07232, recall: 0.11760, f1_score: 0.08956, speed: 4.50 step/s\n",
      "global_step: 60, epoch: 0, batch: 59, loss: 0.10404, precission: 0.12995, recall: 0.20321, f1_score: 0.15853, speed: 4.02 step/s\n",
      "global_step: 70, epoch: 0, batch: 69, loss: 0.12064, precission: 0.18256, recall: 0.27677, f1_score: 0.22000, speed: 3.62 step/s\n",
      "global_step: 80, epoch: 0, batch: 79, loss: 0.11108, precission: 0.21901, recall: 0.32335, f1_score: 0.26114, speed: 4.34 step/s\n",
      "global_step: 90, epoch: 0, batch: 89, loss: 0.09889, precission: 0.26277, recall: 0.37785, f1_score: 0.30998, speed: 3.79 step/s\n",
      "global_step: 100, epoch: 0, batch: 99, loss: 0.06404, precission: 0.29874, recall: 0.42071, f1_score: 0.34939, speed: 4.47 step/s\n",
      "eval dev loss: 0.05483, precission: 0.75670, recall: 0.82756, f1_score: 0.79054\n",
      "save model at global step : 100, best_precission: 0.75670, best_recall: 0.82756, best val f1_score: 0.79054\n",
      "global_step: 110, epoch: 0, batch: 109, loss: 0.04443, precission: 0.75319, recall: 0.82259, f1_score: 0.78636, speed: 0.61 step/s\n",
      "global_step: 120, epoch: 0, batch: 119, loss: 0.08168, precission: 0.75300, recall: 0.82313, f1_score: 0.78651, speed: 4.16 step/s\n",
      "global_step: 130, epoch: 0, batch: 129, loss: 0.05394, precission: 0.75665, recall: 0.82412, f1_score: 0.78894, speed: 4.62 step/s\n",
      "global_step: 140, epoch: 0, batch: 139, loss: 0.05788, precission: 0.75649, recall: 0.82218, f1_score: 0.78797, speed: 4.20 step/s\n",
      "global_step: 150, epoch: 0, batch: 149, loss: 0.03634, precission: 0.75879, recall: 0.82480, f1_score: 0.79042, speed: 3.46 step/s\n",
      "global_step: 160, epoch: 0, batch: 159, loss: 0.03350, precission: 0.76039, recall: 0.82495, f1_score: 0.79135, speed: 4.55 step/s\n",
      "global_step: 170, epoch: 0, batch: 169, loss: 0.04241, precission: 0.76244, recall: 0.82623, f1_score: 0.79306, speed: 3.61 step/s\n",
      "global_step: 180, epoch: 0, batch: 179, loss: 0.03335, precission: 0.76303, recall: 0.82585, f1_score: 0.79319, speed: 3.66 step/s\n",
      "global_step: 190, epoch: 0, batch: 189, loss: 0.07256, precission: 0.76495, recall: 0.82636, f1_score: 0.79447, speed: 4.08 step/s\n",
      "global_step: 200, epoch: 0, batch: 199, loss: 0.02070, precission: 0.76715, recall: 0.82851, f1_score: 0.79665, speed: 3.58 step/s\n",
      "eval dev loss: 0.03885, precission: 0.84361, recall: 0.88016, f1_score: 0.86150\n",
      "save model at global step : 200, best_precission: 0.84361, best_recall: 0.88016, best val f1_score: 0.86150\n",
      "global_step: 210, epoch: 0, batch: 209, loss: 0.02491, precission: 0.83910, recall: 0.87560, f1_score: 0.85696, speed: 0.61 step/s\n",
      "global_step: 220, epoch: 0, batch: 219, loss: 0.04212, precission: 0.83558, recall: 0.87151, f1_score: 0.85317, speed: 4.62 step/s\n",
      "global_step: 230, epoch: 0, batch: 229, loss: 0.06633, precission: 0.83353, recall: 0.87174, f1_score: 0.85221, speed: 2.97 step/s\n",
      "global_step: 240, epoch: 0, batch: 239, loss: 0.02656, precission: 0.83082, recall: 0.87032, f1_score: 0.85011, speed: 3.16 step/s\n",
      "global_step: 250, epoch: 0, batch: 249, loss: 0.07761, precission: 0.82622, recall: 0.86806, f1_score: 0.84662, speed: 4.16 step/s\n",
      "global_step: 260, epoch: 0, batch: 259, loss: 0.01036, precission: 0.82782, recall: 0.86833, f1_score: 0.84759, speed: 4.02 step/s\n",
      "global_step: 270, epoch: 0, batch: 269, loss: 0.01448, precission: 0.83001, recall: 0.86848, f1_score: 0.84881, speed: 3.05 step/s\n",
      "global_step: 280, epoch: 0, batch: 279, loss: 0.04213, precission: 0.83273, recall: 0.87110, f1_score: 0.85148, speed: 4.51 step/s\n",
      "global_step: 290, epoch: 0, batch: 289, loss: 0.05611, precission: 0.83108, recall: 0.87008, f1_score: 0.85013, speed: 4.43 step/s\n",
      "global_step: 300, epoch: 0, batch: 299, loss: 0.04695, precission: 0.83097, recall: 0.87007, f1_score: 0.85007, speed: 4.67 step/s\n",
      "eval dev loss: 0.03378, precission: 0.85857, recall: 0.88779, f1_score: 0.87293\n",
      "save model at global step : 300, best_precission: 0.85857, best_recall: 0.88779, best val f1_score: 0.87293\n",
      "global_step: 310, epoch: 0, batch: 309, loss: 0.01486, precission: 0.85704, recall: 0.88658, f1_score: 0.87156, speed: 0.61 step/s\n",
      "global_step: 320, epoch: 0, batch: 319, loss: 0.03321, precission: 0.85432, recall: 0.88585, f1_score: 0.86980, speed: 4.53 step/s\n",
      "global_step: 330, epoch: 0, batch: 329, loss: 0.02696, precission: 0.85497, recall: 0.88499, f1_score: 0.86972, speed: 4.50 step/s\n",
      "global_step: 340, epoch: 0, batch: 339, loss: 0.02801, precission: 0.85313, recall: 0.88501, f1_score: 0.86878, speed: 4.45 step/s\n",
      "global_step: 350, epoch: 0, batch: 349, loss: 0.04867, precission: 0.85344, recall: 0.88525, f1_score: 0.86905, speed: 3.17 step/s\n",
      "global_step: 360, epoch: 0, batch: 359, loss: 0.02701, precission: 0.85128, recall: 0.88473, f1_score: 0.86768, speed: 3.35 step/s\n",
      "global_step: 370, epoch: 0, batch: 369, loss: 0.04299, precission: 0.85165, recall: 0.88571, f1_score: 0.86835, speed: 4.34 step/s\n",
      "global_step: 380, epoch: 0, batch: 379, loss: 0.04844, precission: 0.85160, recall: 0.88665, f1_score: 0.86877, speed: 4.27 step/s\n",
      "global_step: 390, epoch: 0, batch: 389, loss: 0.01916, precission: 0.85088, recall: 0.88566, f1_score: 0.86792, speed: 4.27 step/s\n",
      "global_step: 400, epoch: 0, batch: 399, loss: 0.05304, precission: 0.84988, recall: 0.88528, f1_score: 0.86722, speed: 4.09 step/s\n",
      "eval dev loss: 0.02801, precission: 0.87674, recall: 0.91997, f1_score: 0.89784\n",
      "save model at global step : 400, best_precission: 0.87674, best_recall: 0.91997, best val f1_score: 0.89784\n",
      "global_step: 410, epoch: 0, batch: 409, loss: 0.01724, precission: 0.87209, recall: 0.91707, f1_score: 0.89401, speed: 0.60 step/s\n",
      "global_step: 420, epoch: 0, batch: 419, loss: 0.03668, precission: 0.86901, recall: 0.91461, f1_score: 0.89123, speed: 3.38 step/s\n",
      "global_step: 430, epoch: 0, batch: 429, loss: 0.04351, precission: 0.86357, recall: 0.91058, f1_score: 0.88645, speed: 3.55 step/s\n",
      "global_step: 440, epoch: 0, batch: 439, loss: 0.03951, precission: 0.86507, recall: 0.91129, f1_score: 0.88758, speed: 4.29 step/s\n",
      "global_step: 450, epoch: 0, batch: 449, loss: 0.03318, precission: 0.86501, recall: 0.90947, f1_score: 0.88668, speed: 4.61 step/s\n",
      "global_step: 460, epoch: 0, batch: 459, loss: 0.02722, precission: 0.86397, recall: 0.90847, f1_score: 0.88566, speed: 4.26 step/s\n",
      "global_step: 470, epoch: 0, batch: 469, loss: 0.03163, precission: 0.86344, recall: 0.90798, f1_score: 0.88515, speed: 4.47 step/s\n",
      "global_step: 480, epoch: 0, batch: 479, loss: 0.03522, precission: 0.86432, recall: 0.90771, f1_score: 0.88548, speed: 4.03 step/s\n",
      "global_step: 490, epoch: 0, batch: 489, loss: 0.03149, precission: 0.86393, recall: 0.90760, f1_score: 0.88523, speed: 3.97 step/s\n",
      "global_step: 500, epoch: 0, batch: 499, loss: 0.02040, precission: 0.86240, recall: 0.90664, f1_score: 0.88397, speed: 4.10 step/s\n",
      "eval dev loss: 0.02580, precission: 0.90234, recall: 0.91295, f1_score: 0.90762\n",
      "global_step: 510, epoch: 0, batch: 509, loss: 0.02340, precission: 0.89424, recall: 0.90567, f1_score: 0.89992, speed: 0.88 step/s\n",
      "global_step: 520, epoch: 0, batch: 519, loss: 0.05168, precission: 0.88966, recall: 0.90422, f1_score: 0.89688, speed: 3.92 step/s\n",
      "global_step: 530, epoch: 0, batch: 529, loss: 0.07082, precission: 0.88537, recall: 0.90155, f1_score: 0.89339, speed: 3.63 step/s\n",
      "global_step: 540, epoch: 0, batch: 539, loss: 0.03040, precission: 0.88338, recall: 0.90191, f1_score: 0.89255, speed: 4.07 step/s\n",
      "global_step: 550, epoch: 0, batch: 549, loss: 0.02849, precission: 0.88147, recall: 0.90019, f1_score: 0.89073, speed: 4.19 step/s\n",
      "global_step: 560, epoch: 0, batch: 559, loss: 0.05826, precission: 0.88265, recall: 0.90247, f1_score: 0.89245, speed: 4.58 step/s\n",
      "global_step: 570, epoch: 0, batch: 569, loss: 0.02202, precission: 0.88179, recall: 0.90172, f1_score: 0.89164, speed: 4.27 step/s\n",
      "global_step: 580, epoch: 0, batch: 579, loss: 0.06813, precission: 0.88176, recall: 0.90215, f1_score: 0.89184, speed: 2.61 step/s\n",
      "global_step: 590, epoch: 0, batch: 589, loss: 0.03664, precission: 0.88197, recall: 0.90391, f1_score: 0.89281, speed: 4.28 step/s\n",
      "global_step: 600, epoch: 0, batch: 599, loss: 0.01403, precission: 0.88141, recall: 0.90366, f1_score: 0.89240, speed: 4.27 step/s\n",
      "eval dev loss: 0.02474, precission: 0.90704, recall: 0.92781, f1_score: 0.91730\n",
      "save model at global step : 600, best_precission: 0.90704, best_recall: 0.92781, best val f1_score: 0.91730\n",
      "global_step: 610, epoch: 0, batch: 609, loss: 0.01490, precission: 0.90386, recall: 0.92551, f1_score: 0.91456, speed: 0.63 step/s\n",
      "global_step: 620, epoch: 0, batch: 619, loss: 0.01908, precission: 0.90109, recall: 0.92474, f1_score: 0.91276, speed: 4.61 step/s\n",
      "global_step: 630, epoch: 0, batch: 629, loss: 0.01916, precission: 0.90258, recall: 0.92620, f1_score: 0.91424, speed: 2.86 step/s\n",
      "global_step: 640, epoch: 0, batch: 639, loss: 0.00917, precission: 0.90142, recall: 0.92393, f1_score: 0.91253, speed: 3.51 step/s\n",
      "global_step: 650, epoch: 0, batch: 649, loss: 0.03626, precission: 0.89836, recall: 0.92047, f1_score: 0.90928, speed: 3.11 step/s\n",
      "global_step: 660, epoch: 0, batch: 659, loss: 0.02694, precission: 0.89752, recall: 0.92138, f1_score: 0.90929, speed: 4.40 step/s\n",
      "global_step: 670, epoch: 0, batch: 669, loss: 0.03437, precission: 0.89354, recall: 0.91859, f1_score: 0.90589, speed: 4.01 step/s\n",
      "global_step: 680, epoch: 0, batch: 679, loss: 0.04807, precission: 0.89043, recall: 0.91663, f1_score: 0.90334, speed: 4.21 step/s\n",
      "global_step: 690, epoch: 0, batch: 689, loss: 0.01024, precission: 0.88721, recall: 0.91488, f1_score: 0.90084, speed: 3.33 step/s\n",
      "global_step: 700, epoch: 0, batch: 699, loss: 0.03288, precission: 0.88769, recall: 0.91428, f1_score: 0.90079, speed: 4.23 step/s\n",
      "eval dev loss: 0.02373, precission: 0.92017, recall: 0.92492, f1_score: 0.92254\n",
      "global_step: 710, epoch: 0, batch: 709, loss: 0.02167, precission: 0.91604, recall: 0.92349, f1_score: 0.91975, speed: 0.83 step/s\n",
      "global_step: 720, epoch: 0, batch: 719, loss: 0.02022, precission: 0.91025, recall: 0.92139, f1_score: 0.91579, speed: 4.69 step/s\n",
      "global_step: 730, epoch: 0, batch: 729, loss: 0.01831, precission: 0.90826, recall: 0.92130, f1_score: 0.91473, speed: 3.35 step/s\n",
      "global_step: 740, epoch: 0, batch: 739, loss: 0.03427, precission: 0.90827, recall: 0.91995, f1_score: 0.91407, speed: 3.54 step/s\n",
      "global_step: 750, epoch: 0, batch: 749, loss: 0.01679, precission: 0.90868, recall: 0.92078, f1_score: 0.91469, speed: 3.07 step/s\n",
      "global_step: 760, epoch: 0, batch: 759, loss: 0.01008, precission: 0.90524, recall: 0.91874, f1_score: 0.91194, speed: 4.73 step/s\n",
      "global_step: 770, epoch: 0, batch: 769, loss: 0.02329, precission: 0.90280, recall: 0.91699, f1_score: 0.90984, speed: 4.26 step/s\n",
      "global_step: 780, epoch: 0, batch: 779, loss: 0.01116, precission: 0.90097, recall: 0.91720, f1_score: 0.90901, speed: 4.70 step/s\n",
      "global_step: 790, epoch: 0, batch: 789, loss: 0.02690, precission: 0.90066, recall: 0.91875, f1_score: 0.90961, speed: 3.53 step/s\n",
      "global_step: 800, epoch: 0, batch: 799, loss: 0.00962, precission: 0.89987, recall: 0.91908, f1_score: 0.90937, speed: 3.40 step/s\n",
      "eval dev loss: 0.02153, precission: 0.91941, recall: 0.93894, f1_score: 0.92907\n",
      "save model at global step : 800, best_precission: 0.91941, best_recall: 0.93894, best val f1_score: 0.92907\n",
      "global_step: 810, epoch: 0, batch: 809, loss: 0.00688, precission: 0.91538, recall: 0.93681, f1_score: 0.92597, speed: 0.62 step/s\n",
      "global_step: 820, epoch: 0, batch: 819, loss: 0.02185, precission: 0.91257, recall: 0.93468, f1_score: 0.92349, speed: 4.41 step/s\n",
      "global_step: 830, epoch: 0, batch: 829, loss: 0.02516, precission: 0.91192, recall: 0.93401, f1_score: 0.92283, speed: 3.32 step/s\n",
      "global_step: 840, epoch: 0, batch: 839, loss: 0.03725, precission: 0.90951, recall: 0.93181, f1_score: 0.92052, speed: 4.00 step/s\n",
      "global_step: 850, epoch: 0, batch: 849, loss: 0.01953, precission: 0.90678, recall: 0.92944, f1_score: 0.91797, speed: 2.59 step/s\n",
      "global_step: 860, epoch: 0, batch: 859, loss: 0.01708, precission: 0.90574, recall: 0.92835, f1_score: 0.91691, speed: 4.79 step/s\n",
      "global_step: 870, epoch: 0, batch: 869, loss: 0.07226, precission: 0.90482, recall: 0.92921, f1_score: 0.91685, speed: 3.54 step/s\n",
      "global_step: 880, epoch: 0, batch: 879, loss: 0.02732, precission: 0.90359, recall: 0.92770, f1_score: 0.91549, speed: 3.88 step/s\n",
      "global_step: 890, epoch: 0, batch: 889, loss: 0.02434, precission: 0.90312, recall: 0.92780, f1_score: 0.91530, speed: 4.32 step/s\n",
      "global_step: 900, epoch: 0, batch: 899, loss: 0.02824, precission: 0.90168, recall: 0.92715, f1_score: 0.91424, speed: 3.08 step/s\n",
      "eval dev loss: 0.01986, precission: 0.92797, recall: 0.93812, f1_score: 0.93302\n",
      "global_step: 910, epoch: 0, batch: 909, loss: 0.00573, precission: 0.92340, recall: 0.93641, f1_score: 0.92986, speed: 0.93 step/s\n",
      "global_step: 920, epoch: 0, batch: 919, loss: 0.02110, precission: 0.92490, recall: 0.93869, f1_score: 0.93174, speed: 3.20 step/s\n",
      "global_step: 930, epoch: 0, batch: 929, loss: 0.04264, precission: 0.92022, recall: 0.93436, f1_score: 0.92723, speed: 4.32 step/s\n",
      "global_step: 940, epoch: 0, batch: 939, loss: 0.00992, precission: 0.91670, recall: 0.93365, f1_score: 0.92510, speed: 3.60 step/s\n",
      "global_step: 950, epoch: 0, batch: 949, loss: 0.01814, precission: 0.91331, recall: 0.93233, f1_score: 0.92272, speed: 3.44 step/s\n",
      "global_step: 960, epoch: 0, batch: 959, loss: 0.03249, precission: 0.91044, recall: 0.93080, f1_score: 0.92051, speed: 4.15 step/s\n",
      "global_step: 970, epoch: 0, batch: 969, loss: 0.02863, precission: 0.91098, recall: 0.93034, f1_score: 0.92056, speed: 3.69 step/s\n",
      "global_step: 980, epoch: 0, batch: 979, loss: 0.08756, precission: 0.91020, recall: 0.93088, f1_score: 0.92042, speed: 3.50 step/s\n",
      "global_step: 990, epoch: 0, batch: 989, loss: 0.01704, precission: 0.91183, recall: 0.93124, f1_score: 0.92143, speed: 4.69 step/s\n",
      "global_step: 1000, epoch: 0, batch: 999, loss: 0.02310, precission: 0.91208, recall: 0.93147, f1_score: 0.92167, speed: 3.34 step/s\n",
      "eval dev loss: 0.02047, precission: 0.92110, recall: 0.94389, f1_score: 0.93236\n",
      "save model at global step : 1000, best_precission: 0.92110, best_recall: 0.94389, best val f1_score: 0.93236\n",
      "global_step: 1010, epoch: 0, batch: 1009, loss: 0.01144, precission: 0.91812, recall: 0.94199, f1_score: 0.92990, speed: 0.64 step/s\n",
      "global_step: 1020, epoch: 0, batch: 1019, loss: 0.00646, precission: 0.91863, recall: 0.94221, f1_score: 0.93027, speed: 3.59 step/s\n",
      "global_step: 1030, epoch: 0, batch: 1029, loss: 0.03125, precission: 0.91501, recall: 0.93998, f1_score: 0.92732, speed: 4.44 step/s\n",
      "global_step: 1040, epoch: 0, batch: 1039, loss: 0.01687, precission: 0.91220, recall: 0.93814, f1_score: 0.92499, speed: 3.28 step/s\n",
      "global_step: 1050, epoch: 0, batch: 1049, loss: 0.05693, precission: 0.91256, recall: 0.93697, f1_score: 0.92460, speed: 3.28 step/s\n",
      "global_step: 1060, epoch: 0, batch: 1059, loss: 0.02365, precission: 0.91085, recall: 0.93566, f1_score: 0.92309, speed: 4.16 step/s\n",
      "global_step: 1070, epoch: 0, batch: 1069, loss: 0.03568, precission: 0.91045, recall: 0.93584, f1_score: 0.92297, speed: 4.05 step/s\n",
      "global_step: 1080, epoch: 0, batch: 1079, loss: 0.00901, precission: 0.91126, recall: 0.93590, f1_score: 0.92342, speed: 3.40 step/s\n",
      "global_step: 1090, epoch: 0, batch: 1089, loss: 0.01190, precission: 0.91039, recall: 0.93480, f1_score: 0.92244, speed: 2.86 step/s\n",
      "global_step: 1100, epoch: 0, batch: 1099, loss: 0.03529, precission: 0.90847, recall: 0.93380, f1_score: 0.92096, speed: 4.24 step/s\n",
      "eval dev loss: 0.02082, precission: 0.93155, recall: 0.94596, f1_score: 0.93870\n",
      "save model at global step : 1100, best_precission: 0.93155, best_recall: 0.94596, best val f1_score: 0.93870\n",
      "global_step: 1110, epoch: 0, batch: 1109, loss: 0.03078, precission: 0.92798, recall: 0.94348, f1_score: 0.93566, speed: 0.64 step/s\n",
      "global_step: 1120, epoch: 0, batch: 1119, loss: 0.01664, precission: 0.92686, recall: 0.94290, f1_score: 0.93481, speed: 4.37 step/s\n",
      "global_step: 1130, epoch: 0, batch: 1129, loss: 0.01368, precission: 0.92232, recall: 0.94034, f1_score: 0.93124, speed: 3.41 step/s\n",
      "global_step: 1140, epoch: 0, batch: 1139, loss: 0.00691, precission: 0.92152, recall: 0.93957, f1_score: 0.93046, speed: 4.49 step/s\n",
      "global_step: 1150, epoch: 0, batch: 1149, loss: 0.03096, precission: 0.91995, recall: 0.93788, f1_score: 0.92883, speed: 3.46 step/s\n",
      "global_step: 1160, epoch: 0, batch: 1159, loss: 0.03259, precission: 0.91933, recall: 0.93679, f1_score: 0.92798, speed: 4.54 step/s\n",
      "global_step: 1170, epoch: 0, batch: 1169, loss: 0.02421, precission: 0.91750, recall: 0.93564, f1_score: 0.92648, speed: 4.49 step/s\n",
      "global_step: 1180, epoch: 0, batch: 1179, loss: 0.03011, precission: 0.91720, recall: 0.93524, f1_score: 0.92613, speed: 4.24 step/s\n",
      "global_step: 1190, epoch: 0, batch: 1189, loss: 0.00719, precission: 0.91723, recall: 0.93578, f1_score: 0.92641, speed: 3.92 step/s\n",
      "global_step: 1200, epoch: 0, batch: 1199, loss: 0.01570, precission: 0.91574, recall: 0.93603, f1_score: 0.92577, speed: 2.43 step/s\n",
      "eval dev loss: 0.01949, precission: 0.93367, recall: 0.94080, f1_score: 0.93722\n",
      "global_step: 1210, epoch: 0, batch: 1209, loss: 0.05771, precission: 0.93163, recall: 0.93827, f1_score: 0.93494, speed: 0.93 step/s\n",
      "global_step: 1220, epoch: 0, batch: 1219, loss: 0.01277, precission: 0.92876, recall: 0.93784, f1_score: 0.93328, speed: 2.62 step/s\n",
      "global_step: 1230, epoch: 0, batch: 1229, loss: 0.01610, precission: 0.92776, recall: 0.93774, f1_score: 0.93272, speed: 4.46 step/s\n",
      "global_step: 1240, epoch: 0, batch: 1239, loss: 0.03055, precission: 0.92587, recall: 0.93707, f1_score: 0.93144, speed: 3.40 step/s\n",
      "global_step: 1250, epoch: 0, batch: 1249, loss: 0.02682, precission: 0.92323, recall: 0.93515, f1_score: 0.92915, speed: 3.88 step/s\n",
      "global_step: 1260, epoch: 0, batch: 1259, loss: 0.00680, precission: 0.92278, recall: 0.93581, f1_score: 0.92925, speed: 4.32 step/s\n",
      "global_step: 1270, epoch: 0, batch: 1269, loss: 0.00871, precission: 0.92293, recall: 0.93586, f1_score: 0.92935, speed: 3.71 step/s\n",
      "global_step: 1280, epoch: 0, batch: 1279, loss: 0.02350, precission: 0.92309, recall: 0.93543, f1_score: 0.92922, speed: 4.14 step/s\n",
      "global_step: 1290, epoch: 0, batch: 1289, loss: 0.03800, precission: 0.92261, recall: 0.93560, f1_score: 0.92906, speed: 4.13 step/s\n",
      "global_step: 1300, epoch: 0, batch: 1299, loss: 0.03336, precission: 0.92230, recall: 0.93464, f1_score: 0.92843, speed: 4.33 step/s\n",
      "eval dev loss: 0.02155, precission: 0.92850, recall: 0.93750, f1_score: 0.93298\n",
      "global_step: 1310, epoch: 0, batch: 1309, loss: 0.01132, precission: 0.92441, recall: 0.93482, f1_score: 0.92959, speed: 0.93 step/s\n",
      "global_step: 1320, epoch: 1, batch: 6, loss: 0.01549, precission: 0.92129, recall: 0.93479, f1_score: 0.92799, speed: 4.71 step/s\n",
      "global_step: 1330, epoch: 1, batch: 16, loss: 0.00822, precission: 0.92220, recall: 0.93663, f1_score: 0.92936, speed: 3.12 step/s\n",
      "global_step: 1340, epoch: 1, batch: 26, loss: 0.00769, precission: 0.92317, recall: 0.93853, f1_score: 0.93078, speed: 3.28 step/s\n",
      "global_step: 1350, epoch: 1, batch: 36, loss: 0.01086, precission: 0.92443, recall: 0.93939, f1_score: 0.93185, speed: 3.13 step/s\n",
      "global_step: 1360, epoch: 1, batch: 46, loss: 0.01435, precission: 0.92537, recall: 0.94035, f1_score: 0.93280, speed: 4.24 step/s\n",
      "global_step: 1370, epoch: 1, batch: 56, loss: 0.01432, precission: 0.92518, recall: 0.94058, f1_score: 0.93281, speed: 3.54 step/s\n",
      "global_step: 1380, epoch: 1, batch: 66, loss: 0.00876, precission: 0.92330, recall: 0.93919, f1_score: 0.93118, speed: 4.46 step/s\n",
      "global_step: 1390, epoch: 1, batch: 76, loss: 0.00515, precission: 0.92479, recall: 0.93951, f1_score: 0.93209, speed: 4.51 step/s\n",
      "global_step: 1400, epoch: 1, batch: 86, loss: 0.02416, precission: 0.92430, recall: 0.94039, f1_score: 0.93227, speed: 4.63 step/s\n",
      "eval dev loss: 0.02089, precission: 0.92834, recall: 0.94596, f1_score: 0.93707\n",
      "global_step: 1410, epoch: 1, batch: 96, loss: 0.01706, precission: 0.92865, recall: 0.94682, f1_score: 0.93765, speed: 0.89 step/s\n",
      "global_step: 1420, epoch: 1, batch: 106, loss: 0.02062, precission: 0.92933, recall: 0.94656, f1_score: 0.93787, speed: 4.56 step/s\n",
      "global_step: 1430, epoch: 1, batch: 116, loss: 0.00841, precission: 0.92649, recall: 0.94496, f1_score: 0.93563, speed: 4.11 step/s\n",
      "global_step: 1440, epoch: 1, batch: 126, loss: 0.00241, precission: 0.92635, recall: 0.94546, f1_score: 0.93580, speed: 4.35 step/s\n",
      "global_step: 1450, epoch: 1, batch: 136, loss: 0.01808, precission: 0.92785, recall: 0.94636, f1_score: 0.93701, speed: 4.90 step/s\n",
      "global_step: 1460, epoch: 1, batch: 146, loss: 0.02129, precission: 0.92966, recall: 0.94804, f1_score: 0.93876, speed: 3.95 step/s\n",
      "global_step: 1470, epoch: 1, batch: 156, loss: 0.00588, precission: 0.92911, recall: 0.94740, f1_score: 0.93817, speed: 2.89 step/s\n",
      "global_step: 1480, epoch: 1, batch: 166, loss: 0.01209, precission: 0.92897, recall: 0.94710, f1_score: 0.93795, speed: 4.05 step/s\n",
      "global_step: 1490, epoch: 1, batch: 176, loss: 0.01515, precission: 0.92910, recall: 0.94664, f1_score: 0.93779, speed: 4.58 step/s\n",
      "global_step: 1500, epoch: 1, batch: 186, loss: 0.00653, precission: 0.92999, recall: 0.94691, f1_score: 0.93837, speed: 4.66 step/s\n",
      "eval dev loss: 0.01993, precission: 0.93354, recall: 0.95318, f1_score: 0.94325\n",
      "save model at global step : 1500, best_precission: 0.93354, best_recall: 0.95318, best val f1_score: 0.94325\n",
      "global_step: 1510, epoch: 1, batch: 196, loss: 0.01004, precission: 0.93503, recall: 0.95409, f1_score: 0.94446, speed: 0.62 step/s\n",
      "global_step: 1520, epoch: 1, batch: 206, loss: 0.02137, precission: 0.93563, recall: 0.95412, f1_score: 0.94479, speed: 4.61 step/s\n",
      "global_step: 1530, epoch: 1, batch: 216, loss: 0.01295, precission: 0.93535, recall: 0.95350, f1_score: 0.94433, speed: 4.23 step/s\n",
      "global_step: 1540, epoch: 1, batch: 226, loss: 0.01359, precission: 0.93408, recall: 0.95316, f1_score: 0.94352, speed: 4.09 step/s\n",
      "global_step: 1550, epoch: 1, batch: 236, loss: 0.00684, precission: 0.93529, recall: 0.95368, f1_score: 0.94440, speed: 3.00 step/s\n",
      "global_step: 1560, epoch: 1, batch: 246, loss: 0.01334, precission: 0.93427, recall: 0.95302, f1_score: 0.94355, speed: 2.86 step/s\n",
      "global_step: 1570, epoch: 1, batch: 256, loss: 0.00896, precission: 0.93512, recall: 0.95319, f1_score: 0.94407, speed: 3.98 step/s\n",
      "global_step: 1580, epoch: 1, batch: 266, loss: 0.01591, precission: 0.93483, recall: 0.95324, f1_score: 0.94394, speed: 4.23 step/s\n",
      "global_step: 1590, epoch: 1, batch: 276, loss: 0.00682, precission: 0.93458, recall: 0.95311, f1_score: 0.94375, speed: 3.91 step/s\n",
      "global_step: 1600, epoch: 1, batch: 286, loss: 0.00918, precission: 0.93513, recall: 0.95391, f1_score: 0.94443, speed: 4.24 step/s\n",
      "eval dev loss: 0.02088, precission: 0.93410, recall: 0.94431, f1_score: 0.93917\n",
      "global_step: 1610, epoch: 1, batch: 296, loss: 0.00669, precission: 0.93526, recall: 0.94593, f1_score: 0.94056, speed: 0.90 step/s\n",
      "global_step: 1620, epoch: 1, batch: 306, loss: 0.00569, precission: 0.93188, recall: 0.94500, f1_score: 0.93839, speed: 3.71 step/s\n",
      "global_step: 1630, epoch: 1, batch: 316, loss: 0.00932, precission: 0.93279, recall: 0.94623, f1_score: 0.93947, speed: 4.91 step/s\n",
      "global_step: 1640, epoch: 1, batch: 326, loss: 0.00486, precission: 0.93530, recall: 0.94846, f1_score: 0.94183, speed: 3.87 step/s\n",
      "global_step: 1650, epoch: 1, batch: 336, loss: 0.02469, precission: 0.93510, recall: 0.94808, f1_score: 0.94154, speed: 3.82 step/s\n",
      "global_step: 1660, epoch: 1, batch: 346, loss: 0.01146, precission: 0.93370, recall: 0.94735, f1_score: 0.94047, speed: 2.94 step/s\n",
      "global_step: 1670, epoch: 1, batch: 356, loss: 0.03552, precission: 0.93281, recall: 0.94769, f1_score: 0.94019, speed: 3.69 step/s\n",
      "global_step: 1680, epoch: 1, batch: 366, loss: 0.01445, precission: 0.93251, recall: 0.94782, f1_score: 0.94011, speed: 4.00 step/s\n",
      "global_step: 1690, epoch: 1, batch: 376, loss: 0.00967, precission: 0.93325, recall: 0.94814, f1_score: 0.94064, speed: 2.55 step/s\n",
      "global_step: 1700, epoch: 1, batch: 386, loss: 0.00599, precission: 0.93375, recall: 0.94881, f1_score: 0.94122, speed: 4.23 step/s\n",
      "eval dev loss: 0.01885, precission: 0.94687, recall: 0.95215, f1_score: 0.94950\n",
      "global_step: 1710, epoch: 1, batch: 396, loss: 0.02962, precission: 0.94624, recall: 0.95326, f1_score: 0.94974, speed: 0.92 step/s\n",
      "global_step: 1720, epoch: 1, batch: 406, loss: 0.00350, precission: 0.94561, recall: 0.95426, f1_score: 0.94992, speed: 4.65 step/s\n",
      "global_step: 1730, epoch: 1, batch: 416, loss: 0.00224, precission: 0.94535, recall: 0.95404, f1_score: 0.94968, speed: 3.75 step/s\n",
      "global_step: 1740, epoch: 1, batch: 426, loss: 0.01406, precission: 0.94514, recall: 0.95436, f1_score: 0.94973, speed: 4.06 step/s\n",
      "global_step: 1750, epoch: 1, batch: 436, loss: 0.02051, precission: 0.94155, recall: 0.95269, f1_score: 0.94709, speed: 4.17 step/s\n",
      "global_step: 1760, epoch: 1, batch: 446, loss: 0.02645, precission: 0.93980, recall: 0.95190, f1_score: 0.94581, speed: 4.26 step/s\n",
      "global_step: 1770, epoch: 1, batch: 456, loss: 0.03460, precission: 0.93981, recall: 0.95218, f1_score: 0.94595, speed: 3.12 step/s\n",
      "global_step: 1780, epoch: 1, batch: 466, loss: 0.00231, precission: 0.93990, recall: 0.95257, f1_score: 0.94619, speed: 3.20 step/s\n",
      "global_step: 1790, epoch: 1, batch: 476, loss: 0.00945, precission: 0.93923, recall: 0.95171, f1_score: 0.94543, speed: 4.23 step/s\n",
      "global_step: 1800, epoch: 1, batch: 486, loss: 0.00647, precission: 0.93651, recall: 0.95092, f1_score: 0.94366, speed: 4.74 step/s\n",
      "eval dev loss: 0.02183, precission: 0.93314, recall: 0.95297, f1_score: 0.94295\n",
      "global_step: 1810, epoch: 1, batch: 496, loss: 0.00417, precission: 0.93596, recall: 0.95413, f1_score: 0.94496, speed: 0.91 step/s\n",
      "global_step: 1820, epoch: 1, batch: 506, loss: 0.01883, precission: 0.93752, recall: 0.95389, f1_score: 0.94563, speed: 3.82 step/s\n",
      "global_step: 1830, epoch: 1, batch: 516, loss: 0.01030, precission: 0.93782, recall: 0.95360, f1_score: 0.94564, speed: 3.59 step/s\n",
      "global_step: 1840, epoch: 1, batch: 526, loss: 0.00767, precission: 0.93720, recall: 0.95246, f1_score: 0.94477, speed: 4.61 step/s\n",
      "global_step: 1850, epoch: 1, batch: 536, loss: 0.00264, precission: 0.93775, recall: 0.95377, f1_score: 0.94569, speed: 4.19 step/s\n",
      "global_step: 1860, epoch: 1, batch: 546, loss: 0.01354, precission: 0.93773, recall: 0.95367, f1_score: 0.94563, speed: 3.67 step/s\n",
      "global_step: 1870, epoch: 1, batch: 556, loss: 0.01237, precission: 0.93822, recall: 0.95395, f1_score: 0.94602, speed: 4.30 step/s\n",
      "global_step: 1880, epoch: 1, batch: 566, loss: 0.05265, precission: 0.93753, recall: 0.95294, f1_score: 0.94517, speed: 3.75 step/s\n",
      "global_step: 1890, epoch: 1, batch: 576, loss: 0.02575, precission: 0.93653, recall: 0.95239, f1_score: 0.94439, speed: 4.89 step/s\n",
      "global_step: 1900, epoch: 1, batch: 586, loss: 0.01177, precission: 0.93703, recall: 0.95232, f1_score: 0.94461, speed: 4.77 step/s\n",
      "eval dev loss: 0.02205, precission: 0.93868, recall: 0.95050, f1_score: 0.94455\n",
      "global_step: 1910, epoch: 1, batch: 596, loss: 0.00749, precission: 0.93940, recall: 0.95142, f1_score: 0.94537, speed: 0.85 step/s\n",
      "global_step: 1920, epoch: 1, batch: 606, loss: 0.00870, precission: 0.93696, recall: 0.95176, f1_score: 0.94430, speed: 3.17 step/s\n",
      "global_step: 1930, epoch: 1, batch: 616, loss: 0.00410, precission: 0.93748, recall: 0.95233, f1_score: 0.94485, speed: 3.41 step/s\n",
      "global_step: 1940, epoch: 1, batch: 626, loss: 0.01480, precission: 0.93830, recall: 0.95270, f1_score: 0.94544, speed: 4.74 step/s\n",
      "global_step: 1950, epoch: 1, batch: 636, loss: 0.00746, precission: 0.93921, recall: 0.95327, f1_score: 0.94619, speed: 4.51 step/s\n",
      "global_step: 1960, epoch: 1, batch: 646, loss: 0.02462, precission: 0.93882, recall: 0.95232, f1_score: 0.94552, speed: 3.70 step/s\n",
      "global_step: 1970, epoch: 1, batch: 656, loss: 0.00140, precission: 0.93886, recall: 0.95277, f1_score: 0.94577, speed: 3.44 step/s\n",
      "global_step: 1980, epoch: 1, batch: 666, loss: 0.03209, precission: 0.93808, recall: 0.95218, f1_score: 0.94508, speed: 4.51 step/s\n",
      "global_step: 1990, epoch: 1, batch: 676, loss: 0.01680, precission: 0.93639, recall: 0.95189, f1_score: 0.94407, speed: 3.12 step/s\n",
      "global_step: 2000, epoch: 1, batch: 686, loss: 0.01959, precission: 0.93602, recall: 0.95149, f1_score: 0.94369, speed: 4.52 step/s\n",
      "eval dev loss: 0.02008, precission: 0.92527, recall: 0.95256, f1_score: 0.93871\n",
      "global_step: 2010, epoch: 1, batch: 696, loss: 0.01032, precission: 0.92688, recall: 0.95463, f1_score: 0.94055, speed: 0.92 step/s\n",
      "global_step: 2020, epoch: 1, batch: 706, loss: 0.00586, precission: 0.92658, recall: 0.95310, f1_score: 0.93965, speed: 4.26 step/s\n",
      "global_step: 2030, epoch: 1, batch: 716, loss: 0.01391, precission: 0.92562, recall: 0.95102, f1_score: 0.93815, speed: 3.90 step/s\n",
      "global_step: 2040, epoch: 1, batch: 726, loss: 0.01830, precission: 0.92448, recall: 0.95088, f1_score: 0.93749, speed: 4.48 step/s\n",
      "global_step: 2050, epoch: 1, batch: 736, loss: 0.02374, precission: 0.92231, recall: 0.94983, f1_score: 0.93587, speed: 3.80 step/s\n",
      "global_step: 2060, epoch: 1, batch: 746, loss: 0.00115, precission: 0.92333, recall: 0.94998, f1_score: 0.93647, speed: 4.72 step/s\n",
      "global_step: 2070, epoch: 1, batch: 756, loss: 0.01184, precission: 0.92228, recall: 0.94949, f1_score: 0.93569, speed: 4.60 step/s\n",
      "global_step: 2080, epoch: 1, batch: 766, loss: 0.00827, precission: 0.92329, recall: 0.95013, f1_score: 0.93652, speed: 4.51 step/s\n",
      "global_step: 2090, epoch: 1, batch: 776, loss: 0.01233, precission: 0.92351, recall: 0.94968, f1_score: 0.93641, speed: 4.33 step/s\n",
      "global_step: 2100, epoch: 1, batch: 786, loss: 0.00672, precission: 0.92365, recall: 0.94911, f1_score: 0.93621, speed: 4.23 step/s\n",
      "eval dev loss: 0.01851, precission: 0.93475, recall: 0.95153, f1_score: 0.94306\n",
      "global_step: 2110, epoch: 1, batch: 796, loss: 0.01200, precission: 0.93353, recall: 0.95019, f1_score: 0.94178, speed: 0.94 step/s\n",
      "global_step: 2120, epoch: 1, batch: 806, loss: 0.01081, precission: 0.93207, recall: 0.94991, f1_score: 0.94091, speed: 4.60 step/s\n",
      "global_step: 2130, epoch: 1, batch: 816, loss: 0.01438, precission: 0.93405, recall: 0.95226, f1_score: 0.94307, speed: 3.55 step/s\n",
      "global_step: 2140, epoch: 1, batch: 826, loss: 0.01091, precission: 0.93434, recall: 0.95164, f1_score: 0.94291, speed: 4.04 step/s\n",
      "global_step: 2150, epoch: 1, batch: 836, loss: 0.01321, precission: 0.93608, recall: 0.95342, f1_score: 0.94467, speed: 4.09 step/s\n",
      "global_step: 2160, epoch: 1, batch: 846, loss: 0.00538, precission: 0.93636, recall: 0.95389, f1_score: 0.94504, speed: 3.48 step/s\n",
      "global_step: 2170, epoch: 1, batch: 856, loss: 0.00051, precission: 0.93652, recall: 0.95376, f1_score: 0.94506, speed: 3.34 step/s\n",
      "global_step: 2180, epoch: 1, batch: 866, loss: 0.01642, precission: 0.93711, recall: 0.95381, f1_score: 0.94538, speed: 2.59 step/s\n",
      "global_step: 2190, epoch: 1, batch: 876, loss: 0.00953, precission: 0.93773, recall: 0.95494, f1_score: 0.94626, speed: 3.48 step/s\n",
      "global_step: 2200, epoch: 1, batch: 886, loss: 0.02304, precission: 0.93721, recall: 0.95401, f1_score: 0.94553, speed: 2.99 step/s\n",
      "eval dev loss: 0.01719, precission: 0.94387, recall: 0.95730, f1_score: 0.95054\n",
      "save model at global step : 2200, best_precission: 0.94387, best_recall: 0.95730, best val f1_score: 0.95054\n",
      "global_step: 2210, epoch: 1, batch: 896, loss: 0.03334, precission: 0.93922, recall: 0.95517, f1_score: 0.94713, speed: 0.62 step/s\n",
      "global_step: 2220, epoch: 1, batch: 906, loss: 0.01005, precission: 0.94072, recall: 0.95659, f1_score: 0.94859, speed: 2.93 step/s\n",
      "global_step: 2230, epoch: 1, batch: 916, loss: 0.00557, precission: 0.94121, recall: 0.95777, f1_score: 0.94942, speed: 2.91 step/s\n",
      "global_step: 2240, epoch: 1, batch: 926, loss: 0.01494, precission: 0.94065, recall: 0.95722, f1_score: 0.94886, speed: 3.22 step/s\n",
      "global_step: 2250, epoch: 1, batch: 936, loss: 0.01669, precission: 0.93999, recall: 0.95625, f1_score: 0.94805, speed: 4.36 step/s\n",
      "global_step: 2260, epoch: 1, batch: 946, loss: 0.00871, precission: 0.94096, recall: 0.95672, f1_score: 0.94878, speed: 3.31 step/s\n",
      "global_step: 2270, epoch: 1, batch: 956, loss: 0.02898, precission: 0.93842, recall: 0.95524, f1_score: 0.94675, speed: 4.09 step/s\n",
      "global_step: 2280, epoch: 1, batch: 966, loss: 0.00510, precission: 0.93985, recall: 0.95545, f1_score: 0.94759, speed: 3.53 step/s\n",
      "global_step: 2290, epoch: 1, batch: 976, loss: 0.01752, precission: 0.93909, recall: 0.95523, f1_score: 0.94709, speed: 4.49 step/s\n",
      "global_step: 2300, epoch: 1, batch: 986, loss: 0.00207, precission: 0.93909, recall: 0.95496, f1_score: 0.94696, speed: 4.35 step/s\n",
      "eval dev loss: 0.01717, precission: 0.93938, recall: 0.95565, f1_score: 0.94744\n",
      "global_step: 2310, epoch: 1, batch: 996, loss: 0.01201, precission: 0.93948, recall: 0.95634, f1_score: 0.94783, speed: 0.91 step/s\n",
      "global_step: 2320, epoch: 1, batch: 1006, loss: 0.04613, precission: 0.93844, recall: 0.95462, f1_score: 0.94646, speed: 3.92 step/s\n",
      "global_step: 2330, epoch: 1, batch: 1016, loss: 0.01334, precission: 0.93986, recall: 0.95591, f1_score: 0.94781, speed: 3.45 step/s\n",
      "global_step: 2340, epoch: 1, batch: 1026, loss: 0.02102, precission: 0.94048, recall: 0.95624, f1_score: 0.94830, speed: 4.56 step/s\n",
      "global_step: 2350, epoch: 1, batch: 1036, loss: 0.00436, precission: 0.94014, recall: 0.95538, f1_score: 0.94770, speed: 3.04 step/s\n",
      "global_step: 2360, epoch: 1, batch: 1046, loss: 0.00867, precission: 0.93912, recall: 0.95448, f1_score: 0.94674, speed: 3.92 step/s\n",
      "global_step: 2370, epoch: 1, batch: 1056, loss: 0.01233, precission: 0.93761, recall: 0.95381, f1_score: 0.94564, speed: 3.02 step/s\n",
      "global_step: 2380, epoch: 1, batch: 1066, loss: 0.00638, precission: 0.93666, recall: 0.95296, f1_score: 0.94474, speed: 4.38 step/s\n",
      "global_step: 2390, epoch: 1, batch: 1076, loss: 0.01682, precission: 0.93768, recall: 0.95324, f1_score: 0.94539, speed: 4.23 step/s\n",
      "global_step: 2400, epoch: 1, batch: 1086, loss: 0.01765, precission: 0.93700, recall: 0.95285, f1_score: 0.94486, speed: 2.69 step/s\n",
      "eval dev loss: 0.01796, precission: 0.93332, recall: 0.95565, f1_score: 0.94435\n",
      "global_step: 2410, epoch: 1, batch: 1096, loss: 0.00336, precission: 0.93495, recall: 0.95674, f1_score: 0.94572, speed: 0.90 step/s\n",
      "global_step: 2420, epoch: 1, batch: 1106, loss: 0.01481, precission: 0.93320, recall: 0.95515, f1_score: 0.94405, speed: 3.99 step/s\n",
      "global_step: 2430, epoch: 1, batch: 1116, loss: 0.01620, precission: 0.93502, recall: 0.95508, f1_score: 0.94494, speed: 2.90 step/s\n",
      "global_step: 2440, epoch: 1, batch: 1126, loss: 0.01294, precission: 0.93563, recall: 0.95574, f1_score: 0.94558, speed: 3.51 step/s\n",
      "global_step: 2450, epoch: 1, batch: 1136, loss: 0.01540, precission: 0.93209, recall: 0.95385, f1_score: 0.94284, speed: 3.61 step/s\n",
      "global_step: 2460, epoch: 1, batch: 1146, loss: 0.01717, precission: 0.93410, recall: 0.95540, f1_score: 0.94463, speed: 2.96 step/s\n",
      "global_step: 2470, epoch: 1, batch: 1156, loss: 0.00437, precission: 0.93513, recall: 0.95613, f1_score: 0.94552, speed: 3.72 step/s\n",
      "global_step: 2480, epoch: 1, batch: 1166, loss: 0.02621, precission: 0.93550, recall: 0.95536, f1_score: 0.94532, speed: 4.60 step/s\n",
      "global_step: 2490, epoch: 1, batch: 1176, loss: 0.01356, precission: 0.93233, recall: 0.95528, f1_score: 0.94366, speed: 4.03 step/s\n",
      "global_step: 2500, epoch: 1, batch: 1186, loss: 0.01993, precission: 0.93319, recall: 0.95486, f1_score: 0.94390, speed: 4.19 step/s\n",
      "eval dev loss: 0.01807, precission: 0.95124, recall: 0.95380, f1_score: 0.95252\n",
      "global_step: 2510, epoch: 1, batch: 1196, loss: 0.00310, precission: 0.95013, recall: 0.95470, f1_score: 0.95241, speed: 0.92 step/s\n",
      "global_step: 2520, epoch: 1, batch: 1206, loss: 0.01114, precission: 0.94889, recall: 0.95483, f1_score: 0.95185, speed: 4.80 step/s\n",
      "global_step: 2530, epoch: 1, batch: 1216, loss: 0.01633, precission: 0.94734, recall: 0.95481, f1_score: 0.95106, speed: 4.07 step/s\n",
      "global_step: 2540, epoch: 1, batch: 1226, loss: 0.04649, precission: 0.94838, recall: 0.95517, f1_score: 0.95176, speed: 4.16 step/s\n",
      "global_step: 2550, epoch: 1, batch: 1236, loss: 0.01111, precission: 0.95017, recall: 0.95642, f1_score: 0.95328, speed: 5.33 step/s\n",
      "global_step: 2560, epoch: 1, batch: 1246, loss: 0.00821, precission: 0.95031, recall: 0.95690, f1_score: 0.95359, speed: 5.07 step/s\n",
      "global_step: 2570, epoch: 1, batch: 1256, loss: 0.00276, precission: 0.94941, recall: 0.95752, f1_score: 0.95344, speed: 4.71 step/s\n",
      "global_step: 2580, epoch: 1, batch: 1266, loss: 0.01924, precission: 0.94924, recall: 0.95647, f1_score: 0.95284, speed: 3.92 step/s\n",
      "global_step: 2590, epoch: 1, batch: 1276, loss: 0.01551, precission: 0.94910, recall: 0.95656, f1_score: 0.95282, speed: 4.01 step/s\n",
      "global_step: 2600, epoch: 1, batch: 1286, loss: 0.03588, precission: 0.94865, recall: 0.95600, f1_score: 0.95231, speed: 4.68 step/s\n",
      "eval dev loss: 0.01730, precission: 0.93702, recall: 0.95132, f1_score: 0.94411\n",
      "global_step: 2610, epoch: 1, batch: 1296, loss: 0.01092, precission: 0.93456, recall: 0.95024, f1_score: 0.94233, speed: 0.86 step/s\n",
      "global_step: 2620, epoch: 1, batch: 1306, loss: 0.00616, precission: 0.93293, recall: 0.95010, f1_score: 0.94144, speed: 4.22 step/s\n",
      "global_step: 2630, epoch: 2, batch: 3, loss: 0.00457, precission: 0.93455, recall: 0.95119, f1_score: 0.94280, speed: 4.13 step/s\n",
      "global_step: 2640, epoch: 2, batch: 13, loss: 0.00862, precission: 0.93698, recall: 0.95300, f1_score: 0.94492, speed: 5.13 step/s\n",
      "global_step: 2650, epoch: 2, batch: 23, loss: 0.01273, precission: 0.93734, recall: 0.95258, f1_score: 0.94490, speed: 3.48 step/s\n",
      "global_step: 2660, epoch: 2, batch: 33, loss: 0.00230, precission: 0.93865, recall: 0.95361, f1_score: 0.94607, speed: 4.07 step/s\n",
      "global_step: 2670, epoch: 2, batch: 43, loss: 0.00873, precission: 0.93954, recall: 0.95482, f1_score: 0.94712, speed: 4.19 step/s\n",
      "global_step: 2680, epoch: 2, batch: 53, loss: 0.00280, precission: 0.94059, recall: 0.95607, f1_score: 0.94827, speed: 4.29 step/s\n",
      "global_step: 2690, epoch: 2, batch: 63, loss: 0.00729, precission: 0.94262, recall: 0.95695, f1_score: 0.94973, speed: 3.98 step/s\n",
      "global_step: 2700, epoch: 2, batch: 73, loss: 0.00116, precission: 0.94487, recall: 0.95855, f1_score: 0.95166, speed: 3.23 step/s\n",
      "eval dev loss: 0.01971, precission: 0.94439, recall: 0.95627, f1_score: 0.95029\n",
      "global_step: 2710, epoch: 2, batch: 83, loss: 0.01367, precission: 0.94684, recall: 0.95853, f1_score: 0.95265, speed: 0.86 step/s\n",
      "global_step: 2720, epoch: 2, batch: 93, loss: 0.00650, precission: 0.94989, recall: 0.96078, f1_score: 0.95531, speed: 3.42 step/s\n",
      "global_step: 2730, epoch: 2, batch: 103, loss: 0.01025, precission: 0.95177, recall: 0.96208, f1_score: 0.95690, speed: 3.36 step/s\n",
      "global_step: 2740, epoch: 2, batch: 113, loss: 0.02283, precission: 0.95143, recall: 0.96302, f1_score: 0.95719, speed: 3.84 step/s\n",
      "global_step: 2750, epoch: 2, batch: 123, loss: 0.00376, precission: 0.95129, recall: 0.96277, f1_score: 0.95699, speed: 4.04 step/s\n",
      "global_step: 2760, epoch: 2, batch: 133, loss: 0.00776, precission: 0.95200, recall: 0.96289, f1_score: 0.95741, speed: 4.62 step/s\n",
      "global_step: 2770, epoch: 2, batch: 143, loss: 0.00062, precission: 0.95319, recall: 0.96406, f1_score: 0.95859, speed: 4.56 step/s\n",
      "global_step: 2780, epoch: 2, batch: 153, loss: 0.00517, precission: 0.95407, recall: 0.96411, f1_score: 0.95906, speed: 3.57 step/s\n",
      "global_step: 2790, epoch: 2, batch: 163, loss: 0.00418, precission: 0.95499, recall: 0.96443, f1_score: 0.95969, speed: 4.51 step/s\n",
      "global_step: 2800, epoch: 2, batch: 173, loss: 0.00548, precission: 0.95589, recall: 0.96550, f1_score: 0.96067, speed: 4.05 step/s\n",
      "eval dev loss: 0.02053, precission: 0.94441, recall: 0.96019, f1_score: 0.95223\n",
      "save model at global step : 2800, best_precission: 0.94441, best_recall: 0.96019, best val f1_score: 0.95223\n",
      "global_step: 2810, epoch: 2, batch: 183, loss: 0.01042, precission: 0.94685, recall: 0.96209, f1_score: 0.95441, speed: 0.60 step/s\n",
      "global_step: 2820, epoch: 2, batch: 193, loss: 0.00527, precission: 0.94697, recall: 0.96204, f1_score: 0.95445, speed: 4.26 step/s\n",
      "global_step: 2830, epoch: 2, batch: 203, loss: 0.00754, precission: 0.94613, recall: 0.96214, f1_score: 0.95407, speed: 4.59 step/s\n",
      "global_step: 2840, epoch: 2, batch: 213, loss: 0.00782, precission: 0.94696, recall: 0.96227, f1_score: 0.95455, speed: 4.90 step/s\n",
      "global_step: 2850, epoch: 2, batch: 223, loss: 0.01135, precission: 0.94640, recall: 0.96199, f1_score: 0.95413, speed: 4.60 step/s\n",
      "global_step: 2860, epoch: 2, batch: 233, loss: 0.01069, precission: 0.94745, recall: 0.96259, f1_score: 0.95496, speed: 4.47 step/s\n",
      "global_step: 2870, epoch: 2, batch: 243, loss: 0.00283, precission: 0.94828, recall: 0.96297, f1_score: 0.95557, speed: 4.04 step/s\n",
      "global_step: 2880, epoch: 2, batch: 253, loss: 0.01672, precission: 0.94721, recall: 0.96308, f1_score: 0.95508, speed: 3.77 step/s\n",
      "global_step: 2890, epoch: 2, batch: 263, loss: 0.01708, precission: 0.94711, recall: 0.96266, f1_score: 0.95482, speed: 4.46 step/s\n",
      "global_step: 2900, epoch: 2, batch: 273, loss: 0.00122, precission: 0.94853, recall: 0.96355, f1_score: 0.95598, speed: 3.80 step/s\n",
      "eval dev loss: 0.01996, precission: 0.94233, recall: 0.96390, f1_score: 0.95299\n",
      "global_step: 2910, epoch: 2, batch: 283, loss: 0.00468, precission: 0.94347, recall: 0.96501, f1_score: 0.95412, speed: 0.87 step/s\n",
      "global_step: 2920, epoch: 2, batch: 293, loss: 0.01042, precission: 0.94581, recall: 0.96558, f1_score: 0.95559, speed: 4.55 step/s\n",
      "global_step: 2930, epoch: 2, batch: 303, loss: 0.00908, precission: 0.94659, recall: 0.96628, f1_score: 0.95633, speed: 4.22 step/s\n",
      "global_step: 2940, epoch: 2, batch: 313, loss: 0.00279, precission: 0.94959, recall: 0.96811, f1_score: 0.95876, speed: 4.45 step/s\n",
      "global_step: 2950, epoch: 2, batch: 323, loss: 0.00692, precission: 0.95127, recall: 0.96859, f1_score: 0.95985, speed: 4.00 step/s\n",
      "global_step: 2960, epoch: 2, batch: 333, loss: 0.00943, precission: 0.95199, recall: 0.96877, f1_score: 0.96030, speed: 3.83 step/s\n",
      "global_step: 2970, epoch: 2, batch: 343, loss: 0.00309, precission: 0.95233, recall: 0.96835, f1_score: 0.96027, speed: 3.49 step/s\n",
      "global_step: 2980, epoch: 2, batch: 353, loss: 0.00402, precission: 0.95335, recall: 0.96916, f1_score: 0.96119, speed: 4.47 step/s\n",
      "global_step: 2990, epoch: 2, batch: 363, loss: 0.00049, precission: 0.95298, recall: 0.96894, f1_score: 0.96089, speed: 4.76 step/s\n",
      "global_step: 3000, epoch: 2, batch: 373, loss: 0.00279, precission: 0.95382, recall: 0.96938, f1_score: 0.96154, speed: 3.97 step/s\n",
      "eval dev loss: 0.02083, precission: 0.94954, recall: 0.95091, f1_score: 0.95022\n",
      "global_step: 3010, epoch: 2, batch: 383, loss: 0.00530, precission: 0.94801, recall: 0.95050, f1_score: 0.94925, speed: 0.92 step/s\n",
      "global_step: 3020, epoch: 2, batch: 393, loss: 0.01731, precission: 0.94854, recall: 0.95193, f1_score: 0.95023, speed: 3.46 step/s\n",
      "global_step: 3030, epoch: 2, batch: 403, loss: 0.00783, precission: 0.94972, recall: 0.95461, f1_score: 0.95216, speed: 3.88 step/s\n",
      "global_step: 3040, epoch: 2, batch: 413, loss: 0.00142, precission: 0.95252, recall: 0.95605, f1_score: 0.95428, speed: 3.21 step/s\n",
      "global_step: 3050, epoch: 2, batch: 423, loss: 0.00279, precission: 0.95363, recall: 0.95768, f1_score: 0.95565, speed: 4.98 step/s\n",
      "global_step: 3060, epoch: 2, batch: 433, loss: 0.00101, precission: 0.95394, recall: 0.95898, f1_score: 0.95645, speed: 3.31 step/s\n",
      "global_step: 3070, epoch: 2, batch: 443, loss: 0.01481, precission: 0.95546, recall: 0.95997, f1_score: 0.95771, speed: 4.02 step/s\n",
      "global_step: 3080, epoch: 2, batch: 453, loss: 0.01195, precission: 0.95558, recall: 0.96068, f1_score: 0.95812, speed: 3.96 step/s\n",
      "global_step: 3090, epoch: 2, batch: 463, loss: 0.00547, precission: 0.95573, recall: 0.96132, f1_score: 0.95851, speed: 3.23 step/s\n",
      "global_step: 3100, epoch: 2, batch: 473, loss: 0.01559, precission: 0.95621, recall: 0.96169, f1_score: 0.95894, speed: 3.18 step/s\n",
      "eval dev loss: 0.01945, precission: 0.94803, recall: 0.95957, f1_score: 0.95377\n",
      "global_step: 3110, epoch: 2, batch: 483, loss: 0.00395, precission: 0.94888, recall: 0.96080, f1_score: 0.95480, speed: 0.92 step/s\n",
      "global_step: 3120, epoch: 2, batch: 493, loss: 0.02247, precission: 0.95113, recall: 0.96195, f1_score: 0.95651, speed: 3.02 step/s\n",
      "global_step: 3130, epoch: 2, batch: 503, loss: 0.00823, precission: 0.95128, recall: 0.96263, f1_score: 0.95692, speed: 3.59 step/s\n",
      "global_step: 3140, epoch: 2, batch: 513, loss: 0.00940, precission: 0.94901, recall: 0.96203, f1_score: 0.95547, speed: 4.27 step/s\n",
      "global_step: 3150, epoch: 2, batch: 523, loss: 0.01823, precission: 0.94936, recall: 0.96227, f1_score: 0.95577, speed: 4.66 step/s\n",
      "global_step: 3160, epoch: 2, batch: 533, loss: 0.00616, precission: 0.94993, recall: 0.96326, f1_score: 0.95655, speed: 4.20 step/s\n",
      "global_step: 3170, epoch: 2, batch: 543, loss: 0.00610, precission: 0.95081, recall: 0.96401, f1_score: 0.95736, speed: 4.87 step/s\n",
      "global_step: 3180, epoch: 2, batch: 553, loss: 0.01118, precission: 0.95111, recall: 0.96402, f1_score: 0.95752, speed: 4.41 step/s\n",
      "global_step: 3190, epoch: 2, batch: 563, loss: 0.00258, precission: 0.95112, recall: 0.96405, f1_score: 0.95754, speed: 4.18 step/s\n",
      "global_step: 3200, epoch: 2, batch: 573, loss: 0.01141, precission: 0.95113, recall: 0.96390, f1_score: 0.95748, speed: 4.33 step/s\n",
      "eval dev loss: 0.02274, precission: 0.94675, recall: 0.95710, f1_score: 0.95189\n",
      "global_step: 3210, epoch: 2, batch: 583, loss: 0.00720, precission: 0.94709, recall: 0.95848, f1_score: 0.95275, speed: 0.92 step/s\n",
      "global_step: 3220, epoch: 2, batch: 593, loss: 0.00169, precission: 0.94611, recall: 0.95932, f1_score: 0.95267, speed: 3.54 step/s\n",
      "global_step: 3230, epoch: 2, batch: 603, loss: 0.02166, precission: 0.94735, recall: 0.95941, f1_score: 0.95334, speed: 4.42 step/s\n",
      "global_step: 3240, epoch: 2, batch: 613, loss: 0.00208, precission: 0.94828, recall: 0.96045, f1_score: 0.95433, speed: 3.74 step/s\n",
      "global_step: 3250, epoch: 2, batch: 623, loss: 0.01550, precission: 0.94908, recall: 0.96083, f1_score: 0.95492, speed: 2.95 step/s\n",
      "global_step: 3260, epoch: 2, batch: 633, loss: 0.00505, precission: 0.94803, recall: 0.96063, f1_score: 0.95429, speed: 4.32 step/s\n",
      "global_step: 3270, epoch: 2, batch: 643, loss: 0.00805, precission: 0.94855, recall: 0.96088, f1_score: 0.95468, speed: 5.12 step/s\n",
      "global_step: 3280, epoch: 2, batch: 653, loss: 0.03110, precission: 0.94981, recall: 0.96193, f1_score: 0.95583, speed: 4.17 step/s\n",
      "global_step: 3290, epoch: 2, batch: 663, loss: 0.00119, precission: 0.95138, recall: 0.96298, f1_score: 0.95714, speed: 3.20 step/s\n",
      "global_step: 3300, epoch: 2, batch: 673, loss: 0.01255, precission: 0.95146, recall: 0.96288, f1_score: 0.95714, speed: 3.41 step/s\n",
      "eval dev loss: 0.01991, precission: 0.94186, recall: 0.95565, f1_score: 0.94870\n",
      "global_step: 3310, epoch: 2, batch: 683, loss: 0.00936, precission: 0.94288, recall: 0.95520, f1_score: 0.94900, speed: 0.91 step/s\n",
      "global_step: 3320, epoch: 2, batch: 693, loss: 0.00277, precission: 0.94288, recall: 0.95613, f1_score: 0.94946, speed: 4.35 step/s\n",
      "global_step: 3330, epoch: 2, batch: 703, loss: 0.01274, precission: 0.94284, recall: 0.95591, f1_score: 0.94933, speed: 4.41 step/s\n",
      "global_step: 3340, epoch: 2, batch: 713, loss: 0.00439, precission: 0.94495, recall: 0.95824, f1_score: 0.95155, speed: 3.19 step/s\n",
      "global_step: 3350, epoch: 2, batch: 723, loss: 0.00163, precission: 0.94497, recall: 0.95722, f1_score: 0.95106, speed: 3.62 step/s\n",
      "global_step: 3360, epoch: 2, batch: 733, loss: 0.01281, precission: 0.94395, recall: 0.95731, f1_score: 0.95059, speed: 4.06 step/s\n",
      "global_step: 3370, epoch: 2, batch: 743, loss: 0.01934, precission: 0.94207, recall: 0.95591, f1_score: 0.94894, speed: 3.91 step/s\n",
      "global_step: 3380, epoch: 2, batch: 753, loss: 0.01463, precission: 0.94241, recall: 0.95694, f1_score: 0.94962, speed: 4.78 step/s\n",
      "global_step: 3390, epoch: 2, batch: 763, loss: 0.00867, precission: 0.94138, recall: 0.95697, f1_score: 0.94911, speed: 4.15 step/s\n",
      "global_step: 3400, epoch: 2, batch: 773, loss: 0.04005, precission: 0.94203, recall: 0.95765, f1_score: 0.94977, speed: 4.41 step/s\n",
      "eval dev loss: 0.01919, precission: 0.94152, recall: 0.96308, f1_score: 0.95218\n",
      "global_step: 3410, epoch: 2, batch: 783, loss: 0.00644, precission: 0.94349, recall: 0.96416, f1_score: 0.95371, speed: 0.84 step/s\n",
      "global_step: 3420, epoch: 2, batch: 793, loss: 0.00603, precission: 0.94412, recall: 0.96412, f1_score: 0.95402, speed: 4.21 step/s\n",
      "global_step: 3430, epoch: 2, batch: 803, loss: 0.00532, precission: 0.94485, recall: 0.96405, f1_score: 0.95436, speed: 4.49 step/s\n",
      "global_step: 3440, epoch: 2, batch: 813, loss: 0.00033, precission: 0.94575, recall: 0.96523, f1_score: 0.95539, speed: 4.39 step/s\n",
      "global_step: 3450, epoch: 2, batch: 823, loss: 0.01162, precission: 0.94769, recall: 0.96577, f1_score: 0.95664, speed: 3.91 step/s\n",
      "global_step: 3460, epoch: 2, batch: 833, loss: 0.00495, precission: 0.94815, recall: 0.96547, f1_score: 0.95673, speed: 3.65 step/s\n",
      "global_step: 3470, epoch: 2, batch: 843, loss: 0.02401, precission: 0.94828, recall: 0.96553, f1_score: 0.95682, speed: 4.58 step/s\n",
      "global_step: 3480, epoch: 2, batch: 853, loss: 0.01262, precission: 0.94822, recall: 0.96563, f1_score: 0.95684, speed: 3.90 step/s\n",
      "global_step: 3490, epoch: 2, batch: 863, loss: 0.00467, precission: 0.94941, recall: 0.96620, f1_score: 0.95773, speed: 3.19 step/s\n",
      "global_step: 3500, epoch: 2, batch: 873, loss: 0.00186, precission: 0.95031, recall: 0.96613, f1_score: 0.95815, speed: 2.83 step/s\n",
      "eval dev loss: 0.01799, precission: 0.94968, recall: 0.95771, f1_score: 0.95368\n",
      "global_step: 3510, epoch: 2, batch: 883, loss: 0.00632, precission: 0.95120, recall: 0.95979, f1_score: 0.95548, speed: 0.93 step/s\n",
      "global_step: 3520, epoch: 2, batch: 893, loss: 0.01289, precission: 0.95200, recall: 0.96084, f1_score: 0.95640, speed: 3.78 step/s\n",
      "global_step: 3530, epoch: 2, batch: 903, loss: 0.00606, precission: 0.95433, recall: 0.96263, f1_score: 0.95846, speed: 2.42 step/s\n",
      "global_step: 3540, epoch: 2, batch: 913, loss: 0.00197, precission: 0.95520, recall: 0.96272, f1_score: 0.95895, speed: 3.02 step/s\n",
      "global_step: 3550, epoch: 2, batch: 923, loss: 0.00253, precission: 0.95541, recall: 0.96368, f1_score: 0.95953, speed: 3.61 step/s\n",
      "global_step: 3560, epoch: 2, batch: 933, loss: 0.02072, precission: 0.95412, recall: 0.96331, f1_score: 0.95869, speed: 2.98 step/s\n",
      "global_step: 3570, epoch: 2, batch: 943, loss: 0.00380, precission: 0.95470, recall: 0.96444, f1_score: 0.95954, speed: 3.21 step/s\n",
      "global_step: 3580, epoch: 2, batch: 953, loss: 0.02495, precission: 0.95409, recall: 0.96427, f1_score: 0.95915, speed: 3.60 step/s\n",
      "global_step: 3590, epoch: 2, batch: 963, loss: 0.00352, precission: 0.95323, recall: 0.96370, f1_score: 0.95843, speed: 4.02 step/s\n",
      "global_step: 3600, epoch: 2, batch: 973, loss: 0.00370, precission: 0.95360, recall: 0.96368, f1_score: 0.95861, speed: 3.50 step/s\n",
      "eval dev loss: 0.01898, precission: 0.94076, recall: 0.95318, f1_score: 0.94693\n",
      "global_step: 3610, epoch: 2, batch: 983, loss: 0.01043, precission: 0.94217, recall: 0.95338, f1_score: 0.94774, speed: 0.87 step/s\n",
      "global_step: 3620, epoch: 2, batch: 993, loss: 0.00140, precission: 0.94243, recall: 0.95393, f1_score: 0.94814, speed: 4.67 step/s\n",
      "global_step: 3630, epoch: 2, batch: 1003, loss: 0.00788, precission: 0.94241, recall: 0.95511, f1_score: 0.94872, speed: 3.51 step/s\n",
      "global_step: 3640, epoch: 2, batch: 1013, loss: 0.00102, precission: 0.94336, recall: 0.95646, f1_score: 0.94987, speed: 3.47 step/s\n",
      "global_step: 3650, epoch: 2, batch: 1023, loss: 0.00574, precission: 0.94445, recall: 0.95707, f1_score: 0.95072, speed: 2.94 step/s\n",
      "global_step: 3660, epoch: 2, batch: 1033, loss: 0.00114, precission: 0.94514, recall: 0.95725, f1_score: 0.95116, speed: 4.08 step/s\n",
      "global_step: 3670, epoch: 2, batch: 1043, loss: 0.00101, precission: 0.94674, recall: 0.95884, f1_score: 0.95275, speed: 2.63 step/s\n",
      "global_step: 3680, epoch: 2, batch: 1053, loss: 0.00354, precission: 0.94752, recall: 0.95993, f1_score: 0.95369, speed: 3.39 step/s\n",
      "global_step: 3690, epoch: 2, batch: 1063, loss: 0.01391, precission: 0.94755, recall: 0.96012, f1_score: 0.95379, speed: 4.36 step/s\n",
      "global_step: 3700, epoch: 2, batch: 1073, loss: 0.03250, precission: 0.94791, recall: 0.96075, f1_score: 0.95429, speed: 4.72 step/s\n",
      "eval dev loss: 0.01941, precission: 0.95063, recall: 0.95318, f1_score: 0.95190\n",
      "global_step: 3710, epoch: 2, batch: 1083, loss: 0.01101, precission: 0.95113, recall: 0.95379, f1_score: 0.95246, speed: 0.88 step/s\n",
      "global_step: 3720, epoch: 2, batch: 1093, loss: 0.01681, precission: 0.95200, recall: 0.95588, f1_score: 0.95394, speed: 3.26 step/s\n",
      "global_step: 3730, epoch: 2, batch: 1103, loss: 0.00372, precission: 0.95331, recall: 0.95763, f1_score: 0.95546, speed: 4.08 step/s\n",
      "global_step: 3740, epoch: 2, batch: 1113, loss: 0.01014, precission: 0.95449, recall: 0.95888, f1_score: 0.95668, speed: 4.43 step/s\n",
      "global_step: 3750, epoch: 2, batch: 1123, loss: 0.01869, precission: 0.95575, recall: 0.96033, f1_score: 0.95803, speed: 4.22 step/s\n",
      "global_step: 3760, epoch: 2, batch: 1133, loss: 0.01915, precission: 0.95515, recall: 0.96004, f1_score: 0.95759, speed: 4.42 step/s\n",
      "global_step: 3770, epoch: 2, batch: 1143, loss: 0.00426, precission: 0.95485, recall: 0.96086, f1_score: 0.95784, speed: 4.54 step/s\n",
      "global_step: 3780, epoch: 2, batch: 1153, loss: 0.00528, precission: 0.95482, recall: 0.96122, f1_score: 0.95801, speed: 4.19 step/s\n",
      "global_step: 3790, epoch: 2, batch: 1163, loss: 0.00589, precission: 0.95521, recall: 0.96172, f1_score: 0.95845, speed: 3.03 step/s\n",
      "global_step: 3800, epoch: 2, batch: 1173, loss: 0.00911, precission: 0.95546, recall: 0.96228, f1_score: 0.95886, speed: 5.08 step/s\n",
      "eval dev loss: 0.01938, precission: 0.94885, recall: 0.95276, f1_score: 0.95080\n",
      "global_step: 3810, epoch: 2, batch: 1183, loss: 0.00255, precission: 0.95008, recall: 0.95419, f1_score: 0.95213, speed: 0.94 step/s\n",
      "global_step: 3820, epoch: 2, batch: 1193, loss: 0.00924, precission: 0.95009, recall: 0.95496, f1_score: 0.95252, speed: 4.63 step/s\n",
      "global_step: 3830, epoch: 2, batch: 1203, loss: 0.00779, precission: 0.95035, recall: 0.95599, f1_score: 0.95316, speed: 4.02 step/s\n",
      "global_step: 3840, epoch: 2, batch: 1213, loss: 0.00631, precission: 0.95006, recall: 0.95673, f1_score: 0.95338, speed: 3.18 step/s\n",
      "global_step: 3850, epoch: 2, batch: 1223, loss: 0.00582, precission: 0.95082, recall: 0.95807, f1_score: 0.95443, speed: 3.38 step/s\n",
      "global_step: 3860, epoch: 2, batch: 1233, loss: 0.00329, precission: 0.95176, recall: 0.95857, f1_score: 0.95515, speed: 4.46 step/s\n",
      "global_step: 3870, epoch: 2, batch: 1243, loss: 0.00174, precission: 0.95271, recall: 0.95908, f1_score: 0.95588, speed: 3.97 step/s\n",
      "global_step: 3880, epoch: 2, batch: 1253, loss: 0.00247, precission: 0.95366, recall: 0.96016, f1_score: 0.95690, speed: 3.66 step/s\n",
      "global_step: 3890, epoch: 2, batch: 1263, loss: 0.00226, precission: 0.95304, recall: 0.96049, f1_score: 0.95675, speed: 4.53 step/s\n",
      "global_step: 3900, epoch: 2, batch: 1273, loss: 0.00877, precission: 0.95276, recall: 0.96014, f1_score: 0.95643, speed: 3.01 step/s\n",
      "eval dev loss: 0.01922, precission: 0.94601, recall: 0.95771, f1_score: 0.95182\n",
      "global_step: 3910, epoch: 2, batch: 1283, loss: 0.02496, precission: 0.94606, recall: 0.95791, f1_score: 0.95195, speed: 0.92 step/s\n",
      "global_step: 3920, epoch: 2, batch: 1293, loss: 0.01551, precission: 0.94514, recall: 0.95865, f1_score: 0.95185, speed: 4.18 step/s\n",
      "global_step: 3930, epoch: 2, batch: 1303, loss: 0.01431, precission: 0.94595, recall: 0.95853, f1_score: 0.95220, speed: 3.20 step/s\n",
      "global_step: 3940, epoch: 3, batch: 0, loss: 0.01929, precission: 0.94679, recall: 0.95962, f1_score: 0.95316, speed: 4.48 step/s\n",
      "global_step: 3950, epoch: 3, batch: 10, loss: 0.00477, precission: 0.94772, recall: 0.95985, f1_score: 0.95375, speed: 3.90 step/s\n",
      "global_step: 3960, epoch: 3, batch: 20, loss: 0.00410, precission: 0.94769, recall: 0.96086, f1_score: 0.95423, speed: 4.12 step/s\n",
      "global_step: 3970, epoch: 3, batch: 30, loss: 0.01495, precission: 0.94861, recall: 0.96139, f1_score: 0.95496, speed: 4.45 step/s\n",
      "global_step: 3980, epoch: 3, batch: 40, loss: 0.00032, precission: 0.94992, recall: 0.96275, f1_score: 0.95629, speed: 4.55 step/s\n",
      "global_step: 3990, epoch: 3, batch: 50, loss: 0.00572, precission: 0.95115, recall: 0.96399, f1_score: 0.95753, speed: 4.05 step/s\n",
      "global_step: 4000, epoch: 3, batch: 60, loss: 0.00053, precission: 0.95250, recall: 0.96492, f1_score: 0.95867, speed: 3.58 step/s\n",
      "eval dev loss: 0.02175, precission: 0.95079, recall: 0.95648, f1_score: 0.95362\n",
      "global_step: 4010, epoch: 3, batch: 70, loss: 0.00087, precission: 0.95543, recall: 0.96102, f1_score: 0.95822, speed: 0.87 step/s\n",
      "global_step: 4020, epoch: 3, batch: 80, loss: 0.00062, precission: 0.95657, recall: 0.96236, f1_score: 0.95946, speed: 4.66 step/s\n",
      "global_step: 4030, epoch: 3, batch: 90, loss: 0.00438, precission: 0.95611, recall: 0.96296, f1_score: 0.95952, speed: 4.27 step/s\n",
      "global_step: 4040, epoch: 3, batch: 100, loss: 0.00688, precission: 0.95760, recall: 0.96391, f1_score: 0.96074, speed: 4.22 step/s\n",
      "global_step: 4050, epoch: 3, batch: 110, loss: 0.00552, precission: 0.95838, recall: 0.96524, f1_score: 0.96180, speed: 3.71 step/s\n",
      "global_step: 4060, epoch: 3, batch: 120, loss: 0.00213, precission: 0.96030, recall: 0.96660, f1_score: 0.96344, speed: 4.36 step/s\n",
      "global_step: 4070, epoch: 3, batch: 130, loss: 0.00189, precission: 0.96098, recall: 0.96761, f1_score: 0.96428, speed: 4.48 step/s\n",
      "global_step: 4080, epoch: 3, batch: 140, loss: 0.00330, precission: 0.96119, recall: 0.96771, f1_score: 0.96444, speed: 2.83 step/s\n",
      "global_step: 4090, epoch: 3, batch: 150, loss: 0.00313, precission: 0.96136, recall: 0.96786, f1_score: 0.96459, speed: 3.68 step/s\n",
      "global_step: 4100, epoch: 3, batch: 160, loss: 0.00186, precission: 0.96051, recall: 0.96812, f1_score: 0.96430, speed: 4.61 step/s\n",
      "eval dev loss: 0.02205, precission: 0.94922, recall: 0.95627, f1_score: 0.95273\n",
      "global_step: 4110, epoch: 3, batch: 170, loss: 0.02568, precission: 0.95141, recall: 0.95867, f1_score: 0.95503, speed: 0.88 step/s\n",
      "global_step: 4120, epoch: 3, batch: 180, loss: 0.00097, precission: 0.95476, recall: 0.96134, f1_score: 0.95804, speed: 3.55 step/s\n",
      "global_step: 4130, epoch: 3, batch: 190, loss: 0.01007, precission: 0.95676, recall: 0.96336, f1_score: 0.96005, speed: 3.16 step/s\n",
      "global_step: 4140, epoch: 3, batch: 200, loss: 0.00049, precission: 0.95865, recall: 0.96533, f1_score: 0.96198, speed: 3.90 step/s\n",
      "global_step: 4150, epoch: 3, batch: 210, loss: 0.00051, precission: 0.95978, recall: 0.96685, f1_score: 0.96330, speed: 4.21 step/s\n",
      "global_step: 4160, epoch: 3, batch: 220, loss: 0.00159, precission: 0.96037, recall: 0.96728, f1_score: 0.96381, speed: 4.61 step/s\n",
      "global_step: 4170, epoch: 3, batch: 230, loss: 0.01551, precission: 0.96157, recall: 0.96806, f1_score: 0.96481, speed: 2.52 step/s\n",
      "global_step: 4180, epoch: 3, batch: 240, loss: 0.00021, precission: 0.96213, recall: 0.96870, f1_score: 0.96540, speed: 3.24 step/s\n",
      "global_step: 4190, epoch: 3, batch: 250, loss: 0.00161, precission: 0.96240, recall: 0.96930, f1_score: 0.96584, speed: 4.01 step/s\n",
      "global_step: 4200, epoch: 3, batch: 260, loss: 0.00553, precission: 0.96226, recall: 0.96956, f1_score: 0.96589, speed: 4.06 step/s\n",
      "eval dev loss: 0.02019, precission: 0.95404, recall: 0.96349, f1_score: 0.95874\n",
      "save model at global step : 4200, best_precission: 0.95404, best_recall: 0.96349, best val f1_score: 0.95874\n",
      "global_step: 4210, epoch: 3, batch: 270, loss: 0.00586, precission: 0.95615, recall: 0.96446, f1_score: 0.96029, speed: 0.64 step/s\n",
      "global_step: 4220, epoch: 3, batch: 280, loss: 0.00258, precission: 0.95898, recall: 0.96711, f1_score: 0.96303, speed: 3.85 step/s\n",
      "global_step: 4230, epoch: 3, batch: 290, loss: 0.00804, precission: 0.96073, recall: 0.96848, f1_score: 0.96459, speed: 4.63 step/s\n",
      "global_step: 4240, epoch: 3, batch: 300, loss: 0.00059, precission: 0.96153, recall: 0.96940, f1_score: 0.96545, speed: 5.01 step/s\n",
      "global_step: 4250, epoch: 3, batch: 310, loss: 0.00112, precission: 0.96220, recall: 0.97041, f1_score: 0.96629, speed: 4.68 step/s\n",
      "global_step: 4260, epoch: 3, batch: 320, loss: 0.00236, precission: 0.96337, recall: 0.97109, f1_score: 0.96722, speed: 4.27 step/s\n",
      "global_step: 4270, epoch: 3, batch: 330, loss: 0.00805, precission: 0.96438, recall: 0.97173, f1_score: 0.96804, speed: 3.90 step/s\n",
      "global_step: 4280, epoch: 3, batch: 340, loss: 0.00161, precission: 0.96515, recall: 0.97212, f1_score: 0.96862, speed: 4.15 step/s\n",
      "global_step: 4290, epoch: 3, batch: 350, loss: 0.00050, precission: 0.96598, recall: 0.97321, f1_score: 0.96958, speed: 4.44 step/s\n",
      "global_step: 4300, epoch: 3, batch: 360, loss: 0.00077, precission: 0.96640, recall: 0.97329, f1_score: 0.96984, speed: 4.25 step/s\n",
      "eval dev loss: 0.02337, precission: 0.94882, recall: 0.95215, f1_score: 0.95048\n",
      "global_step: 4310, epoch: 3, batch: 370, loss: 0.00588, precission: 0.94953, recall: 0.95362, f1_score: 0.95157, speed: 0.92 step/s\n",
      "global_step: 4320, epoch: 3, batch: 380, loss: 0.00690, precission: 0.95073, recall: 0.95523, f1_score: 0.95297, speed: 4.78 step/s\n",
      "global_step: 4330, epoch: 3, batch: 390, loss: 0.03149, precission: 0.95292, recall: 0.95736, f1_score: 0.95514, speed: 4.34 step/s\n",
      "global_step: 4340, epoch: 3, batch: 400, loss: 0.01082, precission: 0.95435, recall: 0.95891, f1_score: 0.95663, speed: 2.82 step/s\n",
      "global_step: 4350, epoch: 3, batch: 410, loss: 0.00886, precission: 0.95542, recall: 0.96056, f1_score: 0.95798, speed: 3.99 step/s\n",
      "global_step: 4360, epoch: 3, batch: 420, loss: 0.01142, precission: 0.95542, recall: 0.96117, f1_score: 0.95828, speed: 4.57 step/s\n",
      "global_step: 4370, epoch: 3, batch: 430, loss: 0.00822, precission: 0.95685, recall: 0.96280, f1_score: 0.95981, speed: 3.24 step/s\n",
      "global_step: 4380, epoch: 3, batch: 440, loss: 0.00270, precission: 0.95657, recall: 0.96271, f1_score: 0.95963, speed: 3.51 step/s\n",
      "global_step: 4390, epoch: 3, batch: 450, loss: 0.00581, precission: 0.95773, recall: 0.96413, f1_score: 0.96092, speed: 3.37 step/s\n",
      "global_step: 4400, epoch: 3, batch: 460, loss: 0.00255, precission: 0.95808, recall: 0.96488, f1_score: 0.96147, speed: 4.70 step/s\n",
      "eval dev loss: 0.01955, precission: 0.94682, recall: 0.96225, f1_score: 0.95448\n",
      "global_step: 4410, epoch: 3, batch: 470, loss: 0.00493, precission: 0.95052, recall: 0.96448, f1_score: 0.95745, speed: 0.87 step/s\n",
      "global_step: 4420, epoch: 3, batch: 480, loss: 0.00928, precission: 0.95248, recall: 0.96547, f1_score: 0.95893, speed: 4.05 step/s\n",
      "global_step: 4430, epoch: 3, batch: 490, loss: 0.00063, precission: 0.95445, recall: 0.96600, f1_score: 0.96019, speed: 3.52 step/s\n",
      "global_step: 4440, epoch: 3, batch: 500, loss: 0.01204, precission: 0.95501, recall: 0.96664, f1_score: 0.96079, speed: 4.37 step/s\n",
      "global_step: 4450, epoch: 3, batch: 510, loss: 0.01828, precission: 0.95523, recall: 0.96744, f1_score: 0.96130, speed: 3.82 step/s\n",
      "global_step: 4460, epoch: 3, batch: 520, loss: 0.00744, precission: 0.95631, recall: 0.96838, f1_score: 0.96231, speed: 4.29 step/s\n",
      "global_step: 4470, epoch: 3, batch: 530, loss: 0.01712, precission: 0.95737, recall: 0.96899, f1_score: 0.96315, speed: 4.11 step/s\n",
      "global_step: 4480, epoch: 3, batch: 540, loss: 0.00450, precission: 0.95841, recall: 0.96989, f1_score: 0.96411, speed: 2.49 step/s\n",
      "global_step: 4490, epoch: 3, batch: 550, loss: 0.00418, precission: 0.95840, recall: 0.96983, f1_score: 0.96408, speed: 4.36 step/s\n",
      "global_step: 4500, epoch: 3, batch: 560, loss: 0.01128, precission: 0.95790, recall: 0.96903, f1_score: 0.96343, speed: 2.85 step/s\n",
      "eval dev loss: 0.02109, precission: 0.94586, recall: 0.95503, f1_score: 0.95043\n",
      "global_step: 4510, epoch: 3, batch: 570, loss: 0.01813, precission: 0.94806, recall: 0.95801, f1_score: 0.95301, speed: 0.91 step/s\n",
      "global_step: 4520, epoch: 3, batch: 580, loss: 0.00403, precission: 0.95056, recall: 0.96061, f1_score: 0.95556, speed: 3.99 step/s\n",
      "global_step: 4530, epoch: 3, batch: 590, loss: 0.00237, precission: 0.95207, recall: 0.96150, f1_score: 0.95676, speed: 4.30 step/s\n",
      "global_step: 4540, epoch: 3, batch: 600, loss: 0.01380, precission: 0.95324, recall: 0.96285, f1_score: 0.95802, speed: 3.90 step/s\n",
      "global_step: 4550, epoch: 3, batch: 610, loss: 0.00148, precission: 0.95489, recall: 0.96473, f1_score: 0.95978, speed: 3.94 step/s\n",
      "global_step: 4560, epoch: 3, batch: 620, loss: 0.00052, precission: 0.95580, recall: 0.96506, f1_score: 0.96041, speed: 3.99 step/s\n",
      "global_step: 4570, epoch: 3, batch: 630, loss: 0.00235, precission: 0.95711, recall: 0.96677, f1_score: 0.96191, speed: 3.01 step/s\n",
      "global_step: 4580, epoch: 3, batch: 640, loss: 0.00383, precission: 0.95809, recall: 0.96805, f1_score: 0.96305, speed: 3.45 step/s\n",
      "global_step: 4590, epoch: 3, batch: 650, loss: 0.00130, precission: 0.95899, recall: 0.96841, f1_score: 0.96368, speed: 4.15 step/s\n",
      "global_step: 4600, epoch: 3, batch: 660, loss: 0.00716, precission: 0.95931, recall: 0.96861, f1_score: 0.96394, speed: 3.99 step/s\n",
      "eval dev loss: 0.02079, precission: 0.94470, recall: 0.96555, f1_score: 0.95501\n",
      "global_step: 4610, epoch: 3, batch: 670, loss: 0.00014, precission: 0.94916, recall: 0.96786, f1_score: 0.95842, speed: 0.88 step/s\n",
      "global_step: 4620, epoch: 3, batch: 680, loss: 0.00225, precission: 0.95123, recall: 0.96897, f1_score: 0.96002, speed: 3.96 step/s\n",
      "global_step: 4630, epoch: 3, batch: 690, loss: 0.00160, precission: 0.95277, recall: 0.96957, f1_score: 0.96110, speed: 3.84 step/s\n",
      "global_step: 4640, epoch: 3, batch: 700, loss: 0.00224, precission: 0.95497, recall: 0.97099, f1_score: 0.96292, speed: 3.51 step/s\n",
      "global_step: 4650, epoch: 3, batch: 710, loss: 0.00505, precission: 0.95656, recall: 0.97190, f1_score: 0.96417, speed: 4.26 step/s\n",
      "global_step: 4660, epoch: 3, batch: 720, loss: 0.00053, precission: 0.95799, recall: 0.97228, f1_score: 0.96508, speed: 4.39 step/s\n",
      "global_step: 4670, epoch: 3, batch: 730, loss: 0.00655, precission: 0.95955, recall: 0.97316, f1_score: 0.96631, speed: 3.45 step/s\n",
      "global_step: 4680, epoch: 3, batch: 740, loss: 0.00190, precission: 0.95876, recall: 0.97287, f1_score: 0.96577, speed: 4.00 step/s\n",
      "global_step: 4690, epoch: 3, batch: 750, loss: 0.00048, precission: 0.95859, recall: 0.97295, f1_score: 0.96571, speed: 4.73 step/s\n",
      "global_step: 4700, epoch: 3, batch: 760, loss: 0.00284, precission: 0.95946, recall: 0.97357, f1_score: 0.96646, speed: 4.26 step/s\n",
      "eval dev loss: 0.02360, precission: 0.95257, recall: 0.95689, f1_score: 0.95472\n",
      "global_step: 4710, epoch: 3, batch: 770, loss: 0.00103, precission: 0.95345, recall: 0.95825, f1_score: 0.95584, speed: 0.91 step/s\n",
      "global_step: 4720, epoch: 3, batch: 780, loss: 0.01098, precission: 0.95573, recall: 0.96073, f1_score: 0.95822, speed: 3.49 step/s\n",
      "global_step: 4730, epoch: 3, batch: 790, loss: 0.00088, precission: 0.95718, recall: 0.96207, f1_score: 0.95962, speed: 3.90 step/s\n",
      "global_step: 4740, epoch: 3, batch: 800, loss: 0.00145, precission: 0.95777, recall: 0.96299, f1_score: 0.96037, speed: 3.48 step/s\n",
      "global_step: 4750, epoch: 3, batch: 810, loss: 0.01181, precission: 0.95782, recall: 0.96325, f1_score: 0.96053, speed: 3.98 step/s\n",
      "global_step: 4760, epoch: 3, batch: 820, loss: 0.00247, precission: 0.95831, recall: 0.96386, f1_score: 0.96107, speed: 3.89 step/s\n",
      "global_step: 4770, epoch: 3, batch: 830, loss: 0.00896, precission: 0.95915, recall: 0.96479, f1_score: 0.96196, speed: 4.09 step/s\n",
      "global_step: 4780, epoch: 3, batch: 840, loss: 0.00364, precission: 0.95953, recall: 0.96527, f1_score: 0.96239, speed: 3.99 step/s\n",
      "global_step: 4790, epoch: 3, batch: 850, loss: 0.00283, precission: 0.96014, recall: 0.96628, f1_score: 0.96320, speed: 3.59 step/s\n",
      "global_step: 4800, epoch: 3, batch: 860, loss: 0.00663, precission: 0.96077, recall: 0.96716, f1_score: 0.96395, speed: 3.92 step/s\n",
      "eval dev loss: 0.02058, precission: 0.94623, recall: 0.95833, f1_score: 0.95224\n",
      "global_step: 4810, epoch: 3, batch: 870, loss: 0.00161, precission: 0.94945, recall: 0.96093, f1_score: 0.95515, speed: 0.88 step/s\n",
      "global_step: 4820, epoch: 3, batch: 880, loss: 0.00292, precission: 0.95199, recall: 0.96238, f1_score: 0.95715, speed: 3.74 step/s\n",
      "global_step: 4830, epoch: 3, batch: 890, loss: 0.00170, precission: 0.95298, recall: 0.96354, f1_score: 0.95823, speed: 4.24 step/s\n",
      "global_step: 4840, epoch: 3, batch: 900, loss: 0.01373, precission: 0.95271, recall: 0.96377, f1_score: 0.95821, speed: 3.10 step/s\n",
      "global_step: 4850, epoch: 3, batch: 910, loss: 0.00190, precission: 0.95203, recall: 0.96368, f1_score: 0.95782, speed: 4.43 step/s\n",
      "global_step: 4860, epoch: 3, batch: 920, loss: 0.00385, precission: 0.95367, recall: 0.96520, f1_score: 0.95940, speed: 4.38 step/s\n",
      "global_step: 4870, epoch: 3, batch: 930, loss: 0.00440, precission: 0.95419, recall: 0.96478, f1_score: 0.95945, speed: 4.19 step/s\n",
      "global_step: 4880, epoch: 3, batch: 940, loss: 0.00050, precission: 0.95449, recall: 0.96521, f1_score: 0.95982, speed: 4.49 step/s\n",
      "global_step: 4890, epoch: 3, batch: 950, loss: 0.00203, precission: 0.95578, recall: 0.96698, f1_score: 0.96135, speed: 3.45 step/s\n",
      "global_step: 4900, epoch: 3, batch: 960, loss: 0.02176, precission: 0.95692, recall: 0.96755, f1_score: 0.96220, speed: 3.38 step/s\n",
      "eval dev loss: 0.02249, precission: 0.95002, recall: 0.95668, f1_score: 0.95334\n",
      "global_step: 4910, epoch: 3, batch: 970, loss: 0.00033, precission: 0.95222, recall: 0.95877, f1_score: 0.95548, speed: 0.92 step/s\n",
      "global_step: 4920, epoch: 3, batch: 980, loss: 0.00131, precission: 0.95405, recall: 0.96103, f1_score: 0.95752, speed: 4.53 step/s\n",
      "global_step: 4930, epoch: 3, batch: 990, loss: 0.00175, precission: 0.95717, recall: 0.96373, f1_score: 0.96044, speed: 3.09 step/s\n",
      "global_step: 4940, epoch: 3, batch: 1000, loss: 0.00024, precission: 0.95758, recall: 0.96447, f1_score: 0.96101, speed: 2.81 step/s\n",
      "global_step: 4950, epoch: 3, batch: 1010, loss: 0.00078, precission: 0.95823, recall: 0.96558, f1_score: 0.96189, speed: 4.65 step/s\n",
      "global_step: 4960, epoch: 3, batch: 1020, loss: 0.00037, precission: 0.95967, recall: 0.96689, f1_score: 0.96326, speed: 3.34 step/s\n",
      "global_step: 4970, epoch: 3, batch: 1030, loss: 0.01371, precission: 0.96089, recall: 0.96792, f1_score: 0.96439, speed: 4.07 step/s\n",
      "global_step: 4980, epoch: 3, batch: 1040, loss: 0.00902, precission: 0.96199, recall: 0.96874, f1_score: 0.96535, speed: 4.38 step/s\n",
      "global_step: 4990, epoch: 3, batch: 1050, loss: 0.00102, precission: 0.96234, recall: 0.96917, f1_score: 0.96574, speed: 2.84 step/s\n",
      "global_step: 5000, epoch: 3, batch: 1060, loss: 0.00542, precission: 0.96340, recall: 0.97002, f1_score: 0.96670, speed: 3.09 step/s\n",
      "eval dev loss: 0.02097, precission: 0.95783, recall: 0.96514, f1_score: 0.96147\n",
      "save model at global step : 5000, best_precission: 0.95783, best_recall: 0.96514, best val f1_score: 0.96147\n",
      "global_step: 5010, epoch: 3, batch: 1070, loss: 0.00376, precission: 0.96025, recall: 0.96672, f1_score: 0.96347, speed: 0.63 step/s\n",
      "global_step: 5020, epoch: 3, batch: 1080, loss: 0.00028, precission: 0.96211, recall: 0.96820, f1_score: 0.96515, speed: 3.35 step/s\n",
      "global_step: 5030, epoch: 3, batch: 1090, loss: 0.00668, precission: 0.96361, recall: 0.97026, f1_score: 0.96692, speed: 3.05 step/s\n",
      "global_step: 5040, epoch: 3, batch: 1100, loss: 0.00484, precission: 0.96377, recall: 0.97048, f1_score: 0.96711, speed: 3.30 step/s\n",
      "global_step: 5050, epoch: 3, batch: 1110, loss: 0.00186, precission: 0.96460, recall: 0.97107, f1_score: 0.96783, speed: 4.06 step/s\n",
      "global_step: 5060, epoch: 3, batch: 1120, loss: 0.00330, precission: 0.96411, recall: 0.97122, f1_score: 0.96765, speed: 4.14 step/s\n",
      "global_step: 5070, epoch: 3, batch: 1130, loss: 0.00434, precission: 0.96448, recall: 0.97156, f1_score: 0.96801, speed: 3.44 step/s\n",
      "global_step: 5080, epoch: 3, batch: 1140, loss: 0.00731, precission: 0.96565, recall: 0.97191, f1_score: 0.96877, speed: 4.11 step/s\n",
      "global_step: 5090, epoch: 3, batch: 1150, loss: 0.00880, precission: 0.96667, recall: 0.97298, f1_score: 0.96981, speed: 4.77 step/s\n",
      "global_step: 5100, epoch: 3, batch: 1160, loss: 0.00266, precission: 0.96610, recall: 0.97307, f1_score: 0.96958, speed: 4.04 step/s\n",
      "eval dev loss: 0.01985, precission: 0.95769, recall: 0.96184, f1_score: 0.95976\n",
      "global_step: 5110, epoch: 3, batch: 1170, loss: 0.00471, precission: 0.95872, recall: 0.96338, f1_score: 0.96104, speed: 0.92 step/s\n",
      "global_step: 5120, epoch: 3, batch: 1180, loss: 0.00399, precission: 0.95976, recall: 0.96467, f1_score: 0.96221, speed: 3.20 step/s\n",
      "global_step: 5130, epoch: 3, batch: 1190, loss: 0.00471, precission: 0.95981, recall: 0.96526, f1_score: 0.96253, speed: 4.26 step/s\n",
      "global_step: 5140, epoch: 3, batch: 1200, loss: 0.00067, precission: 0.96149, recall: 0.96675, f1_score: 0.96412, speed: 3.78 step/s\n",
      "global_step: 5150, epoch: 3, batch: 1210, loss: 0.00118, precission: 0.96171, recall: 0.96760, f1_score: 0.96465, speed: 3.16 step/s\n",
      "global_step: 5160, epoch: 3, batch: 1220, loss: 0.00169, precission: 0.96268, recall: 0.96868, f1_score: 0.96567, speed: 4.30 step/s\n",
      "global_step: 5170, epoch: 3, batch: 1230, loss: 0.00848, precission: 0.96289, recall: 0.96988, f1_score: 0.96637, speed: 4.63 step/s\n",
      "global_step: 5180, epoch: 3, batch: 1240, loss: 0.00133, precission: 0.96443, recall: 0.97119, f1_score: 0.96780, speed: 3.77 step/s\n",
      "global_step: 5190, epoch: 3, batch: 1250, loss: 0.00301, precission: 0.96443, recall: 0.97096, f1_score: 0.96769, speed: 3.76 step/s\n",
      "global_step: 5200, epoch: 3, batch: 1260, loss: 0.00579, precission: 0.96470, recall: 0.97107, f1_score: 0.96787, speed: 3.90 step/s\n",
      "eval dev loss: 0.02276, precission: 0.94421, recall: 0.95998, f1_score: 0.95203\n",
      "global_step: 5210, epoch: 3, batch: 1270, loss: 0.01191, precission: 0.94476, recall: 0.96075, f1_score: 0.95269, speed: 0.92 step/s\n",
      "global_step: 5220, epoch: 3, batch: 1280, loss: 0.00978, precission: 0.94729, recall: 0.96205, f1_score: 0.95461, speed: 3.67 step/s\n",
      "global_step: 5230, epoch: 3, batch: 1290, loss: 0.00720, precission: 0.94885, recall: 0.96380, f1_score: 0.95627, speed: 4.50 step/s\n",
      "global_step: 5240, epoch: 3, batch: 1300, loss: 0.00618, precission: 0.95079, recall: 0.96455, f1_score: 0.95762, speed: 4.54 step/s\n",
      "global_step: 5250, epoch: 3, batch: 1310, loss: 0.00194, precission: 0.95185, recall: 0.96540, f1_score: 0.95858, speed: 3.25 step/s\n",
      "global_step: 5260, epoch: 4, batch: 7, loss: 0.00156, precission: 0.95167, recall: 0.96532, f1_score: 0.95845, speed: 4.90 step/s\n",
      "global_step: 5270, epoch: 4, batch: 17, loss: 0.00454, precission: 0.95357, recall: 0.96671, f1_score: 0.96010, speed: 3.26 step/s\n",
      "global_step: 5280, epoch: 4, batch: 27, loss: 0.00191, precission: 0.95528, recall: 0.96789, f1_score: 0.96154, speed: 3.93 step/s\n",
      "global_step: 5290, epoch: 4, batch: 37, loss: 0.00051, precission: 0.95662, recall: 0.96880, f1_score: 0.96267, speed: 4.50 step/s\n",
      "global_step: 5300, epoch: 4, batch: 47, loss: 0.00223, precission: 0.95761, recall: 0.96961, f1_score: 0.96358, speed: 4.45 step/s\n",
      "eval dev loss: 0.02408, precission: 0.94477, recall: 0.95978, f1_score: 0.95222\n",
      "global_step: 5310, epoch: 4, batch: 57, loss: 0.00048, precission: 0.94572, recall: 0.96098, f1_score: 0.95328, speed: 0.92 step/s\n",
      "global_step: 5320, epoch: 4, batch: 67, loss: 0.00679, precission: 0.94855, recall: 0.96329, f1_score: 0.95587, speed: 3.22 step/s\n",
      "global_step: 5330, epoch: 4, batch: 77, loss: 0.00148, precission: 0.95079, recall: 0.96378, f1_score: 0.95724, speed: 3.09 step/s\n",
      "global_step: 5340, epoch: 4, batch: 87, loss: 0.00562, precission: 0.95374, recall: 0.96616, f1_score: 0.95991, speed: 4.25 step/s\n",
      "global_step: 5350, epoch: 4, batch: 97, loss: 0.00556, precission: 0.95524, recall: 0.96769, f1_score: 0.96143, speed: 4.00 step/s\n",
      "global_step: 5360, epoch: 4, batch: 107, loss: 0.00150, precission: 0.95673, recall: 0.96884, f1_score: 0.96275, speed: 3.17 step/s\n",
      "global_step: 5370, epoch: 4, batch: 117, loss: 0.00917, precission: 0.95715, recall: 0.96893, f1_score: 0.96301, speed: 4.01 step/s\n",
      "global_step: 5380, epoch: 4, batch: 127, loss: 0.00298, precission: 0.95768, recall: 0.96914, f1_score: 0.96338, speed: 2.71 step/s\n",
      "global_step: 5390, epoch: 4, batch: 137, loss: 0.02275, precission: 0.95862, recall: 0.96967, f1_score: 0.96412, speed: 3.86 step/s\n",
      "global_step: 5400, epoch: 4, batch: 147, loss: 0.00385, precission: 0.95908, recall: 0.97026, f1_score: 0.96464, speed: 3.83 step/s\n",
      "eval dev loss: 0.02181, precission: 0.94821, recall: 0.95916, f1_score: 0.95365\n",
      "global_step: 5410, epoch: 4, batch: 157, loss: 0.00170, precission: 0.95097, recall: 0.96228, f1_score: 0.95659, speed: 0.92 step/s\n",
      "global_step: 5420, epoch: 4, batch: 167, loss: 0.01010, precission: 0.95353, recall: 0.96462, f1_score: 0.95904, speed: 3.92 step/s\n",
      "global_step: 5430, epoch: 4, batch: 177, loss: 0.00035, precission: 0.95531, recall: 0.96554, f1_score: 0.96040, speed: 4.17 step/s\n",
      "global_step: 5440, epoch: 4, batch: 187, loss: 0.01044, precission: 0.95637, recall: 0.96651, f1_score: 0.96141, speed: 3.85 step/s\n",
      "global_step: 5450, epoch: 4, batch: 197, loss: 0.00368, precission: 0.95763, recall: 0.96756, f1_score: 0.96257, speed: 4.87 step/s\n",
      "global_step: 5460, epoch: 4, batch: 207, loss: 0.00537, precission: 0.95843, recall: 0.96867, f1_score: 0.96352, speed: 3.09 step/s\n",
      "global_step: 5470, epoch: 4, batch: 217, loss: 0.03064, precission: 0.95899, recall: 0.96870, f1_score: 0.96382, speed: 3.73 step/s\n",
      "global_step: 5480, epoch: 4, batch: 227, loss: 0.00012, precission: 0.96037, recall: 0.96995, f1_score: 0.96513, speed: 4.27 step/s\n",
      "global_step: 5490, epoch: 4, batch: 237, loss: 0.00351, precission: 0.96173, recall: 0.97090, f1_score: 0.96629, speed: 4.07 step/s\n",
      "global_step: 5500, epoch: 4, batch: 247, loss: 0.00813, precission: 0.96243, recall: 0.97125, f1_score: 0.96682, speed: 4.75 step/s\n",
      "eval dev loss: 0.02058, precission: 0.94917, recall: 0.95916, f1_score: 0.95414\n",
      "global_step: 5510, epoch: 4, batch: 257, loss: 0.01445, precission: 0.94976, recall: 0.96090, f1_score: 0.95530, speed: 0.91 step/s\n",
      "global_step: 5520, epoch: 4, batch: 267, loss: 0.01166, precission: 0.95197, recall: 0.96293, f1_score: 0.95741, speed: 3.87 step/s\n",
      "global_step: 5530, epoch: 4, batch: 277, loss: 0.00213, precission: 0.95448, recall: 0.96486, f1_score: 0.95964, speed: 3.36 step/s\n",
      "global_step: 5540, epoch: 4, batch: 287, loss: 0.00437, precission: 0.95503, recall: 0.96526, f1_score: 0.96012, speed: 4.03 step/s\n",
      "global_step: 5550, epoch: 4, batch: 297, loss: 0.00142, precission: 0.95688, recall: 0.96685, f1_score: 0.96184, speed: 3.03 step/s\n",
      "global_step: 5560, epoch: 4, batch: 307, loss: 0.00265, precission: 0.95865, recall: 0.96832, f1_score: 0.96346, speed: 3.19 step/s\n",
      "global_step: 5570, epoch: 4, batch: 317, loss: 0.00639, precission: 0.95983, recall: 0.96916, f1_score: 0.96447, speed: 3.87 step/s\n",
      "global_step: 5580, epoch: 4, batch: 327, loss: 0.01259, precission: 0.96106, recall: 0.96992, f1_score: 0.96547, speed: 3.09 step/s\n",
      "global_step: 5590, epoch: 4, batch: 337, loss: 0.00269, precission: 0.96042, recall: 0.96999, f1_score: 0.96518, speed: 3.56 step/s\n",
      "global_step: 5600, epoch: 4, batch: 347, loss: 0.00614, precission: 0.96090, recall: 0.97031, f1_score: 0.96558, speed: 4.04 step/s\n",
      "eval dev loss: 0.02483, precission: 0.95362, recall: 0.95854, f1_score: 0.95607\n",
      "global_step: 5610, epoch: 4, batch: 357, loss: 0.00450, precission: 0.95595, recall: 0.96109, f1_score: 0.95851, speed: 0.89 step/s\n",
      "global_step: 5620, epoch: 4, batch: 367, loss: 0.00360, precission: 0.95833, recall: 0.96349, f1_score: 0.96090, speed: 3.79 step/s\n",
      "global_step: 5630, epoch: 4, batch: 377, loss: 0.00211, precission: 0.96068, recall: 0.96615, f1_score: 0.96341, speed: 4.08 step/s\n",
      "global_step: 5640, epoch: 4, batch: 387, loss: 0.00074, precission: 0.96136, recall: 0.96746, f1_score: 0.96440, speed: 3.27 step/s\n",
      "global_step: 5650, epoch: 4, batch: 397, loss: 0.02555, precission: 0.96234, recall: 0.96844, f1_score: 0.96538, speed: 3.65 step/s\n",
      "global_step: 5660, epoch: 4, batch: 407, loss: 0.01071, precission: 0.96277, recall: 0.96922, f1_score: 0.96599, speed: 4.83 step/s\n",
      "global_step: 5670, epoch: 4, batch: 417, loss: 0.00247, precission: 0.96362, recall: 0.97035, f1_score: 0.96697, speed: 4.41 step/s\n",
      "global_step: 5680, epoch: 4, batch: 427, loss: 0.01452, precission: 0.96384, recall: 0.97063, f1_score: 0.96723, speed: 4.24 step/s\n",
      "global_step: 5690, epoch: 4, batch: 437, loss: 0.01937, precission: 0.96408, recall: 0.97120, f1_score: 0.96762, speed: 4.75 step/s\n",
      "global_step: 5700, epoch: 4, batch: 447, loss: 0.00448, precission: 0.96344, recall: 0.97173, f1_score: 0.96757, speed: 4.03 step/s\n",
      "eval dev loss: 0.02072, precission: 0.94394, recall: 0.95854, f1_score: 0.95118\n",
      "global_step: 5710, epoch: 4, batch: 457, loss: 0.00511, precission: 0.94697, recall: 0.96075, f1_score: 0.95381, speed: 0.92 step/s\n",
      "global_step: 5720, epoch: 4, batch: 467, loss: 0.00739, precission: 0.94987, recall: 0.96204, f1_score: 0.95592, speed: 4.23 step/s\n",
      "global_step: 5730, epoch: 4, batch: 477, loss: 0.00147, precission: 0.95234, recall: 0.96415, f1_score: 0.95821, speed: 3.97 step/s\n",
      "global_step: 5740, epoch: 4, batch: 487, loss: 0.00887, precission: 0.95465, recall: 0.96642, f1_score: 0.96050, speed: 3.29 step/s\n",
      "global_step: 5750, epoch: 4, batch: 497, loss: 0.00188, precission: 0.95716, recall: 0.96800, f1_score: 0.96255, speed: 5.00 step/s\n",
      "global_step: 5760, epoch: 4, batch: 507, loss: 0.00036, precission: 0.95827, recall: 0.96864, f1_score: 0.96343, speed: 4.74 step/s\n",
      "global_step: 5770, epoch: 4, batch: 517, loss: 0.00380, precission: 0.95796, recall: 0.96882, f1_score: 0.96336, speed: 4.36 step/s\n",
      "global_step: 5780, epoch: 4, batch: 527, loss: 0.00037, precission: 0.95865, recall: 0.96958, f1_score: 0.96408, speed: 4.30 step/s\n",
      "global_step: 5790, epoch: 4, batch: 537, loss: 0.00304, precission: 0.95966, recall: 0.97001, f1_score: 0.96481, speed: 3.29 step/s\n",
      "global_step: 5800, epoch: 4, batch: 547, loss: 0.00440, precission: 0.96023, recall: 0.97042, f1_score: 0.96530, speed: 3.48 step/s\n",
      "eval dev loss: 0.02122, precission: 0.94867, recall: 0.96060, f1_score: 0.95460\n",
      "global_step: 5810, epoch: 4, batch: 557, loss: 0.00342, precission: 0.95105, recall: 0.96234, f1_score: 0.95666, speed: 0.92 step/s\n",
      "global_step: 5820, epoch: 4, batch: 567, loss: 0.00241, precission: 0.95366, recall: 0.96472, f1_score: 0.95916, speed: 4.09 step/s\n",
      "global_step: 5830, epoch: 4, batch: 577, loss: 0.01222, precission: 0.95536, recall: 0.96611, f1_score: 0.96070, speed: 3.40 step/s\n",
      "global_step: 5840, epoch: 4, batch: 587, loss: 0.00110, precission: 0.95723, recall: 0.96698, f1_score: 0.96208, speed: 2.79 step/s\n",
      "global_step: 5850, epoch: 4, batch: 597, loss: 0.01790, precission: 0.95809, recall: 0.96775, f1_score: 0.96290, speed: 2.77 step/s\n",
      "global_step: 5860, epoch: 4, batch: 607, loss: 0.00141, precission: 0.95959, recall: 0.96896, f1_score: 0.96425, speed: 4.48 step/s\n",
      "global_step: 5870, epoch: 4, batch: 617, loss: 0.00112, precission: 0.96093, recall: 0.97001, f1_score: 0.96545, speed: 4.43 step/s\n",
      "global_step: 5880, epoch: 4, batch: 627, loss: 0.00168, precission: 0.96157, recall: 0.97090, f1_score: 0.96621, speed: 4.57 step/s\n",
      "global_step: 5890, epoch: 4, batch: 637, loss: 0.00041, precission: 0.96305, recall: 0.97180, f1_score: 0.96741, speed: 4.71 step/s\n",
      "global_step: 5900, epoch: 4, batch: 647, loss: 0.00355, precission: 0.96333, recall: 0.97208, f1_score: 0.96768, speed: 3.43 step/s\n",
      "eval dev loss: 0.02211, precission: 0.95139, recall: 0.95689, f1_score: 0.95413\n",
      "global_step: 5910, epoch: 4, batch: 657, loss: 0.00162, precission: 0.95414, recall: 0.95889, f1_score: 0.95651, speed: 0.81 step/s\n",
      "global_step: 5920, epoch: 4, batch: 667, loss: 0.00453, precission: 0.95617, recall: 0.96097, f1_score: 0.95856, speed: 3.39 step/s\n",
      "global_step: 5930, epoch: 4, batch: 677, loss: 0.00928, precission: 0.95782, recall: 0.96327, f1_score: 0.96054, speed: 4.23 step/s\n",
      "global_step: 5940, epoch: 4, batch: 687, loss: 0.00663, precission: 0.95855, recall: 0.96499, f1_score: 0.96176, speed: 4.16 step/s\n",
      "global_step: 5950, epoch: 4, batch: 697, loss: 0.00585, precission: 0.96003, recall: 0.96545, f1_score: 0.96273, speed: 2.97 step/s\n",
      "global_step: 5960, epoch: 4, batch: 707, loss: 0.00191, precission: 0.96096, recall: 0.96650, f1_score: 0.96372, speed: 3.85 step/s\n",
      "global_step: 5970, epoch: 4, batch: 717, loss: 0.00302, precission: 0.96220, recall: 0.96795, f1_score: 0.96506, speed: 3.85 step/s\n",
      "global_step: 5980, epoch: 4, batch: 727, loss: 0.00146, precission: 0.96277, recall: 0.96885, f1_score: 0.96580, speed: 4.54 step/s\n",
      "global_step: 5990, epoch: 4, batch: 737, loss: 0.00805, precission: 0.96381, recall: 0.96979, f1_score: 0.96679, speed: 3.03 step/s\n",
      "global_step: 6000, epoch: 4, batch: 747, loss: 0.01945, precission: 0.96344, recall: 0.96976, f1_score: 0.96659, speed: 3.22 step/s\n",
      "eval dev loss: 0.02207, precission: 0.94951, recall: 0.96205, f1_score: 0.95574\n",
      "global_step: 6010, epoch: 4, batch: 757, loss: 0.00074, precission: 0.95084, recall: 0.96379, f1_score: 0.95727, speed: 0.92 step/s\n",
      "global_step: 6020, epoch: 4, batch: 767, loss: 0.00169, precission: 0.95403, recall: 0.96633, f1_score: 0.96014, speed: 3.78 step/s\n",
      "global_step: 6030, epoch: 4, batch: 777, loss: 0.00760, precission: 0.95194, recall: 0.96560, f1_score: 0.95872, speed: 4.46 step/s\n",
      "global_step: 6040, epoch: 4, batch: 787, loss: 0.00405, precission: 0.95325, recall: 0.96626, f1_score: 0.95971, speed: 4.24 step/s\n",
      "global_step: 6050, epoch: 4, batch: 797, loss: 0.00429, precission: 0.95436, recall: 0.96738, f1_score: 0.96082, speed: 3.95 step/s\n",
      "global_step: 6060, epoch: 4, batch: 807, loss: 0.00152, precission: 0.95642, recall: 0.96796, f1_score: 0.96216, speed: 3.89 step/s\n",
      "global_step: 6070, epoch: 4, batch: 817, loss: 0.00237, precission: 0.95695, recall: 0.96831, f1_score: 0.96260, speed: 3.73 step/s\n",
      "global_step: 6080, epoch: 4, batch: 827, loss: 0.00961, precission: 0.95748, recall: 0.96888, f1_score: 0.96314, speed: 4.22 step/s\n",
      "global_step: 6090, epoch: 4, batch: 837, loss: 0.00448, precission: 0.95852, recall: 0.96958, f1_score: 0.96402, speed: 3.96 step/s\n",
      "global_step: 6100, epoch: 4, batch: 847, loss: 0.00081, precission: 0.95913, recall: 0.96999, f1_score: 0.96453, speed: 3.62 step/s\n",
      "eval dev loss: 0.02241, precission: 0.95141, recall: 0.96122, f1_score: 0.95629\n",
      "global_step: 6110, epoch: 4, batch: 857, loss: 0.01115, precission: 0.95313, recall: 0.96272, f1_score: 0.95790, speed: 0.89 step/s\n",
      "global_step: 6120, epoch: 4, batch: 867, loss: 0.00020, precission: 0.95502, recall: 0.96465, f1_score: 0.95981, speed: 4.61 step/s\n",
      "global_step: 6130, epoch: 4, batch: 877, loss: 0.00050, precission: 0.95741, recall: 0.96688, f1_score: 0.96212, speed: 4.91 step/s\n",
      "global_step: 6140, epoch: 4, batch: 887, loss: 0.00049, precission: 0.95947, recall: 0.96833, f1_score: 0.96388, speed: 4.01 step/s\n",
      "global_step: 6150, epoch: 4, batch: 897, loss: 0.00092, precission: 0.96095, recall: 0.96946, f1_score: 0.96518, speed: 4.31 step/s\n",
      "global_step: 6160, epoch: 4, batch: 907, loss: 0.00123, precission: 0.96269, recall: 0.97002, f1_score: 0.96634, speed: 4.01 step/s\n",
      "global_step: 6170, epoch: 4, batch: 917, loss: 0.00157, precission: 0.96312, recall: 0.97083, f1_score: 0.96696, speed: 3.73 step/s\n",
      "global_step: 6180, epoch: 4, batch: 927, loss: 0.00487, precission: 0.96363, recall: 0.97110, f1_score: 0.96735, speed: 3.50 step/s\n",
      "global_step: 6190, epoch: 4, batch: 937, loss: 0.00500, precission: 0.96414, recall: 0.97125, f1_score: 0.96768, speed: 3.31 step/s\n",
      "global_step: 6200, epoch: 4, batch: 947, loss: 0.01380, precission: 0.96453, recall: 0.97171, f1_score: 0.96811, speed: 3.19 step/s\n",
      "eval dev loss: 0.02475, precission: 0.94881, recall: 0.95586, f1_score: 0.95232\n",
      "global_step: 6210, epoch: 4, batch: 957, loss: 0.00099, precission: 0.95215, recall: 0.95886, f1_score: 0.95549, speed: 0.85 step/s\n",
      "global_step: 6220, epoch: 4, batch: 967, loss: 0.00269, precission: 0.95348, recall: 0.96060, f1_score: 0.95703, speed: 4.41 step/s\n",
      "global_step: 6230, epoch: 4, batch: 977, loss: 0.00378, precission: 0.95437, recall: 0.96192, f1_score: 0.95813, speed: 4.55 step/s\n",
      "global_step: 6240, epoch: 4, batch: 987, loss: 0.00083, precission: 0.95623, recall: 0.96439, f1_score: 0.96029, speed: 3.41 step/s\n",
      "global_step: 6250, epoch: 4, batch: 997, loss: 0.00025, precission: 0.95828, recall: 0.96603, f1_score: 0.96214, speed: 4.45 step/s\n",
      "global_step: 6260, epoch: 4, batch: 1007, loss: 0.02068, precission: 0.95886, recall: 0.96625, f1_score: 0.96254, speed: 4.31 step/s\n",
      "global_step: 6270, epoch: 4, batch: 1017, loss: 0.00515, precission: 0.96017, recall: 0.96765, f1_score: 0.96390, speed: 4.27 step/s\n",
      "global_step: 6280, epoch: 4, batch: 1027, loss: 0.01168, precission: 0.95993, recall: 0.96805, f1_score: 0.96398, speed: 4.45 step/s\n",
      "global_step: 6290, epoch: 4, batch: 1037, loss: 0.00612, precission: 0.96121, recall: 0.96907, f1_score: 0.96513, speed: 4.70 step/s\n",
      "global_step: 6300, epoch: 4, batch: 1047, loss: 0.00540, precission: 0.96142, recall: 0.96929, f1_score: 0.96534, speed: 4.04 step/s\n",
      "eval dev loss: 0.02102, precission: 0.95275, recall: 0.96081, f1_score: 0.95676\n",
      "global_step: 6310, epoch: 4, batch: 1057, loss: 0.00686, precission: 0.95584, recall: 0.96361, f1_score: 0.95971, speed: 0.86 step/s\n",
      "global_step: 6320, epoch: 4, batch: 1067, loss: 0.00181, precission: 0.95866, recall: 0.96584, f1_score: 0.96224, speed: 3.59 step/s\n",
      "global_step: 6330, epoch: 4, batch: 1077, loss: 0.01292, precission: 0.95712, recall: 0.96567, f1_score: 0.96137, speed: 3.92 step/s\n",
      "global_step: 6340, epoch: 4, batch: 1087, loss: 0.00066, precission: 0.95859, recall: 0.96654, f1_score: 0.96255, speed: 4.10 step/s\n",
      "global_step: 6350, epoch: 4, batch: 1097, loss: 0.00352, precission: 0.95925, recall: 0.96732, f1_score: 0.96327, speed: 4.24 step/s\n",
      "global_step: 6360, epoch: 4, batch: 1107, loss: 0.00037, precission: 0.96028, recall: 0.96848, f1_score: 0.96436, speed: 3.89 step/s\n",
      "global_step: 6370, epoch: 4, batch: 1117, loss: 0.00631, precission: 0.96096, recall: 0.96906, f1_score: 0.96499, speed: 4.47 step/s\n",
      "global_step: 6380, epoch: 4, batch: 1127, loss: 0.00734, precission: 0.96125, recall: 0.96970, f1_score: 0.96546, speed: 3.99 step/s\n",
      "global_step: 6390, epoch: 4, batch: 1137, loss: 0.00040, precission: 0.96191, recall: 0.97031, f1_score: 0.96609, speed: 4.47 step/s\n",
      "global_step: 6400, epoch: 4, batch: 1147, loss: 0.00853, precission: 0.96300, recall: 0.97085, f1_score: 0.96691, speed: 4.03 step/s\n",
      "eval dev loss: 0.02210, precission: 0.95468, recall: 0.96019, f1_score: 0.95742\n",
      "global_step: 6410, epoch: 4, batch: 1157, loss: 0.01093, precission: 0.95578, recall: 0.96183, f1_score: 0.95880, speed: 0.93 step/s\n",
      "global_step: 6420, epoch: 4, batch: 1167, loss: 0.00109, precission: 0.95672, recall: 0.96274, f1_score: 0.95972, speed: 4.66 step/s\n",
      "global_step: 6430, epoch: 4, batch: 1177, loss: 0.00170, precission: 0.95842, recall: 0.96443, f1_score: 0.96142, speed: 4.37 step/s\n",
      "global_step: 6440, epoch: 4, batch: 1187, loss: 0.00860, precission: 0.95952, recall: 0.96560, f1_score: 0.96255, speed: 4.79 step/s\n",
      "global_step: 6450, epoch: 4, batch: 1197, loss: 0.00833, precission: 0.95898, recall: 0.96609, f1_score: 0.96252, speed: 3.12 step/s\n",
      "global_step: 6460, epoch: 4, batch: 1207, loss: 0.00504, precission: 0.95936, recall: 0.96576, f1_score: 0.96255, speed: 3.86 step/s\n",
      "global_step: 6470, epoch: 4, batch: 1217, loss: 0.01332, precission: 0.96035, recall: 0.96674, f1_score: 0.96354, speed: 4.11 step/s\n",
      "global_step: 6480, epoch: 4, batch: 1227, loss: 0.00621, precission: 0.96163, recall: 0.96803, f1_score: 0.96482, speed: 3.22 step/s\n",
      "global_step: 6490, epoch: 4, batch: 1237, loss: 0.00025, precission: 0.96242, recall: 0.96847, f1_score: 0.96544, speed: 3.15 step/s\n",
      "global_step: 6500, epoch: 4, batch: 1247, loss: 0.00160, precission: 0.96365, recall: 0.96973, f1_score: 0.96668, speed: 3.31 step/s\n",
      "eval dev loss: 0.02284, precission: 0.94967, recall: 0.96143, f1_score: 0.95551\n",
      "global_step: 6510, epoch: 4, batch: 1257, loss: 0.00035, precission: 0.95235, recall: 0.96330, f1_score: 0.95780, speed: 0.91 step/s\n",
      "global_step: 6520, epoch: 4, batch: 1267, loss: 0.00989, precission: 0.95488, recall: 0.96557, f1_score: 0.96020, speed: 4.01 step/s\n",
      "global_step: 6530, epoch: 4, batch: 1277, loss: 0.00696, precission: 0.95531, recall: 0.96607, f1_score: 0.96066, speed: 3.95 step/s\n",
      "global_step: 6540, epoch: 4, batch: 1287, loss: 0.00632, precission: 0.95615, recall: 0.96633, f1_score: 0.96121, speed: 4.76 step/s\n",
      "global_step: 6550, epoch: 4, batch: 1297, loss: 0.00320, precission: 0.95705, recall: 0.96730, f1_score: 0.96215, speed: 4.26 step/s\n",
      "global_step: 6560, epoch: 4, batch: 1307, loss: 0.00044, precission: 0.95673, recall: 0.96744, f1_score: 0.96205, speed: 4.30 step/s\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "best_f1_score = 0.0\n",
    "best_precission = 0.0\n",
    "best_recall = 0.0\n",
    "\n",
    "print_every_step = 10\n",
    "evaluate_every_step = 100\n",
    "\n",
    "save_dir = os.path.join('./data', 'checkpoints')\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_param_path = os.path.join(save_dir, 'bets_model_state.pdparams')\n",
    "\n",
    "tic_train = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch_data in enumerate(train_data_loader):\n",
    "        \n",
    "        input_ids, token_type_ids, length, labels = batch_data\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        preds = paddle.argmax(logits, axis=-1)\n",
    "        n_infer, n_label, n_correct = metric.compute(None, length, preds, labels)\n",
    "        metric.update(n_infer.numpy(), n_label.numpy(), n_correct.numpy())\n",
    "        precission, recall, f1_score = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % print_every_step == 0:\n",
    "            print('global_step: %d, epoch: %d, batch: %d, loss: %.5f, precission: %.5f, recall: %.5f, f1_score: %.5f, speed: %.2f step/s' % (\n",
    "                global_step, epoch, step, loss.numpy(), precission, recall, f1_score, print_every_step / (time.time() - tic_train)\n",
    "            ))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        if global_step % evaluate_every_step == 0:\n",
    "            loss, precission, recall, f1_score = evaluate(model, loss_fn, metric, dev_data_loader)\n",
    "            print('eval dev loss: %.5f, precission: %.5f, recall: %.5f, f1_score: %.5f' % (\n",
    "                loss, precission, recall, f1_score\n",
    "            ))\n",
    "            if f1_score > best_f1_score and precission > best_precission and recall > best_recall:\n",
    "                \n",
    "                best_f1_score = f1_score\n",
    "                best_precission = precission \n",
    "                best_recall = recall\n",
    "\n",
    "                print('save model at global step : %d, best_precission: %.5f, best_recall: %.5f, best val f1_score: %.5f' % (\n",
    "                    global_step, best_precission, best_recall, best_f1_score\n",
    "                ))\n",
    "\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "|dataset|Precission| Recall|F1-Score|\n",
    "|---|---|---|---|\n",
    "|train|96.340|97.002|96.67|\n",
    "|dev|95.783|96.514|96.147|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型预测\n",
    "\n",
    "训练保存好的模型，即可用于预测。如以下示例代码自定义预测数据，调用`predict()`函数即可一键预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batch_sampler = BatchSampler(\r\n",
    "    dataset=test_dataset,\r\n",
    "    batch_size=2,\r\n",
    "    shuffle=False\r\n",
    ")\r\n",
    "test_data_loader = DataLoader(\r\n",
    "    dataset=test_dataset,\r\n",
    "    batch_sampler=test_batch_sampler,\r\n",
    "    collate_fn=batchify_fn,\r\n",
    "    return_list=True\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader, ds, label_vocab):\r\n",
    "    pred_list = []\r\n",
    "    len_list = []\r\n",
    "    for input_ids, seg_ids, lens, labels in data_loader:\r\n",
    "        logits = model(input_ids, seg_ids)\r\n",
    "        pred = paddle.argmax(logits, axis=-1)\r\n",
    "        pred_list.append(pred.numpy())\r\n",
    "        len_list.append(lens.numpy())\r\n",
    "    preds = parse_decodes(ds, pred_list, len_list, label_vocab)\r\n",
    "    return preds\r\n",
    "\r\n",
    "def parse_decodes(ds, decodes, lens, label_vocab):\r\n",
    "    decodes = [x for batch in decodes for x in batch]  # [[]]\r\n",
    "    lens = [x for batch in lens for x in batch]        # []\r\n",
    "    id_label = dict(zip(label_vocab.values(), label_vocab.keys()))\r\n",
    "\r\n",
    "    outputs = []\r\n",
    "    for idx, end in enumerate(lens):\r\n",
    "        sent = ds.data[idx]['tokens'][:end]\r\n",
    "        tags = [id_label[x] for x in decodes[idx][1:end]]\r\n",
    "        sent_out = []\r\n",
    "        tags_out = []\r\n",
    "        words = \"\"\r\n",
    "        for s, t in zip(sent, tags):\r\n",
    "            if t.startswith('B-') or t == 'O':\r\n",
    "                if len(words):\r\n",
    "                    sent_out.append(words)\r\n",
    "                if t.startswith('B-'):\r\n",
    "                    tags_out.append(t.split('-')[1])\r\n",
    "                else:\r\n",
    "                    tags_out.append(t)\r\n",
    "                words = s\r\n",
    "            else:\r\n",
    "                words += s\r\n",
    "        if len(sent_out) < len(tags_out):\r\n",
    "            sent_out.append(words)\r\n",
    "        outputs.append(''.join(\r\n",
    "            [str((s, t)) for s, t in zip(sent_out, tags_out)]))\r\n",
    "    return outputs\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = predict(model, test_data_loader, test_dataset, label_vocab)\n",
    "file_path = \"msra_ner_results.txt\"\n",
    "with open(file_path, \"w\", encoding=\"utf8\") as fout:\n",
    "    fout.write(\"\\n\".join(preds))\n",
    "# Print some examples\n",
    "print(\n",
    "    \"The results have been saved in the file: %s, some examples are shown below: \"\n",
    "    % file_path)\n",
    "print(\"\\n\".join(preds[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 进一步使用CRF\n",
    "\n",
    "PaddleNLP提供了CRF Layer，它能够学习label之间的关系，能够帮助模型更好地学习、预测序列标注任务。\n",
    "\n",
    "我们在PaddleNLP仓库中提供了[示例](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/information_extraction/waybill_ie/run_ernie_crf.py)，您可以参照示例代码使用Ernie-CRF结构完成快递单信息抽取任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 加入交流群，一起学习吧\n",
    "\n",
    "现在就加入课程QQ交流群，一起交流NLP技术吧！\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/d953727af0c24a7c806ab529495f0904f22f809961be420b8c88cdf59b837394\" width=\"200\" height=\"250\" >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
